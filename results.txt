[36mBullseye[37m: [0m[37mStarting...[97m (integrate)[0m[0m
[36mBullseye[37m/[36mclean[37m: [0m[37mStarting...[0m[0m
SKIPPED target 'clean' evaluated not to run
[36mBullseye[37m/[36mclean[37m: [0m[32mSucceeded.[0m[35m (8.19 ms)[0m[0m
[36mBullseye[37m/[36mrestore[37m: [0m[37mStarting...[0m[0m
  Restore completed in 47.25 ms for c:\Source\elasticsearch-net-7.x\src\CodeGeneration\ApiGenerator\ApiGenerator.csproj.
  Restore completed in 46.99 ms for c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Elasticsearch.Net.csproj.
  Restore completed in 46.99 ms for c:\Source\elasticsearch-net-7.x\build\scripts\scripts.fsproj.
  Restore completed in 49.43 ms for c:\Source\elasticsearch-net-7.x\src\CodeGeneration\DocGenerator\DocGenerator.csproj.
  Restore completed in 0.96 ms for c:\Source\elasticsearch-net-7.x\src\Nest\Nest.csproj.
  Restore completed in 0.9 ms for c:\Source\elasticsearch-net-7.x\src\Serializers\Nest.JsonNetSerializer\Nest.JsonNetSerializer.csproj.
  Restore completed in 0.46 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.Configuration\Tests.Configuration.csproj.
  Restore completed in 1.65 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.Domain\Tests.Domain.csproj.
  Restore completed in 5.38 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.ClusterLauncher\Tests.ClusterLauncher.csproj.
  Restore completed in 1.98 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.Core\Tests.Core.csproj.
  Restore completed in 3.56 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Tests.csproj.
  Restore completed in 9.65 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.Reproduce\Tests.Reproduce.csproj.
  Restore completed in 14.63 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.Benchmarking\Tests.Benchmarking.csproj.
  Restore completed in 35.12 ms for c:\Source\elasticsearch-net-7.x\build\scripts\scripts.fsproj.
  Restore completed in 1.94 ms for c:\Source\elasticsearch-net-7.x\src\Tests\Tests.ScratchPad\Tests.ScratchPad.csproj.
  Restore completed in 42.45 ms for c:\Source\elasticsearch-net-7.x\build\scripts\scripts.fsproj.
[36mBullseye[37m/[36mrestore[37m: [0m[32mSucceeded.[0m[35m (1.87 s)[0m[0m
[36mBullseye[37m/[36mfull-build[37m: [0m[37mStarting...[0m[0m
SKIPPED target 'full-build' evaluated not to run
[36mBullseye[37m/[36mfull-build[37m: [0m[32mSucceeded.[0m[35m (<1 ms)[0m[0m
[36mBullseye[37m/[36mintegrate[37m: [0m[37mStarting...[0m[0m
Build started, please wait...
Build completed.

Test run for c:\Source\elasticsearch-net-7.x\src\Tests\Tests\bin\RELEASE\netcoreapp2.1\Tests.dll(.NETCoreApp,Version=v2.1)
Microsoft (R) Test Execution Command Line Tool Version 15.9.0
Copyright (c) Microsoft Corporation.  All rights reserved.

Starting test execution, please wait...
--------------------
Starting tests using config:
 - TestAgainstAlreadyRunningElasticsearch: False
 - ElasticsearchVersion: 7.0.0
 - Mode: Integration
 - Seed: 44010
 - ForceReseed: False
 - TestOnlyOne: False
 - ClusterFilter: 
 - TestFilter: 
 - RunIntegrationTests: True
 - RunUnitTests: False
 - Random:
 	- SourceSerializer: True
 	- TypedKeys: False
--------------------
[2019-06-03T05:57:02,747][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T05:57:02,759][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T05:57:02,760][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-cca293]
[2019-06-03T05:57:02,761][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T05:57:02,761][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T05:57:02,764][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T05:57:02,765][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [mapper-murmur3]
[2019-06-03T05:57:02,766][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T05:57:02,766][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T05:57:02,767][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T05:57:02,769][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T05:57:02,770][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T05:57:02,771][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T05:57:02,772][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T05:57:02,772][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T05:57:02,775][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T05:57:02,782][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-mapper-murmur3} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\home]
[2019-06-03T05:57:05,583][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T05:57:05,600][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293}
[2019-06-03T05:57:05,600][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\config}
[2019-06-03T05:57:05,604][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\config]
[2019-06-03T05:57:05,624][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-mapper-murmur3]
[2019-06-03T05:57:05,626][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\config\analysis]
[2019-06-03T05:57:05,637][INFO ][Managed Elasticsearch    ] [readonly-node-2cfe0f9200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\home\bin\elasticsearch.bat]
[2019-06-03T05:57:05,638][INFO ][Managed Elasticsearch    ] [readonly-node-2cfe0f9200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-cca293 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=readonly-node-2cfe0f9200 -E http.port=9200 -E cluster.initial_master_nodes=readonly-node-2cfe0f9200}
[2019-06-03T15:57:16,558][INFO ][o.e.e.NodeEnvironment    ] [readonly-node-2cfe0f9200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T15:57:16,562][INFO ][o.e.e.NodeEnvironment    ] [readonly-node-2cfe0f9200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T15:57:16,570][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] node name [readonly-node-2cfe0f9200], node ID [D0Nh2fysTpGMg1iKu38Yxw]
[2019-06-03T15:57:16,571][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] version[7.0.0], pid[9788], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T15:57:16,571][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T15:57:16,572][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T15:57:35,564][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [aggs-matrix-stats]
[2019-06-03T15:57:35,565][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [analysis-common]
[2019-06-03T15:57:35,565][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [ingest-common]
[2019-06-03T15:57:35,565][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [ingest-geoip]
[2019-06-03T15:57:35,566][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [ingest-user-agent]
[2019-06-03T15:57:35,566][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [lang-expression]
[2019-06-03T15:57:35,566][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [lang-mustache]
[2019-06-03T15:57:35,567][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [lang-painless]
[2019-06-03T15:57:35,567][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [mapper-extras]
[2019-06-03T15:57:35,567][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [parent-join]
[2019-06-03T15:57:35,567][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [percolator]
[2019-06-03T15:57:35,568][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [rank-eval]
[2019-06-03T15:57:35,568][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [reindex]
[2019-06-03T15:57:35,568][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [repository-url]
[2019-06-03T15:57:35,570][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [transport-netty4]
[2019-06-03T15:57:35,570][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-ccr]
[2019-06-03T15:57:35,571][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-core]
[2019-06-03T15:57:35,571][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-deprecation]
[2019-06-03T15:57:35,572][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-graph]
[2019-06-03T15:57:35,572][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-ilm]
[2019-06-03T15:57:35,573][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-logstash]
[2019-06-03T15:57:35,573][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-ml]
[2019-06-03T15:57:35,574][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-monitoring]
[2019-06-03T15:57:35,575][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-rollup]
[2019-06-03T15:57:35,575][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-security]
[2019-06-03T15:57:35,576][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-sql]
[2019-06-03T15:57:35,576][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded module [x-pack-watcher]
[2019-06-03T15:57:35,577][INFO ][o.e.p.PluginsService     ] [readonly-node-2cfe0f9200] loaded plugin [mapper-murmur3]
[2019-06-03T15:57:43,269][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [readonly-node-2cfe0f9200] [controller/6524] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T15:57:44,451][INFO ][o.e.d.DiscoveryModule    ] [readonly-node-2cfe0f9200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T15:57:45,407][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] initialized
[2019-06-03T15:57:45,407][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] starting ...
[2019-06-03T15:57:46,179][INFO ][o.e.t.TransportService   ] [readonly-node-2cfe0f9200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T15:57:46,185][WARN ][o.e.b.BootstrapChecks    ] [readonly-node-2cfe0f9200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T15:57:46,199][INFO ][o.e.c.c.ClusterBootstrapService] [readonly-node-2cfe0f9200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T15:57:49,205][INFO ][o.e.c.c.Coordinator      ] [readonly-node-2cfe0f9200] setting initial configuration to VotingConfiguration{D0Nh2fysTpGMg1iKu38Yxw}
[2019-06-03T15:57:49,321][INFO ][o.e.c.s.MasterService    ] [readonly-node-2cfe0f9200] elected-as-master ([1] nodes joined)[{readonly-node-2cfe0f9200}{D0Nh2fysTpGMg1iKu38Yxw}{Np2Thv_rQUW6B_9X8HJFJQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{readonly-node-2cfe0f9200}{D0Nh2fysTpGMg1iKu38Yxw}{Np2Thv_rQUW6B_9X8HJFJQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T15:57:49,442][INFO ][o.e.c.s.ClusterApplierService] [readonly-node-2cfe0f9200] master node changed {previous [], current [{readonly-node-2cfe0f9200}{D0Nh2fysTpGMg1iKu38Yxw}{Np2Thv_rQUW6B_9X8HJFJQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T15:57:49,775][INFO ][o.e.g.GatewayService     ] [readonly-node-2cfe0f9200] recovered [0] indices into cluster_state
[2019-06-03T15:57:49,931][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T15:57:50,132][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T15:57:50,303][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T15:57:50,477][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T15:57:50,622][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T15:57:50,815][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T15:57:50,913][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T15:57:50,971][INFO ][o.e.h.AbstractHttpServerTransport] [readonly-node-2cfe0f9200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T15:57:50,972][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] started
[2019-06-03T05:57:50,992][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T15:57:51,019][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T15:57:51,095][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [readonly-node-2cfe0f9200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T15:57:51,397][INFO ][o.e.l.LicenseService     ] [readonly-node-2cfe0f9200] license [a3b96bb0-44eb-4cf6-829a-9f66a8c04d9f] mode [basic] - valid
[2019-06-03T05:57:51,408][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T05:57:51,460][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T05:57:51,462][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T05:57:51,464][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T05:57:51,634][INFO ][Managed Elasticsearch    ]  {ValidatePluginsTask} validating the cluster is running the requested plugins
[2019-06-03T05:57:51,650][INFO ][Managed Elasticsearch    ]  All good! kicking off [ReadOnlyCluster] tests now
[2019-06-03T15:57:51,869][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [readonly-node-2cfe0f9200] failed to delete templates [nest_tests]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [nest_tests] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:52,078][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:57:52,080][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:57:52,108][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:57:52,110][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:57:52,446][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [nest_tests] for index patterns [*]
[2019-06-03T15:57:52,892][INFO ][o.e.c.m.MetaDataCreateIndexService] [readonly-node-2cfe0f9200] [devs] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:57:53,061][INFO ][o.e.c.m.MetaDataCreateIndexService] [readonly-node-2cfe0f9200] [project] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:57:53,250][INFO ][o.e.c.m.MetaDataCreateIndexService] [readonly-node-2cfe0f9200] [queries] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:57:53,698][INFO ][o.e.c.r.a.AllocationService] [readonly-node-2cfe0f9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[queries][0]] ...]).
[2019-06-03T15:57:53,991][INFO ][o.e.c.m.MetaDataMappingService] [readonly-node-2cfe0f9200] [project/Fq7oXseLTySuuXI4pnx8KQ] update_mapping [_doc]
[2019-06-03T15:57:55,181][INFO ][o.e.c.m.MetaDataMappingService] [readonly-node-2cfe0f9200] [project/Fq7oXseLTySuuXI4pnx8KQ] update_mapping [_doc]
[2019-06-03T15:57:57,443][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:57,450][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:57,766][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:57,819][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:57,819][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,234][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,417][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,420][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,502][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,685][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386)Failed   Tests.Search.MultiSearch.MultiSearchInvalidApiTests.ReturnsExpectedIsValid
 ~[elasticsearch-7.0.0.jar:7.0.0]Error Message:

 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
	at Stack Trace:
org.elasticsearch.search.SearchService.access$100   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 361
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 120
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 128
(Failed   Tests.Search.MultiSearch.MultiSearchInvalidApiTests.AssertResponse
SearchService.java:124Error Message:
)  Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
~[elasticsearch-7.0.0.jar:7.0.0]
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 361
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 120
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 128
Failed   Tests.Search.MultiSearch.MultiSearchInvalidApiTests.ReturnsExpectedResponse
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 361
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 120
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 128
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at Failed   Tests.Search.MultiSearch.MultiSearchInvalidApiTests.ReturnsExpectedStatusCode
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedStatusCode() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 44
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 361
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 120
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 128
org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:58,688][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"point","coordinates":[38.897676,-77.03653]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:59,115][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:57:59,484][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_two.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:58:00,213][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_one.seeds] from [[]] to [["127.0.0.1:9300","127.0.0.1:9301"]]
[2019-06-03T15:58:00,215][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_two.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:58:00,234][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_one.seeds] from [[]] to [["127.0.0.1:9300","127.0.0.1:9301"]]
[2019-06-03T15:58:00,321][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_two.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:58:00,322][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_one.seeds] from [[]] to [["127.0.0.1:9300","127.0.0.1:9301"]]
[2019-06-03T15:58:00,323][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_one.seeds] from [[]] to [["127.0.0.1:9300","127.0.0.1:9301"]]
[2019-06-03T15:58:00,414][INFO ][o.e.c.s.ClusterSettings  ] [readonly-node-2cfe0f9200] updating [cluster.remote.cluster_two.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:58:01,312][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,318][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,312][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,462][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at Failed   Tests.Cluster.NodesHotThreads.NodesHotThreadsApiTests.ReturnsExpectedResponse
Error Message:
org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun Tests.Framework.EndpointTests.ResponseAssertionException : Expected response.HotThreads not to be empty.
Response Under Test:
Valid NEST response built from a successful low level call on GET: /_nodes/hot_threads?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] HealthyResponse: Node: http://localhost:9200/ Took: 00:00:00.7261793
# Request:
<Request stream not captured or already read to completion by serializer. Set DisableDirectStreaming() on ConnectionSettings to force it to be set on the response.>
# Response:
::: {readonly-node-2cfe0f9200}{D0Nh2fysTpGMg1iKu38Yxw}{Np2Thv_rQUW6B_9X8HJFJQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}
   Hot threads at 2019-06-03T05:57:59.591Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:
   
    9.4% (46.8ms out of 500ms) cpu usage by thread 'elasticsearch[readonly-node-2cfe0f9200][search][T#1]'
     3/10 snapshots sharing following 7 elements
       app//org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
       app//org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41)
       app//org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751)
       app//org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
       java.base@10.0.1/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
       java.base@10.0.1/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
       java.base@10.0.1/java.lang.Thread.run(Unknown Source)
     6/10 snapshots sharing following 10 elements
       java.base@10.0.1/jdk.internal.misc.Unsafe.park(Native Method)
       java.base@10.0.1/java.util.concurrent.locks.LockSupport.park(Unknown Source)
       java.base@10.0.1/java.util.concurrent.LinkedTransferQueue.awaitMatch(Unknown Source)
       java.base@10.0.1/java.util.concurrent.LinkedTransferQueue.xfer(Unknown Source)
       java.base@10.0.1/java.util.concurrent.LinkedTransferQueue.take(Unknown Source)
       app//org.elasticsearch.common.util.concurrent.SizeBlockingQueue.take(SizeBlockingQueue.java:165)
       java.base@10.0.1/java.util.concurrent.ThreadPoolExecutor.getTask(Unknown Source)
       java.base@10.0.1/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
       java.base@10.0.1/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
       java.base@10.0.1/java.lang.Thread.run(Unknown Source)



---- Expected response.HotThreads not to be empty.
(Stack Trace:
ThreadContext.java:751   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void FluentAssertions.Execution.XUnit2TestFramework.Throw(string message) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/XUnit2TestFramework.cs:line 32
   at Continuation FluentAssertions.Execution.AssertionScope.FailWith(Func<FailReason> failReasonFunc) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/AssertionScope.cs:line 181
   at AndConstraint<TAssertions> FluentAssertions.Collections.CollectionAssertions<TSubject, TAssertions>.NotBeEmpty(string because, object[] becauseArgs) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Collections/CollectionAssertions.cs:line 71
   at void Tests.Cluster.NodesHotThreads.NodesHotThreadsApiTests.ExpectResponse(NodesHotThreadsResponse response) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Cluster/NodesHotThreads/NodesHotThreadsApiTests.cs:line 31
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,461][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at Failed   Tests.Document.Single.Source.SourceIntegrationTests.SourceReturnsDocument
Error Message:
 System.NullReferenceException : Object reference not set to an instance of an object.
Stack Trace:
   at Tests.Document.Single.Source.SourceIntegrationTests.SourceReturnsDocument() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Document\Single\Source\SourceApiTests.cs:line 18
org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,532][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:01,531][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:03,338][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"from":10,"size":20,"aggregations":{"startDates":{"date_range":{"ranges":[{"from":"-1m"}],"keyed":false}}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.ElasticsearchParseException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]: [failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]
	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:116) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:224) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: java.time.format.DateTimeParseException: Failed to parse with all enclosed parsers
	at org.elasticsearch.common.time.JavaDateFormatter.doParse(JavaDateFormatter.java:143) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:114) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:224) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
[2019-06-03T15:58:03,338][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"from":10,"size":20,"aggregations":{"startDates":{"date_range":{"ranges":[{"from":"-1m"}],"keyed":false}}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.ElasticsearchParseException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]: [failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]
	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:116) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:224) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: java.time.format.DateTimeParseException: Failed to parse with all enclosed parsers
	at org.elasticsearch.common.time.JavaDateFormatter.doParse(JavaDateFormatter.java:143) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:114) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:224) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
Failed   Tests.Cluster.NodesStats.NodesStatsApiTests.ReturnsExpectedResponse
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearch(Indices index, Func`2 selector) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 664
   at Tests.Cluster.NodesStats.NodesStatsApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Cluster\NodesStats\NodesStatsApiTests.cs:line 41
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
Failed   Tests.Cluster.NodesStats.NodesStatsApiTests.ReturnsExpectedStatusCode
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearch(Indices index, Func`2 selector) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 664
   at Tests.Cluster.NodesStats.NodesStatsApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Cluster\NodesStats\NodesStatsApiTests.cs:line 41
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedStatusCode() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 44
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at Failed   Tests.Cluster.NodesStats.NodesStatsApiTests.ReturnsExpectedIsValid
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearch(Indices index, Func`2 selector) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 664
   at Tests.Cluster.NodesStats.NodesStatsApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Cluster\NodesStats\NodesStatsApiTests.cs:line 41
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
[2019-06-03T15:58:02,905][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:04,157][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:06,351][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.ElasticsearchParseException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]: [failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parse(JavaDateMathParser.java:76) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:229) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.DocValueFormat$DateTime.parseDouble(DocValueFormat.java:234) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.lambda$innerBuild$2(DateRangeAggregationBuilder.java:303) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.AbstractRangeBuilder.processRanges(AbstractRangeBuilder.java:78) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:295) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.bucket.range.DateRangeAggregationBuilder.innerBuild(DateRangeAggregationBuilder.java:38) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:315) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:139) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:332) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:801) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: failed to parse date field [-1m] with format [strict_date_optional_time||epoch_millis]
	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:116) ~[elasticsearch-7.0.0.jar:7.0.0]
	at Failed   Tests.Search.MultiSearch.MultiSearchApiTests.AssertResponse
org.elasticsearch.common.time.JavaDateMathParser.parseDateTimeError Message:
( Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
JavaDateMathParser.java:224Stack Trace:
)    at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__5>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
~[elasticsearch-7.0.0.jar:7.0.0]
Failed   Tests.Search.MultiSearch.MultiSearchApiTests.ReturnsExpectedStatusCode
	... 26 more
Error Message:
Caused by: java.time.format.DateTimeParseException: Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
 Failed to parse with all enclosed parsersStack Trace:

   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__5>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedStatusCode() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 44
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
	at Failed   Tests.Search.MultiSearch.MultiSearchApiTests.ReturnsExpectedResponse
org.elasticsearch.common.time.JavaDateFormatter.doParseError Message:
( Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
JavaDateFormatter.java:143Stack Trace:
)    at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__5>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
~[elasticsearch-7.0.0.jar:7.0.0]Failed   Tests.Search.MultiSearch.MultiSearchApiTests.ReturnsExpectedIsValid
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__5>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73

	at org.elasticsearch.common.time.JavaDateFormatter.parse(JavaDateFormatter.java:114) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.time.JavaDateMathParser.parseDateTime(JavaDateMathParser.java:224) Failed   Tests.Search.MultiSearch.MultiSearchTemplate.MultiSearchTemplateApiTests.ReturnsExpectedStatusCode
~[elasticsearch-7.0.0.jar:7.0.0]
Error Message:
	... 26 more
 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
[Stack Trace:
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearchTemplate(IMultiSearchTemplateRequest request) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 700
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<Calls>b__4() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 105
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedStatusCode() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 44
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
Failed   Tests.Search.MultiSearch.MultiSearchTemplate.MultiSearchTemplateApiTests.ReturnsExpectedResponse
Error Message:
2019-06-03T15:58:04,155 Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
][DEBUGStack Trace:
][o.e.a.s.TransportSearchAction   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearchTemplate(IMultiSearchTemplateRequest request) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 700
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<Calls>b__4() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 105
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
] [readonly-node-2cfe0f9200Failed   Tests.Search.MultiSearch.MultiSearchTemplate.MultiSearchTemplateApiTests.ReturnsExpectedIsValid
] [projectError Message:
][ Elasticsearch.Net.UnexpectedElasticsearchClientException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
---- System.MissingMethodException : Constructor on type 'Nest.MultiSearchResponseFormatter' not found.
1], nodeStack Trace:
[D0Nh2fysTpGMg1iKu38Yxw]   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 91
   at Nest.ElasticClient.MultiSearchTemplate(IMultiSearchTemplateRequest request) in c:\Source\elasticsearch-net-7.x\src\Nest\ElasticClient.NoNamespace.cs:line 700
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<Calls>b__4() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 105
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonFormatterResolverExtensions.GetFormatterWithVerify[T](IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\IJsonFormatterResolver.cs:line 52
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 260
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Stream stream, IJsonFormatterResolver resolver) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonSerializer.cs:line 319
   at Nest.InternalSerializer.Deserialize[T](Stream stream) in c:\Source\elasticsearch-net-7.x\src\Nest\CommonAbstractions\SerializationBehavior\InternalSerializer.cs:line 35
   at Elasticsearch.Net.ResponseBuilder.SetBody[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 103
   at Elasticsearch.Net.ResponseBuilder.ToResponse[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\ResponseBuilder.cs:line 28
   at Elasticsearch.Net.HttpConnection.Request[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Connection\HttpConnection.cs:line 77
   at Elasticsearch.Net.RequestPipeline.CallElasticsearch[TResponse](RequestData requestData) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Pipeline\RequestPipeline.cs:line 155
   at Elasticsearch.Net.Transport`1.Request[TResponse](HttpMethod method, String path, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 73
, [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
[xUnit.net 00:01:08.8324419]     Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedResponse [SKIP]
[xUnit.net 00:01:08.8340942]     Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedStatusCode [SKIP]
[xUnit.net 00:01:08.8343633]     Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedIsValid [SKIP]
Skipped  Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedResponse
Skipped  Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedStatusCode
Skipped  Tests.Aggregations.Metric.GeoCentroid.GeoCentroidNoResultsAggregationUsageTests.ReturnsExpectedIsValid
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:04,031][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:07,500][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:07,499][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:07,069][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [nest-fluentasync-08db14b8] for index patterns [nestx-*]
[2019-06-03T15:58:08,228][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,072][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,071][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,291][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,281][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,259][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,439][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,403][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,832][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,832][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,858][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,857][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,850][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,849][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multipoint","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,846][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [nest-initializer-ccb02572] for index patterns [nestx-*]
[2019-06-03T15:58:08,839][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,839][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,206][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,071][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,900][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:08,878][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,289][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [nest-initializerasync-053cde0e] for index patterns [nestx-*]
[2019-06-03T15:58:09,269][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,251][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,397][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,841][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,843][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"circle","radius":"100.0m","coordinates":[45.0,-45.0]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,861][INFO ][o.e.c.m.MetaDataIndexTemplateService] [readonly-node-2cfe0f9200] adding template [nest-fluent-1ad57e62] for index patterns [nestx-*]
[2019-06-03T15:58:09,853][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,853][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,852][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,851][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,845][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,845][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,928][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:09,889][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,239][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,252][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,251][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,249][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,299][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,275][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,275][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"linestring","coordinates":[[38.897676,-77.03653],[38.889939,-77.009051]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,321][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,321][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,321][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][0], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=u4fzz75YRB6ZZu9LC17eQQ]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"envelope","coordinates":[[45.0,-45.0],[-45.0,45.0]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,321][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] [project][1], node[D0Nh2fysTpGMg1iKu38Yxw], [P], s[STARTED], a[id=BZpvzg1IS7qpucVI4jl0xw]: Failed to execute [SearchRequest{searchType=QUERY_THEN_FETCH, indices=[project], indicesOptions=IndicesOptions[ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_aliases_to_multiple_indices=true, forbid_closed_indices=true, ignore_aliases=false, ignore_throttled=true], types=[], routing='null', preference='null', requestCache=null, scroll=null, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, allowPartialSearchResults=true, localClusterAlias=null, getOrCreateAbsoluteStartMillis=-1, ccsMinimizeRoundtrips=true, source={"query":{"geo_shape":{"location":{"shape":{"type":"multilinestring","coordinates":[[[2.0,12.0],[2.0,13.0],[3.0,13.0],[3.0,12.0]],[[0.0,10.0],[0.0,11.0],[1.0,11.0],[1.0,10.0]],[[0.2,10.2],[0.2,10.8],[0.8,10.8],[0.8,12.0]]]},"relation":"intersects"},"ignore_unmapped":false,"boost":1.1,"_name":"named_query"}}}}] lastShard [true]
org.elasticsearch.transport.RemoteTransportException: [readonly-node-2cfe0f9200][127.0.0.1:9300][indices:data/read/search[phase/query]]
Caused by: org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,372][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,340][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,404][DEBUG][o.e.a.s.TransportSearchAction] [readonly-node-2cfe0f9200] All shards failed for phase: [query]
org.elasticsearch.index.query.QueryShardException: Field [location] is not of type [geo_shape] but of type [geo_point]
	at org.elasticsearch.index.query.GeoShapeQueryBuilder.doToQuery(GeoShapeQueryBuilder.java:419) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.AbstractQueryBuilder.toQuery(AbstractQueryBuilder.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.lambda$toQuery$1(QueryShardContext.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:305) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.query.QueryShardContext.toQuery(QueryShardContext.java:292) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.parseSource(SearchService.java:755) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:608) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:583) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:386) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService.access$100(SearchService.java:124) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:354) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1069) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:58:10,855][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] stopping ...
[2019-06-03T15:58:10,866][INFO ][o.e.x.w.WatcherService   ] [readonly-node-2cfe0f9200] stopping watch service, reason [shutdown initiated]
[2019-06-03T15:58:10,910][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [readonly-node-2cfe0f9200] [controller/6524] [Main.cc@148] Ml controller exiting
[2019-06-03T15:58:10,911][INFO ][o.e.x.m.p.NativeController] [readonly-node-2cfe0f9200] Native controller process has stopped - no new native processes can be started
[2019-06-03T15:58:11,032][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] stopped
[2019-06-03T15:58:11,033][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] closing ...
[2019-06-03T15:58:11,043][INFO ][o.e.n.Node               ] [readonly-node-2cfe0f9200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T05:58:11,247][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\data}
[2019-06-03T05:58:11,268][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\config}
[2019-06-03T05:58:11,272][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\logs}
[2019-06-03T05:58:11,274][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293\repositories}
[2019-06-03T05:58:11,275][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cca293}
[2019-06-03T05:58:11,487][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T05:58:11,487][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T05:58:11,487][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-bd30a6]
[2019-06-03T05:58:11,488][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T05:58:11,488][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T05:58:11,489][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T05:58:11,489][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [ingest-geoip, ingest-attachment, analysis-kuromoji, analysis-icu, analysis-phonetic, mapper-murmur3, analysis-nori]
[2019-06-03T05:58:11,489][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T05:58:11,490][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T05:58:11,490][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T05:58:11,491][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T05:58:11,491][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T05:58:11,491][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T05:58:11,492][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T05:58:11,492][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T05:58:11,493][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T05:58:11,493][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-analysis-icuanalysis-kuromojianalysis-norianalysis-phoneticingest-attachmentingest-geoipmapper-murmur3} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\home]
[2019-06-03T05:58:13,447][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T05:58:13,449][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6}
[2019-06-03T05:58:13,449][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\config}
[2019-06-03T05:58:13,450][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\config]
[2019-06-03T05:58:13,456][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-analysis-icuanalysis-kuromojianalysis-norianalysis-phoneticingest-attachmentingest-geoipmapper-murmur3]
[2019-06-03T05:58:13,456][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\config\analysis]
[2019-06-03T05:58:13,460][INFO ][Managed Elasticsearch    ] [writable-node-475b8d9200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\home\bin\elasticsearch.bat]
[2019-06-03T05:58:13,461][INFO ][Managed Elasticsearch    ] [writable-node-475b8d9200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-bd30a6 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=writable-node-475b8d9200 -E http.port=9200 -E cluster.initial_master_nodes=writable-node-475b8d9200}
[2019-06-03T15:58:23,466][INFO ][o.e.e.NodeEnvironment    ] [writable-node-475b8d9200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T15:58:23,473][INFO ][o.e.e.NodeEnvironment    ] [writable-node-475b8d9200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T15:58:23,530][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] node name [writable-node-475b8d9200], node ID [aD8ZBMgiT-GMWt55eiPy9g]
[2019-06-03T15:58:23,532][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] version[7.0.0], pid[7776], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T15:58:23,535][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T15:58:23,535][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T15:58:41,075][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [aggs-matrix-stats]
[2019-06-03T15:58:41,075][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [analysis-common]
[2019-06-03T15:58:41,076][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [ingest-common]
[2019-06-03T15:58:41,076][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [ingest-geoip]
[2019-06-03T15:58:41,077][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [ingest-user-agent]
[2019-06-03T15:58:41,077][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [lang-expression]
[2019-06-03T15:58:41,078][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [lang-mustache]
[2019-06-03T15:58:41,078][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [lang-painless]
[2019-06-03T15:58:41,078][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [mapper-extras]
[2019-06-03T15:58:41,079][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [parent-join]
[2019-06-03T15:58:41,079][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [percolator]
[2019-06-03T15:58:41,079][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [rank-eval]
[2019-06-03T15:58:41,079][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [reindex]
[2019-06-03T15:58:41,080][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [repository-url]
[2019-06-03T15:58:41,080][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [transport-netty4]
[2019-06-03T15:58:41,080][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-ccr]
[2019-06-03T15:58:41,081][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-core]
[2019-06-03T15:58:41,081][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-deprecation]
[2019-06-03T15:58:41,082][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-graph]
[2019-06-03T15:58:41,082][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-ilm]
[2019-06-03T15:58:41,082][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-logstash]
[2019-06-03T15:58:41,083][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-ml]
[2019-06-03T15:58:41,083][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-monitoring]
[2019-06-03T15:58:41,083][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-rollup]
[2019-06-03T15:58:41,083][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-security]
[2019-06-03T15:58:41,084][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-sql]
[2019-06-03T15:58:41,084][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded module [x-pack-watcher]
[2019-06-03T15:58:41,085][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [analysis-icu]
[2019-06-03T15:58:41,087][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [analysis-kuromoji]
[2019-06-03T15:58:41,088][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [analysis-nori]
[2019-06-03T15:58:41,089][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [analysis-phonetic]
[2019-06-03T15:58:41,090][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [ingest-attachment]
[2019-06-03T15:58:41,092][INFO ][o.e.p.PluginsService     ] [writable-node-475b8d9200] loaded plugin [mapper-murmur3]
[2019-06-03T15:58:47,797][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [writable-node-475b8d9200] [controller/15996] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T15:58:48,620][INFO ][o.e.d.DiscoveryModule    ] [writable-node-475b8d9200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T15:58:50,125][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] initialized
[2019-06-03T15:58:50,126][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] starting ...
[2019-06-03T15:58:51,748][INFO ][o.e.t.TransportService   ] [writable-node-475b8d9200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T15:58:51,755][WARN ][o.e.b.BootstrapChecks    ] [writable-node-475b8d9200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T15:58:51,766][INFO ][o.e.c.c.ClusterBootstrapService] [writable-node-475b8d9200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T15:58:54,772][INFO ][o.e.c.c.Coordinator      ] [writable-node-475b8d9200] setting initial configuration to VotingConfiguration{aD8ZBMgiT-GMWt55eiPy9g}
[2019-06-03T15:58:54,948][INFO ][o.e.c.s.MasterService    ] [writable-node-475b8d9200] elected-as-master ([1] nodes joined)[{writable-node-475b8d9200}{aD8ZBMgiT-GMWt55eiPy9g}{S4vSm_t9TeyBWdGRdGhinQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{writable-node-475b8d9200}{aD8ZBMgiT-GMWt55eiPy9g}{S4vSm_t9TeyBWdGRdGhinQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T15:58:55,026][INFO ][o.e.c.s.ClusterApplierService] [writable-node-475b8d9200] master node changed {previous [], current [{writable-node-475b8d9200}{aD8ZBMgiT-GMWt55eiPy9g}{S4vSm_t9TeyBWdGRdGhinQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T15:58:55,189][INFO ][o.e.g.GatewayService     ] [writable-node-475b8d9200] recovered [0] indices into cluster_state
[2019-06-03T15:58:56,121][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T15:58:56,186][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T15:58:56,260][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T15:58:56,297][INFO ][o.e.h.AbstractHttpServerTransport] [writable-node-475b8d9200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T15:58:56,299][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] started
[2019-06-03T05:58:56,305][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T15:58:56,414][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T15:58:56,547][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T05:58:56,599][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T05:58:56,636][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T05:58:56,644][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T05:58:56,645][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T15:58:56,666][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T15:58:56,728][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T05:58:56,821][INFO ][Managed Elasticsearch    ]  {Call} [http://localhost:9200/_xpack/license?filter_path=license.type&pretty=true] Bad status code: [404]
[2019-06-03T15:58:56,861][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T05:58:56,993][INFO ][Managed Elasticsearch    ]  {Call} [http://localhost:9200/_xpack/license?filter_path=license.type&pretty=true] returned [{ }]
[2019-06-03T05:58:56,994][INFO ][Managed Elasticsearch    ]  {Call} [http://localhost:9200/_xpack/license?filter_path=license.type&pretty=true] returned []
[2019-06-03T15:58:56,998][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [writable-node-475b8d9200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T15:58:57,181][INFO ][o.e.l.LicenseService     ] [writable-node-475b8d9200] license [7301a629-1b1d-48eb-a79f-3781ba7d7a56] mode [basic] - valid
[2019-06-03T05:59:07,073][INFO ][Managed Elasticsearch    ]  {ValidatePluginsTask} validating the cluster is running the requested plugins
[2019-06-03T05:59:07,083][INFO ][Managed Elasticsearch    ]  All good! kicking off [WritableCluster] tests now
[2019-06-03T15:59:07,118][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [writable-node-475b8d9200] failed to delete templates [nest_tests]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [nest_tests] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:59:07,147][INFO ][o.e.c.s.ClusterSettings  ] [writable-node-475b8d9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:59:07,150][INFO ][o.e.c.s.ClusterSettings  ] [writable-node-475b8d9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:59:07,163][INFO ][o.e.c.s.ClusterSettings  ] [writable-node-475b8d9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:59:07,165][INFO ][o.e.c.s.ClusterSettings  ] [writable-node-475b8d9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T15:59:07,256][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest_tests] for index patterns [*]
[2019-06-03T15:59:07,380][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [devs] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:07,551][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [project] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:07,675][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [queries] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:08,085][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[queries][0]] ...]).
[2019-06-03T15:59:08,285][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project/jisCVqF8RIaKO5_yinmsVQ] update_mapping [_doc]
[2019-06-03T15:59:09,354][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project/jisCVqF8RIaKO5_yinmsVQ] update_mapping [_doc]
[2019-06-03T15:59:11,003][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-7c01d4d7] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:11,105][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [977863bf] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:11,238][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-commongramstests-initializer-0661e274] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:11,330][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-snowballtests-fluent-f6babf10] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:11,579][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-7c01d4d7-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:11,762][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluent-7c01d4d7-queries][0]] ...]).
[2019-06-03T15:59:11,794][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-snowballtests-fluent-f6babf10/U1bXWD0eQWO5fZ8LgO0EZg] deleting index
[2019-06-03T15:59:11,900][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-commongramstests-initializer-0661e274/q6kan8KAQjOnFhIFhb-mmQ] deleting index
[2019-06-03T15:59:12,021][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-lowercasetests-fluent-f67f8a94] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:12,118][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [64d3a29c] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:12,304][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [977863bf/RtvMeCYrTKGwi25wmOvQsw] create_mapping [_doc]
[2019-06-03T15:59:12,368][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-lowercasetests-fluent-f67f8a94/8i1tyr8LTEKTcifBUw0E6A] deleting index
[2019-06-03T15:59:12,437][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ad51acd5] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:12,640][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [fluent-8f8f8b0f-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:12,725][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluentasync-ad51acd5][0]] ...]).
[2019-06-03T15:59:12,765][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [fluentasync-9ba94665-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:12,824][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ad51acd5-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:12,891][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [ois-06d796f8-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:12,965][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [64d3a29c/xBzfXTxLRHyEc9PNPf_m0w] create_mapping [_doc]
[2019-06-03T15:59:13,041][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [oisasync-db5b99be-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:13,080][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluentasync-ad51acd5-queries][0]] ...]).
[2019-06-03T15:59:13,215][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [fluent-8f8f8b0f-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:13,319][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-0ebf21b3] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:13,444][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [fluentasync-9ba94665-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:13,536][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [ois-06d796f8-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:13,718][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluent-0ebf21b3][0]] ...]).
[2019-06-03T15:59:13,808][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [oisasync-db5b99be-indextemplate] for index patterns [startingwiththis-*]
[2019-06-03T15:59:13,881][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-0ebf21b3-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:13,984][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] removing template [fluent-8f8f8b0f-indextemplate]
[2019-06-03T15:59:14,032][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] removing template [fluentasync-9ba94665-indextemplate]
[2019-06-03T15:59:14,099][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icucollationtests-fluent-c65c05b6] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:14,278][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] removing template [ois-06d796f8-indextemplate]
[2019-06-03T15:59:14,369][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-e1d948bc] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:14,699][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] removing template [oisasync-db5b99be-indextemplate]
[2019-06-03T15:59:14,748][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icucollationtests-fluent-c65c05b6/96jBXQ52SrqNuJj1NqiV0A] deleting index
[2019-06-03T15:59:14,985][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [writable-node-475b8d9200] failed to delete templates [fluent-8f8f8b0f-indextemplate]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [fluent-8f8f8b0f-indextemplate] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:59:14,990][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializer-e1d948bc][0]] ...]).
[2019-06-03T15:59:15,029][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [writable-node-475b8d9200] failed to delete templates [fluentasync-9ba94665-indextemplate]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [fluentasync-9ba94665-indextemplate] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:59:15,035][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [writable-node-475b8d9200] failed to delete templates [ois-06d796f8-indextemplate]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [ois-06d796f8-indextemplate] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:59:15,049][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-e1d948bc-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:15,138][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [writable-node-475b8d9200] failed to delete templates [oisasync-db5b99be-indextemplate]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [oisasync-db5b99be-indextemplate] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T15:59:15,149][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-mappingtests-fluent-9aea8c64] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:15,446][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test-mappingtests-fluent-9aea8c64][1]] ...]).
[2019-06-03T15:59:15,481][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-uaxtests-initializerasync-03533fe6] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:15,626][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-mappingtests-fluent-9aea8c64/2jKtHITCTX2xektOG-oB5w] deleting index
[2019-06-03T15:59:15,732][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-fa8b88a1] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:15,846][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-chargrouptests-initializerasync-330b03dc] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:15,929][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-uaxtests-initializerasync-03533fe6/c0aNMpuVS7eyRT5l-nWPvA] deleting index
[2019-06-03T15:59:16,056][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-7538cc18] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:16,169][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-chargrouptests-initializerasync-330b03dc/iomOYXuMRUuNJOkA8E-7jQ] deleting index
[2019-06-03T15:59:16,245][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-fa8b88a1-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:16,396][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icutransformtests-initializer-a8150cb1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:16,555][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-7538cc18-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:16,754][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test-icutransformtests-initializer-a8150cb1][0], [nest-initializerasync-7538cc18-queries][0]] ...]).
[2019-06-03T15:59:16,813][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icutransformtests-initializer-a8150cb1/tUBita_ETq2B6O0ZYL_2dg] deleting index
[2019-06-03T15:59:16,986][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-edgengramtests-initializer-f89350b7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:17,088][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-de357b9b] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:17,340][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializer-de357b9b][0]] ...]).
[2019-06-03T15:59:17,376][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-edgengramtests-initializer-f89350b7/n513GWo9SIqwGSsAKj0WJA] deleting index
[2019-06-03T15:59:17,504][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-de357b9b-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:17,921][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializer-de357b9b-queries][0]] ...]).
[2019-06-03T15:59:18,178][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-pathhierarchytests-fluent-4d5cb504] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:18,517][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test-pathhierarchytests-fluent-4d5cb504][0]] ...]).
[2019-06-03T15:59:18,569][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-pathhierarchytests-fluent-4d5cb504/Qjsq4OzXTNCq_r0BscFDAw] deleting index
[2019-06-03T15:59:18,764][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-461844a5] creating index, cause [api], templates [nest_tests], shards [1]/[2], mappings []
[2019-06-03T15:59:18,836][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-46068e09] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:19,036][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-461844a5/Kv21By-XRH2E44_t2Ej1Xw] create_mapping [_doc]
[2019-06-03T15:59:19,174][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-4b1aebc5] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:19,252][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-acab3217] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:19,580][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-uniquetests-initializerasync-7779d0d1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:19,654][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-38a4099f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:19,777][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-4b1aebc5-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T15:59:19,977][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-uniquetests-initializerasync-7779d0d1/dvxf_OGcRa2Eg1CH81QoPA] deleting index
[2019-06-03T15:59:20,067][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-59117240] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:20,205][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-f8636fee] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:20,616][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-b2f05f49] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:20,974][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-66852303] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:21,078][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-keeptypestests-initializer-920a4081] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:21,370][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-57a9f639] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:21,460][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-keeptypestests-initializer-920a4081/N-Nquv33SMaUSowh7tP71A] deleting index
[2019-06-03T15:59:21,613][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [4bbe7ba4] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:21,704][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojitests-fluentasync-f6b798cb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:21,803][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-b2f05f49/1-BS06mxTKGPHxVnyCUiSA] create_mapping [_doc]
[2019-06-03T15:59:21,862][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-66852303/TaNCeT66QoOaWoXrtf-VYg] create_mapping [_doc]
[2019-06-03T15:59:22,032][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-57a9f639/0PWw7mj6QkKP4dD8YBhnWQ] create_mapping [_doc]
[2019-06-03T15:59:22,038][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [4bbe7ba4/DbcGmvoyRZKcuEWFUX1CWA] create_mapping [_doc]
[2019-06-03T15:59:22,113][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojitests-fluentasync-f6b798cb/yv5X_PcjQyecbrnKShz-PA] deleting index
[2019-06-03T15:59:22,223][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-f8636fee/i6xjQAE4T6uwln87BCXxSA] create_mapping [_doc]
[2019-06-03T15:59:22,733][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-dc74079c] creating index, cause [api], templates [nest_tests], shards [1]/[1], mappings []
[2019-06-03T15:59:22,855][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-synonymgraphtests-initializerasync-c541977f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:23,090][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icufoldingtests-initializer-7f229e95] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:23,356][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-synonymgraphtests-initializerasync-c541977f/mXCJ-0dFSZCgbomasYQwUA] deleting index
[2019-06-03T15:59:23,471][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-78c9a273] creating index, cause [api], templates [nest_tests], shards [1]/[1], mappings []
[2019-06-03T15:59:23,598][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icufoldingtests-initializer-7f229e95/v1HbouLJTCSOg5lz76rffw] deleting index
[2019-06-03T15:59:23,812][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [analysis-index] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T15:59:24,065][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-e323fb65] creating index, cause [api], templates [nest_tests], shards [1]/[1], mappings []
[2019-06-03T15:59:24,360][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-f33c35f1] creating index, cause [api], templates [nest_tests], shards [1]/[1], mappings []
[2019-06-03T15:59:24,428][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [analysis-index/nvrp5vIzTpSVyCc3az7wvg]
[2019-06-03T15:59:24,495][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [analysis-index]
[2019-06-03T15:59:24,802][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[analysis-index/nvrp5vIzTpSVyCc3az7wvg]]
[2019-06-03T15:59:25,263][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[analysis-index][0]] ...]).
[2019-06-03T15:59:25,342][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [project-index] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:25,895][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-cd37ff7d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:26,384][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [project-get-task] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:26,575][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-deb1fec1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:26,757][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-worddelimitergraphtests-fluent-47a636d2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:26,821][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-stemmeroverridetests-initializerasync-c5cdef7e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:27,296][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-5d68713f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:27,410][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-stemmeroverridetests-initializerasync-c5cdef7e/5-PKnIqaSPGbKXZscGov0A] deleting index
[2019-06-03T15:59:27,504][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-worddelimitergraphtests-fluent-47a636d2/Tfx9gE5vQx6MO9lzgFo9pw] deleting index
[2019-06-03T15:59:27,626][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-noritests-fluent-62746f8a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:27,703][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-dictionarydecompoundertests-fluent-82d6b71b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:27,857][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-4624423a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:28,061][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-noritests-fluent-62746f8a/oxtG6s49TGaOo0qhrh9qjQ] deleting index
[2019-06-03T15:59:28,158][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-dictionarydecompoundertests-fluent-82d6b71b/U0yIwI-KQGS61gfmadDCaw] deleting index
[2019-06-03T15:59:28,241][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-86b2996f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:28,311][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-7b4cdf13] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:28,455][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-a5367e84] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:28,580][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-get-task/2oexsBaJQSCGI5wPEFwxIg] create_mapping [_doc]
[2019-06-03T15:59:28,585][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-get-task/2oexsBaJQSCGI5wPEFwxIg] update_mapping [_doc]
[2019-06-03T15:59:28,601][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-5d68713f/N587Es6HRd21U_Ij_O7QJA] create_mapping [_doc]
[2019-06-03T15:59:28,697][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-7b4cdf13/DU1_85a3SDGT8VIkyz97Ww] create_mapping [_doc]
[2019-06-03T15:59:28,723][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-deb1fec1/7PsdBSs8S4GqF-LMQn2EZQ] create_mapping [_doc]
[2019-06-03T15:59:28,790][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-feaecef5] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:28,889][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-4624423a/Ni9cCD3ETdWexcvKFGIX8w] create_mapping [_doc]
[2019-06-03T15:59:28,895][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-get-task/2oexsBaJQSCGI5wPEFwxIg] update_mapping [_doc]
[2019-06-03T15:59:28,898][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-get-task/2oexsBaJQSCGI5wPEFwxIg] update_mapping [_doc]
[2019-06-03T15:59:29,046][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-96c42edf] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:29,132][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-90544810] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:29,417][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-cd37ff7d/-hob3UllQZSL4MKTpddcqA] create_mapping [_doc]
[2019-06-03T15:59:29,421][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-96c42edf/zlC-HlnpQhazEpFltN1boQ] create_mapping [_doc]
[2019-06-03T15:59:29,514][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-86b2996f/D-W3gnr-RTKXaTuUUYQovQ] create_mapping [_doc]
[2019-06-03T15:59:29,567][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-f4a3e487] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:29,664][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-289b7bbe] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:29,889][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-get-task/2oexsBaJQSCGI5wPEFwxIg] update_mapping [_doc]
[2019-06-03T15:59:29,895][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-feaecef5/s1E1W2tmSeCl7SMKJ2giSQ] create_mapping [_doc]
[2019-06-03T15:59:29,956][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-19c1da0c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:30,087][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-a5367e84/G95fE7vQRmWGCypXWpY8OQ] create_mapping [_doc]
[2019-06-03T15:59:30,405][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-289b7bbe/cTL8aO3hSO2Un2xWEGd1oQ] create_mapping [_doc]
[2019-06-03T15:59:30,410][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-90544810/uF1LWqcERK6_oXivHhYvVQ] create_mapping [_doc]
[2019-06-03T15:59:30,716][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-712bb81e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:31,021][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-f7cc6e49] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:32,415][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-f6c73351] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:33,038][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-f7cc6e49/xx8NN5ePT7aflkZvlaUo6Q] create_mapping [_doc]
[2019-06-03T15:59:33,555][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-f6c73351/kRvTTzHVRISd0vO0gtyakg] create_mapping [_doc]
[2019-06-03T15:59:33,765][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-19c1da0c/P7N11FsDSE2-cAZ73CGafQ] create_mapping [_doc]
[2019-06-03T15:59:33,881][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-712bb81e/pvy7DSGBTR-_tHlWnNKxAg] create_mapping [_doc]
[2019-06-03T15:59:34,162][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-f4a3e487/D1vR5kRxR8GnkaGZ4bh7KA] create_mapping [_doc]
[2019-06-03T15:59:34,714][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-patternreplacetests-fluent-a9a1476c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:34,911][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [27d8a814] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:35,051][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojitests-fluentasync-63d585a7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:36,280][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-patternreplacetests-fluent-a9a1476c/QEjl2gHVQXS5WDWI9-iiIA] deleting index
[2019-06-03T15:59:36,775][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [tasks-lists-get] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:37,184][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-e4a63018] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:37,393][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojitests-fluentasync-63d585a7/ze99taKZQkSl8uUMCRNYUg] deleting index
[2019-06-03T15:59:38,072][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3badf196] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:38,176][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-5ddf68e9] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:38,521][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-noritests-fluent-d67b80b5] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:38,765][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-19157119] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:38,848][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-d0e2d772] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:39,091][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-noritests-fluent-d67b80b5/JNqHhPlkRKCnY7F7DsAsSw] deleting index
[2019-06-03T15:59:39,234][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-62dfa997] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:39,419][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3964a232] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:39,638][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-d9888925] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:40,174][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-0175023d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:40,276][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-918b6cc8] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:40,495][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [27d8a814/VHlI5blGSAyErtVWmCQNkA] create_mapping [_doc]
[2019-06-03T15:59:40,502][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [tasks-lists-get/Jo2vBQapTyuzXfi78CB_gw] update_mapping [_doc]
[2019-06-03T15:59:40,510][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-d0e2d772/uF3Vg0BMSfSHSn6jfFj11A] create_mapping [_doc]
[2019-06-03T15:59:40,615][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-19157119/s7tmqe4NRmuhkygnDAP49g] create_mapping [_doc]
[2019-06-03T15:59:40,630][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-5ddf68e9/go6CfP2USIyPbotXpdJ8wQ] create_mapping [_doc]
[2019-06-03T15:59:40,687][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-46d39d3a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:42,159][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-whitespacetests-initializerasync-139cf83b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:43,917][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-e3bbf3dc] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T15:59:44,626][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-d9888925/WRypFU8yT5K_M19yDdnwLA] create_mapping [_doc]
[2019-06-03T15:59:44,630][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-62dfa997/HbkqJixuSbyirr3zwqNkig] create_mapping [_doc]
[2019-06-03T15:59:45,576][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-whitespacetests-initializerasync-139cf83b/yf3txRRwRsuLLLqIwVBmFA] deleting index
[2019-06-03T15:59:47,151][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-e4a63018/K6kvOIykRcSAtCZtUjnf5Q] create_mapping [_doc]
[2019-06-03T15:59:47,159][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-0175023d/dO9Gt5saSfCsX5FpctgFCA] create_mapping [_doc]
[2019-06-03T15:59:47,173][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-e3bbf3dc/2JqPPL_GTLCmriEHv0XuiA] update_mapping [_doc]
[2019-06-03T15:59:47,444][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-3badf196/crhnL8hsQ5qKq0HxSLuW0g] create_mapping [_doc]
[2019-06-03T15:59:47,667][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-918b6cc8/JK1kQQWtS5WagO68MtEasg] update_mapping [_doc]
[2019-06-03T15:59:47,776][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-3964a232/DaZA_qPrS5SOiWD1gNqFUQ] update_mapping [_doc]
[2019-06-03T15:59:47,854][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-46d39d3a/8uQNLgOJSWiJ4JSCoWQ2HA] update_mapping [_doc]
[2019-06-03T15:59:48,168][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-22385b5c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:48,345][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-82196caf] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:48,568][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-hyphenationdecompoundertests-initializer-fff55ac5] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:48,692][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-truncatetests-initializerasync-2484f065] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:49,203][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-25bddf27] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:49,250][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-44302604] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:50,518][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-truncatetests-initializerasync-2484f065/QGW-YKTXRs-Xpd1lf1Li-Q] deleting index
[2019-06-03T15:59:50,684][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-hyphenationdecompoundertests-initializer-fff55ac5/_lJmErFlROqednyo-xyAaw] deleting index
[2019-06-03T15:59:50,801][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-e9a4429c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:51,132][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-a244fe68] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:51,428][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-languagetests-fluent-5c09b5f7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:51,764][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-fe0bf51f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:52,174][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-e69f273b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:52,319][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-b0bbe385] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:53,171][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-b6655b57] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:53,435][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-languagetests-fluent-5c09b5f7/fTu3kP2oRGyY1mcw5SHpsQ] deleting index
[2019-06-03T15:59:53,634][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-96b7852d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:53,732][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-e69f273b/FbcmOO-fRImFsjZOnOZZNw] create_mapping [_doc]
[2019-06-03T15:59:54,061][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-e9a4429c/Svq-e0a3T8q75z7h3zQF0w] create_mapping [_doc]
[2019-06-03T15:59:54,065][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-22385b5c/EtzWdtDTTx6sCTfKN26TGw] create_mapping [_doc]
[2019-06-03T15:59:54,264][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-8405a76c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:54,382][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-fe0bf51f/lyfAjjQsS3GMzgplOn5e5Q] create_mapping [_doc]
[2019-06-03T15:59:54,392][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-82196caf/xayR9TPZSuWSRI8hSZWMWA] create_mapping [_doc]
[2019-06-03T15:59:54,580][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-25bddf27/_IEOcTzXTyGLd2fFDq-Lbw] create_mapping [_doc]
[2019-06-03T15:59:54,789][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-44302604/l8IhIKb-TdiwDEkWnrVTbA] create_mapping [_doc]
[2019-06-03T15:59:54,793][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-b6655b57/uhbnZZqZSJWovQVsS7IxHw] create_mapping [_doc]
[2019-06-03T15:59:55,181][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-a244fe68/yvToDsInT5OCz81z2vN_nw] create_mapping [_doc]
[2019-06-03T15:59:55,340][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-96b7852d/kr2kmVT5To-cGbW8bYaGng] create_mapping [_doc]
[2019-06-03T15:59:55,557][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-c9def5f5] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:55,797][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-limittests-fluent-817c4427] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:55,925][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-porterstemtests-initializer-1cc4943c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:57,716][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-limittests-fluent-817c4427/j7AjPpejTr-z7uFpghOi4Q] deleting index
[2019-06-03T15:59:58,061][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-2ffe6e2b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:58,247][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-b0bbe385/lcTXvkbqQnuCO4nqJ2N0HQ] create_mapping [_doc]
[2019-06-03T15:59:58,345][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-porterstemtests-initializer-1cc4943c/Fyrm_uGgS1im9aHzk-PHtg] deleting index
[2019-06-03T15:59:58,527][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-asciifoldingtests-initializer-494f5b06] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:58,699][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-55790479] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:59,281][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-asciifoldingtests-initializer-494f5b06/ZgH584TGT6S1ymIOdDJrDg] deleting index
[2019-06-03T15:59:59,434][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-standardtests-initializerasync-7f21238f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T15:59:59,704][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-73988e44] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:00,188][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-a5fa7353] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:00,510][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-standardtests-initializerasync-7f21238f/doJurb4UQ6KdIdVp1vLy2w] deleting index
[2019-06-03T16:00:00,881][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojipartofspeechtests-initializer-68821951] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:00,981][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-b47ae979] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:01,141][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-8405a76c/ituS0HiPQISl0VEYKpXotA] create_mapping [_doc]
[2019-06-03T16:00:01,431][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-3d581231] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:01,519][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojipartofspeechtests-initializer-68821951/Cah2ATF_ThuimRSFONmZ_Q] deleting index
[2019-06-03T16:00:01,875][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-05c6e0d8-1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:01,973][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-cee5796f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:02,093][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [aliases-index-6eca8982] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:02,467][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-05c6e0d8-2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:02,568][INFO ][o.e.c.m.MetaDataUpdateSettingsService] [writable-node-475b8d9200] updating number_of_replicas to [2] for indices [nest-fluent-a5fa7353]
[2019-06-03T16:00:02,706][INFO ][o.e.c.m.MetaDataUpdateSettingsService] [writable-node-475b8d9200] updating number_of_replicas to [2] for indices [nest-initializer-3d581231]
[2019-06-03T16:00:02,785][INFO ][o.e.c.m.MetaDataUpdateSettingsService] [writable-node-475b8d9200] updating number_of_replicas to [2] for indices [nest-fluentasync-b47ae979]
[2019-06-03T16:00:02,832][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-3f622418-1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:02,910][INFO ][o.e.c.m.MetaDataUpdateSettingsService] [writable-node-475b8d9200] updating number_of_replicas to [2] for indices [nest-initializerasync-cee5796f]
[2019-06-03T16:00:03,107][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [fluent-8bde200f-analysis] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:03,364][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-3f622418-2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:03,543][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-2e6c1c84] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:03,746][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [fluentasync-00764273-analysis] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:03,965][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-c78b6025-1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:04,082][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-b14dbfdf] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:04,311][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-c78b6025-2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:04,549][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [ois-014b5b5e-analysis] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:04,849][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-5a0211a8-1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:05,034][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-d74b61c1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:05,370][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [oisasync-9faa8753-analysis] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:05,771][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-5a0211a8-2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:05,921][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-f16822fc] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:06,093][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-initializerasync-5a0211a8-1/uvLxJ6TzRPyDU1SRQKvI2g] deleting index
[2019-06-03T16:00:06,276][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-fluent-05c6e0d8-1/kDvWB_j-S0ScmNdrjcFT7w] deleting index
[2019-06-03T16:00:06,410][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-ngramtests-initializerasync-8bc48dc0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:06,544][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-fluentasync-3f622418-1/R0wP8pNsQSGoaidGNiQ6EQ] deleting index
[2019-06-03T16:00:06,758][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-initializer-c78b6025-1/7oGK1E8vS4qubskq_3ll_g] deleting index
[2019-06-03T16:00:06,888][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-ngramtests-initializerasync-8bc48dc0/BLYgUleUSBaGQ7ahP_pDFw] deleting index
[2019-06-03T16:00:06,977][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-f16822fc/ZjgIpz24RHmkUKCWwZ0_6Q] create_mapping [_doc]
[2019-06-03T16:00:07,018][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [fluent-8bde200f-analysis/003VEPlZSQ-tpsY6P9epcQ]
[2019-06-03T16:00:07,043][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-e2abc8a6] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:07,137][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-ngramtests-initializerasync-f1076adb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:07,287][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [fluent-8bde200f-analysis]
[2019-06-03T16:00:07,602][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-2c819421] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:07,718][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[fluent-8bde200f-analysis/003VEPlZSQ-tpsY6P9epcQ]]
[2019-06-03T16:00:07,827][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-ngramtests-initializerasync-f1076adb/iQjfMGTmTCWgHjKsm3DOsw] deleting index
[2019-06-03T16:00:08,043][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[fluent-8bde200f-analysis][1], [fluent-8bde200f-analysis][0]] ...]).
[2019-06-03T16:00:08,074][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-simpletests-fluentasync-ce0a3281] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:08,145][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-6fb4b858] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:08,239][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [fluentasync-00764273-analysis/2tP0Eo-0S-ukmo5nFGmqYQ]
[2019-06-03T16:00:08,315][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-simpletests-fluentasync-ce0a3281/gwXeCojlR3-lTjznQHSYBA] deleting index
[2019-06-03T16:00:08,396][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [fluentasync-00764273-analysis]
[2019-06-03T16:00:08,500][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-7d157f75] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:08,758][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-2753e858] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:08,953][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[fluentasync-00764273-analysis/2tP0Eo-0S-ukmo5nFGmqYQ]]
[2019-06-03T16:00:09,087][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-77714742] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:09,285][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [.tasks] creating index, cause [auto(task api)], templates [nest_tests], shards [1]/[0], mappings [task]
[2019-06-03T16:00:09,327][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[fluentasync-00764273-analysis][1], [fluentasync-00764273-analysis][0]] ...]).
[2019-06-03T16:00:09,452][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [ois-014b5b5e-analysis/chaUAGRVQX-vFKCtxZwzeg]
[2019-06-03T16:00:09,483][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-36a8a0c0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:09,582][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [ois-014b5b5e-analysis]
[2019-06-03T16:00:09,698][INFO ][o.e.t.LoggingTaskListener] [writable-node-475b8d9200] 1012 finished with response BulkByScrollResponse[took=30.8s,timed_out=false,sliceId=null,updated=0,created=9108,deleted=0,batches=10,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:00:09,829][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[ois-014b5b5e-analysis/chaUAGRVQX-vFKCtxZwzeg]]
[2019-06-03T16:00:09,895][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-3a8e4999] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:10,037][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ois-014b5b5e-analysis][1], [ois-014b5b5e-analysis][0]] ...]).
[2019-06-03T16:00:10,088][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-d74b61c1/JRHVrkW7TZaarNcjmV3OhA] create_mapping [_doc]
[2019-06-03T16:00:10,092][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-6fb4b858/LcrYnFkDTBeSB_gT6eWeww] create_mapping [_doc]
[2019-06-03T16:00:10,156][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [oisasync-9faa8753-analysis/lmzrqO2ZTeKiUQKG3S6FPw]
[2019-06-03T16:00:10,207][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [oisasync-9faa8753-analysis]
[2019-06-03T16:00:10,254][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-e2abc8a6/71osPdqhRRWqhpsEa-9Piw] create_mapping [_doc]
[2019-06-03T16:00:10,258][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-b14dbfdf/w-u-KyYJTzOKDZtxu905Jw] create_mapping [_doc]
[2019-06-03T16:00:10,263][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-7d157f75/-Llr4PluTVeNRPvhni4Kbw] create_mapping [_doc]
[2019-06-03T16:00:10,477][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-2e6c1c84/DN8ofeuIQbWSCHVAoI8yGg] create_mapping [_doc]
[2019-06-03T16:00:10,481][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-2c819421/exc8isuLSwqmKAlvTNq-6g] create_mapping [_doc]
[2019-06-03T16:00:10,484][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-77714742/dwtvCYduQNaHvugbLH0wwg] create_mapping [_doc]
[2019-06-03T16:00:10,550][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[oisasync-9faa8753-analysis/lmzrqO2ZTeKiUQKG3S6FPw]]
[2019-06-03T16:00:10,675][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-stemmertests-initializerasync-4936a5c0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:10,870][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-2753e858/XojZU3HmTuG11GwFzquDqQ] create_mapping [_doc]
[2019-06-03T16:00:10,874][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-36a8a0c0/TDJnoi7AS263KMHla8svLQ] create_mapping [_doc]
[2019-06-03T16:00:10,984][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[oisasync-9faa8753-analysis][0], [test-stemmertests-initializerasync-4936a5c0][1], [oisasync-9faa8753-analysis][1], [test-stemmertests-initializerasync-4936a5c0][0]] ...]).
[2019-06-03T16:00:11,032][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-stemmertests-initializerasync-4936a5c0/NdINgt40QECceqvJ1Aq4Sw] deleting index
[2019-06-03T16:00:11,149][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-3a8e4999/7o5mc8DLQJOOKWDM7IPbFQ] create_mapping [_doc]
[2019-06-03T16:00:11,299][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-patterntests-fluent-838094dd] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:11,391][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-whitespacetests-initializer-69650016] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:11,713][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-patterntests-fluent-838094dd/vtkgCzN9TtKCexJrsTns5w] deleting index
[2019-06-03T16:00:11,798][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-whitespacetests-initializer-69650016/yERxoef8S0eatDpoZuXxDQ] deleting index
[2019-06-03T16:00:11,897][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-patterntests-fluent-8a8812a6] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,009][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-elisiontests-fluent-1a8b811d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,115][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-delimitedpayloadfiltertests-initializerasync-9c5f5398] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,336][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-patterntests-fluent-8a8812a6/rD6OXIfDTUSdUyAxWf7weQ] deleting index
[2019-06-03T16:00:12,412][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-elisiontests-fluent-1a8b811d/U-eW0gsVRI6xMpHmyGUtQA] deleting index
[2019-06-03T16:00:12,521][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-fluent-8c71f2da] for index patterns [startingwiththis-*]
[2019-06-03T16:00:12,560][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-8534557b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,627][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-delimitedpayloadfiltertests-initializerasync-9c5f5398/Uyw28b-xRXqpIlIVZKkkPA] deleting index
[2019-06-03T16:00:12,712][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-fluentasync-5306b9a8] for index patterns [startingwiththis-*]
[2019-06-03T16:00:12,740][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-731e8dc3] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,845][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-markertests-initializerasync-79d3c291] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:12,942][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-initializer-11accd20] for index patterns [startingwiththis-*]
[2019-06-03T16:00:13,012][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-d2d9bc6d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:13,139][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-initializerasync-ffbc32ec] for index patterns [startingwiththis-*]
[2019-06-03T16:00:13,179][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-markertests-initializerasync-79d3c291/yJqYI72GTD6U9hEe99HueQ] deleting index
[2019-06-03T16:00:13,254][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-d8ec05e2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:13,377][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-noripartofspeechtests-initializer-38b00f63] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:13,555][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-22e35822] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:13,626][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-e5f7908a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:13,887][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-470d3df9] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,054][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-noripartofspeechtests-initializer-38b00f63/JJS8U_9WRrKKLgr7FeWZnA] deleting index
[2019-06-03T16:00:14,185][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-8baf06ba] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,250][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3f20e743] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,365][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-6edc969d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,430][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-292e0f81] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,609][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-d5cd387b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:14,866][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-3392c1d7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,017][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-d2d9bc6d/GcyDZXPQRPStEcwqTvNigQ] create_mapping [_doc]
[2019-06-03T16:00:15,025][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-6edc969d/USrVv5XJReO0oqoB13JQZg] create_mapping [_doc]
[2019-06-03T16:00:15,101][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-6713e050] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,217][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-8baf06ba/JBjIjDMsRvqwAmtP-T8XYQ] create_mapping [_doc]
[2019-06-03T16:00:15,220][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-731e8dc3/AzrLmHR6QHycOPEd57PsLg] create_mapping [_doc]
[2019-06-03T16:00:15,266][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-9cfcaf20] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,375][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-8534557b/w8_IEh3CTwe8GkNqtCSQUQ] create_mapping [_doc]
[2019-06-03T16:00:15,386][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-d8ec05e2/YVjbf55NTyy8HoUfMB5RDQ] create_mapping [_doc]
[2019-06-03T16:00:15,446][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-ed7d90be] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,551][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-470d3df9/Cp9S1884RyiPuFbodX72Iw] create_mapping [_doc]
[2019-06-03T16:00:15,555][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-e5f7908a/iA87K8HaSxqUXGfM0D4bsw] create_mapping [_doc]
[2019-06-03T16:00:15,642][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-ea3db60a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,705][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [6746a6d4] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,909][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ff1ce7d7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:15,968][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-3392c1d7/_8hSFq1DT5CBH9K6wWRJwQ] create_mapping [_doc]
[2019-06-03T16:00:15,972][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-d5cd387b/3BYIyNx0THWAIiWySXJ1Ww] create_mapping [_doc]
[2019-06-03T16:00:15,977][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [6746a6d4/VUl3IplSRBmXfbpBfehQvw] create_mapping [_doc]
[2019-06-03T16:00:16,141][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-9cfcaf20/X5uLa47lR6mmIDL3Zw9gjw] create_mapping [_doc]
[2019-06-03T16:00:16,144][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-3f20e743/Gda6w2SqR1uPDbpyP05b6A] create_mapping [_doc]
[2019-06-03T16:00:16,189][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-b177d05d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:16,252][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [29825ba0] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:16,484][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-80901f67] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:16,559][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-6713e050/D0Xbi4ciRGK1fUlDF3-4mA] create_mapping [_doc]
[2019-06-03T16:00:16,562][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-292e0f81/vohsIC1hSFCCFR4rM1TL2g] create_mapping [_doc]
[2019-06-03T16:00:16,567][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [29825ba0/CuyQ1_0dQrWgYD4TMms7Ag] create_mapping [_doc]
[2019-06-03T16:00:16,701][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-ed7d90be/aeNBGUXhSfi6IX0HniCWmQ] create_mapping [_doc]
[2019-06-03T16:00:16,703][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-22e35822/4mfmEXtmS9az9ZDje-ztAg] create_mapping [_doc]
[2019-06-03T16:00:16,794][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-36b3f903] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:16,879][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-synonymtests-fluentasync-bdb7a917] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:16,983][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-markerwithpatternstests-initializer-6f9d1344] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:17,309][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-0d1e5127] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:17,468][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-synonymtests-fluentasync-bdb7a917/wFPHcaUKTLWLbQ0kYI6vqg] deleting index
[2019-06-03T16:00:17,526][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-a94e71cd] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:17,625][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-markerwithpatternstests-initializer-6f9d1344/Exf3bl5_QTadE9TuQaXZWg] deleting index
[2019-06-03T16:00:17,693][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-edgengramtests-initializer-6c226483] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:17,764][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-f3a7da6e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:17,887][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icutests-initializerasync-57a12bf8] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:18,015][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-8fff8682] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:18,134][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-edgengramtests-initializer-6c226483/9vmoQsKeTqWrWCUTLT73aQ] deleting index
[2019-06-03T16:00:18,257][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-27998038] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:18,328][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-93211c4d] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:18,408][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-c3de1c01] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:18,484][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icutests-initializerasync-57a12bf8/RrsFjcsSSWmxNsef1PrNlQ] deleting index
[2019-06-03T16:00:18,613][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-29ba791e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:18,737][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-93211c4d-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:18,851][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-9ad371fc] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:19,042][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-fluent-29ba791e/lZztELhZTZeABqQCjEkWTQ]
[2019-06-03T16:00:19,075][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-27998038/YcanwAFsRq-4UUDHhZjKJQ] create_mapping [_doc]
[2019-06-03T16:00:19,136][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-fluent-29ba791e]
[2019-06-03T16:00:19,219][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-a60ab6cb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:19,301][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-8725abb7] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:19,426][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-f3a7da6e/88IBjXTtROOXDkGL5I8G7Q] create_mapping [_doc]
[2019-06-03T16:00:19,430][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-a94e71cd/9wqrmexaT6KQaKoaqEgljg] create_mapping [_doc]
[2019-06-03T16:00:19,468][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-fluentasync-a60ab6cb/RWwBhu7cTlKOe0BEb2ZcUQ]
[2019-06-03T16:00:19,525][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-fluentasync-a60ab6cb]
[2019-06-03T16:00:19,559][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-8725abb7-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:19,608][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-2f17afb9] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:19,721][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-c3de1c01/xMR9A9zJRHO-5SRhbVauIg] create_mapping [_doc]
[2019-06-03T16:00:19,728][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-0d1e5127/4ZmVGZdATcGlNumV0zhQIw] create_mapping [_doc]
[2019-06-03T16:00:19,868][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-8fff8682/Un6lcdISQlaSW2Y6F1CuGA] create_mapping [_doc]
[2019-06-03T16:00:19,873][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-36b3f903/K4i_cFhpQ6SQ4KCqFHijeg] create_mapping [_doc]
[2019-06-03T16:00:19,926][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-initializer-2f17afb9/RfhkhdToRmS37z5K4n0SqA]
[2019-06-03T16:00:19,954][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-06af1024] creating index, cause [api], templates [nest_tests], shards [8]/[0], mappings []
[2019-06-03T16:00:20,091][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-initializer-2f17afb9]
[2019-06-03T16:00:20,199][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-3d19820f] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:20,375][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-163d38e0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:20,632][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-3d19820f-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:20,729][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-9ad371fc/6UEBGwLCTKaGLaxbmePC0g] create_mapping [_doc]
[2019-06-03T16:00:20,813][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-initializerasync-163d38e0/ElTdLqWZR7aaWJ8KoUvELg]
[2019-06-03T16:00:20,880][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-standardtests-fluentasync-39603189] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:20,971][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-06af1024-target] creating index, cause [shrink_index], templates [], shards [4]/[1], mappings []
[2019-06-03T16:00:21,081][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-initializerasync-163d38e0]
[2019-06-03T16:00:21,394][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[nest-initializerasync-163d38e0/ElTdLqWZR7aaWJ8KoUvELg]]
[2019-06-03T16:00:21,482][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-standardtests-fluentasync-39603189/v9qOgoSiRQm8-bbRxAhQJQ] deleting index
[2019-06-03T16:00:21,656][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-fb4888fc] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:21,736][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[nest-fluentasync-06af1024-target][2], [nest-fluentasync-06af1024-target][3], [nest-initializerasync-163d38e0][1], [nest-initializerasync-163d38e0][0]] ...]).
[2019-06-03T16:00:21,812][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-keepwordstests-initializerasync-4f5e0a79] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:21,890][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[nest-fluent-29ba791e/lZztELhZTZeABqQCjEkWTQ]]
[2019-06-03T16:00:21,960][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-401ee1b0] creating index, cause [api], templates [nest_tests], shards [8]/[0], mappings []
[2019-06-03T16:00:22,184][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[nest-fluent-29ba791e][0], [nest-fluent-29ba791e][1]] ...]).
[2019-06-03T16:00:22,269][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-keepwordstests-initializerasync-4f5e0a79/MDUMWWFjSDKVvoy50gmvPw] deleting index
[2019-06-03T16:00:22,357][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-fb4888fc-queries] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:00:22,600][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[nest-initializer-2f17afb9/RfhkhdToRmS37z5K4n0SqA]]
[2019-06-03T16:00:22,661][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-59eb5e06] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:23,128][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[nest-initializer-2f17afb9][0], [nest-initializer-2f17afb9][1]] ...]).
[2019-06-03T16:00:23,403][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[nest-fluentasync-a60ab6cb/RWwBhu7cTlKOe0BEb2ZcUQ]]
[2019-06-03T16:00:23,481][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-75ccbe1f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:23,787][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[nest-fluentasync-a60ab6cb][1], [nest-fluentasync-a60ab6cb][0]] ...]).
[2019-06-03T16:00:23,884][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-b9c09cb8] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:24,001][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-401ee1b0-target] creating index, cause [shrink_index], templates [], shards [4]/[1], mappings []
[2019-06-03T16:00:24,071][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-595d76d5] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:24,369][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-364520dc] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:24,651][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-fe18838f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:24,774][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-24ad1a5c] creating index, cause [api], templates [nest_tests], shards [8]/[0], mappings []
[2019-06-03T16:00:25,097][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-57318021] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:25,380][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-d958bdc1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:25,767][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-7d43c0b1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:26,106][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-66b14c63] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:26,463][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-24ad1a5c-target] creating index, cause [shrink_index], templates [], shards [4]/[1], mappings []
[2019-06-03T16:00:26,568][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-425bff49] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:26,798][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-7faf5a4c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:27,039][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-984ca269] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:27,106][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-45eecd66] creating index, cause [api], templates [nest_tests], shards [8]/[0], mappings []
[2019-06-03T16:00:27,205][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-fda1144f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:27,440][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-c207fe08] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:27,677][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-noriwithuserdictionarytests-initializer-af5943fe] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:27,925][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-c9b5c0f4] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:28,097][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-noriwithuserdictionarytests-initializer-af5943fe/HAb0OJ0zQ3yRvaKa_mRHww] deleting index
[2019-06-03T16:00:28,315][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-45eecd66-target] creating index, cause [shrink_index], templates [], shards [4]/[1], mappings []
[2019-06-03T16:00:28,521][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-7d43c0b1/EtczkapOQ1K7i9yFlIakkg] create_mapping [_doc]
[2019-06-03T16:00:28,525][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-425bff49/B69TWR6nTuWre8R7beGwug] create_mapping [_doc]
[2019-06-03T16:00:28,768][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-57318021/jfoXFssHRVyZUWbeHOVR8Q] create_mapping [_doc]
[2019-06-03T16:00:28,772][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-984ca269/YZBWlLsdSIKH6zMghoAr8w] create_mapping [_doc]
[2019-06-03T16:00:28,837][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [alias-index-cea3baa4-1] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:28,905][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-c9b5c0f4/hJOttgr8QeCohBGQynzc9w] create_mapping [_doc]
[2019-06-03T16:00:28,909][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-b9c09cb8/CKY5bNLrQ0O7IH3S7oVGmQ] create_mapping [_doc]
[2019-06-03T16:00:29,029][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-c207fe08/uzXtyPYAQLitj8N_VLTD8Q] create_mapping [_doc]
[2019-06-03T16:00:29,034][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-364520dc/cWXtS_xFRe2VgfY8WyzLAA] create_mapping [_doc]
[2019-06-03T16:00:29,091][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [alias-index-cea3baa4-2] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:29,156][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-2992fb7a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:29,270][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-6d519396] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:29,549][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [alias-index-cea3baa4-3] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:29,628][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-3d5e0ecd] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:29,905][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-1e06402e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,065][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-patterncapturetests-initializerasync-2083bffb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,178][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-bc5f38a7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,364][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-5ce7331e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,441][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-patterncapturetests-initializerasync-2083bffb/yribx3lQTiKOOK44ndLCDQ] deleting index
[2019-06-03T16:00:30,591][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-531282e8] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,665][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-26d0c061] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:30,777][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-bc474748] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:31,002][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-11947e13] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:31,147][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-2af524b1] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:31,225][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-fluentasync-1e06402e/jk2j_pztQS--P80CHpU80A]
[2019-06-03T16:00:31,337][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-fluentasync-1e06402e]
[2019-06-03T16:00:31,406][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-b4461317] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:31,496][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-fluent-6d519396/3WXpBUtHSj2-WlnEq3qlrg]
[2019-06-03T16:00:31,523][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-3d5e0ecd/UOKW5dDGS8Wa91Q3cy-eZg] create_mapping [_doc]
[2019-06-03T16:00:31,529][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-2af524b1/GG0D_7BkTHiw3c3jiYtIcQ] create_mapping [_doc]
[2019-06-03T16:00:31,655][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-fluent-6d519396]
[2019-06-03T16:00:31,733][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-initializer-5ce7331e/xzfKeI_CTMuNNXtxmOT5TQ]
[2019-06-03T16:00:31,759][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-7669fbf1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:31,855][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-initializer-5ce7331e]
[2019-06-03T16:00:31,931][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-2992fb7a/yitmTojEQUiEtegNnUbyIg] create_mapping [_doc]
[2019-06-03T16:00:31,980][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [nest-initializerasync-bc474748/gCCiWjV7QRqDBgH3f693Qg]
[2019-06-03T16:00:32,051][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [nest-initializerasync-bc474748]
[2019-06-03T16:00:32,146][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-lengthtests-fluentasync-78ab61a0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:32,291][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-26d0c061/cDw0O4NiSrGa5bZXDZCHBQ] create_mapping [_doc]
[2019-06-03T16:00:32,296][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-2af524b1/GG0D_7BkTHiw3c3jiYtIcQ] update_mapping [_doc]
[2019-06-03T16:00:32,475][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-lengthtests-fluentasync-78ab61a0/yUY5b-DdTwKl3nCItrcjLQ] deleting index
[2019-06-03T16:00:32,535][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-conditiontests-fluent-5e67c375] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:32,612][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [project-with-no-source] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:00:32,842][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-conditiontests-fluent-5e67c375/Xti1gdI_Qc-yy-rBawqlRA] deleting index
[2019-06-03T16:00:32,905][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-bc5f38a7/QvQDnTXoTamBZ3rw1BkJiA] create_mapping [_doc]
[2019-06-03T16:00:32,909][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [project-with-no-source/CAgByKyLSpuACByUAuvcqA] update_mapping [_doc]
[2019-06-03T16:00:32,958][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [034eb3b7] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:33,034][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-c728a683] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:33,162][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icunormalizertests-fluent-3622070b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:33,367][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [034eb3b7/r41L6HsaTF6CATT12Oprwg] create_mapping [_doc]
[2019-06-03T16:00:33,503][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-c728a683/MUW4U8IZSWKfT59xnb42Tg] create_mapping [_doc]
[2019-06-03T16:00:33,554][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icunormalizertests-fluent-3622070b/I3R8CWWMRa6QDaJrE1P00Q] deleting index
[2019-06-03T16:00:33,670][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-f4be7de0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:33,785][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojistemmertests-initializer-7038ece7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:34,130][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-2709e2e3] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:34,219][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ef6cd5df] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:34,337][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojistemmertests-initializer-7038ece7/7aWvJmBNQuOjJEYAjpxDCw] deleting index
[2019-06-03T16:00:34,482][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-6a863aa5] creating index, cause [api], templates [nest_tests], shards [4]/[0], mappings []
[2019-06-03T16:00:34,610][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-a98de975] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:34,705][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-e7dc732f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:35,066][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-6a863aa5-target] creating index, cause [split_index], templates [], shards [8]/[1], mappings []
[2019-06-03T16:00:35,388][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-881001b7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:35,464][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-f2fb6f96] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:36,086][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-c728a683/MUW4U8IZSWKfT59xnb42Tg] update_mapping [_doc]
[2019-06-03T16:00:36,134][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-2312be44] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:36,340][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-2d5b3e0e] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:36,466][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3c8ce3f1] creating index, cause [api], templates [nest_tests], shards [4]/[0], mappings []
[2019-06-03T16:00:36,737][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-0638caca] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:36,852][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-a98de975/MVf02S4cTda9add0hjMFDA] create_mapping [_doc]
[2019-06-03T16:00:37,002][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-4b8672f2] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:37,078][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3c8ce3f1-target] creating index, cause [split_index], templates [], shards [8]/[1], mappings []
[2019-06-03T16:00:37,228][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-0436a8d6] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:37,724][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-c5e7e66c] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings []
[2019-06-03T16:00:37,920][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-2709e2e3/auOO-34jSX-vfQiUMqv9pg] create_mapping [_doc]
[2019-06-03T16:00:37,924][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-4b8672f2/OcF--6Y4QPSuH7EBDDeaqA] create_mapping [_doc]
[2019-06-03T16:00:38,072][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-stoptests-fluentasync-d2554c9a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:38,146][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-911bbdb8] creating index, cause [api], templates [nest_tests], shards [4]/[0], mappings []
[2019-06-03T16:00:38,408][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-stoptests-fluentasync-d2554c9a/57XpzsLxQrWMszXibzCDfQ] deleting index
[2019-06-03T16:00:38,531][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icutests-initializer-c6e1c652] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:38,780][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-881001b7/EaBSQ_zESX6p7yPnVHqLIw] create_mapping [_doc]
[2019-06-03T16:00:38,854][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-911bbdb8-target] creating index, cause [split_index], templates [], shards [8]/[1], mappings []
[2019-06-03T16:00:39,698][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icutests-initializer-c6e1c652/rtarGHRSSiGVsW7w9xqyVg] deleting index
[2019-06-03T16:00:40,062][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-uppercasetests-fluentasync-8261a191] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:40,583][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-2312be44/LAwNj3igTbenD2jxcOH_Ag] create_mapping [_doc]
[2019-06-03T16:00:40,589][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-4b8672f2/OcF--6Y4QPSuH7EBDDeaqA] update_mapping [_doc]
[2019-06-03T16:00:40,786][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-f1364c11] creating index, cause [api], templates [nest_tests], shards [4]/[0], mappings []
[2019-06-03T16:00:41,105][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-reversetests-fluentasync-189ab4ed] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:41,318][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-uppercasetests-fluentasync-8261a191/v6HH4-G1QxmOC8g4jcOPUA] deleting index
[2019-06-03T16:00:41,547][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-reversetests-fluentasync-189ab4ed/PsxSJroZTCqf44gHJ0lWZg] deleting index
[2019-06-03T16:00:41,711][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-0648f485] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:41,827][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-fluentasync-27bc08cc] for index patterns [nestx-*]
[2019-06-03T16:00:41,905][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-f1364c11-target] creating index, cause [split_index], templates [], shards [8]/[1], mappings []
[2019-06-03T16:00:42,032][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-fluent-5c9df9d1] for index patterns [nestx-*]
[2019-06-03T16:00:42,302][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-c86ba45f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:00:42,439][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-initializer-aef3ee6d] for index patterns [nestx-*]
[2019-06-03T16:00:42,868][INFO ][o.e.c.m.MetaDataIndexTemplateService] [writable-node-475b8d9200] adding template [nest-initializerasync-5c14355f] for index patterns [nestx-*]
[2019-06-03T16:00:43,130][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-5f3fd3d2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:43,609][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojireadingformtests-fluentasync-d060b79b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:44,140][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-345c8028] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:44,255][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojireadingformtests-fluentasync-d060b79b/TCmX_48GQeKHw0vnPjzv7Q] deleting index
[2019-06-03T16:00:44,509][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-0648f485/l2xctmCxR-iyti4gv_vFQA] create_mapping [_doc]
[2019-06-03T16:00:44,575][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-a22af33c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:44,692][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-e55f10a4] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:45,192][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-ac14d3f7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:45,394][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-multiplexertests-fluent-22c8fecd] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:45,543][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-b719ebb1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:45,934][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-multiplexertests-fluent-22c8fecd/Kwu5O9kwTFW3a20L3POmRw] deleting index
[2019-06-03T16:00:46,253][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-c8b16d01] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:46,502][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-patternreplacetests-initializer-a2e7b824] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:46,845][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-0648f485/l2xctmCxR-iyti4gv_vFQA] update_mapping [_doc]
[2019-06-03T16:00:47,036][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-896961ea] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:47,341][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [fluent-8bde200f-analysiswithnormalizer] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:47,588][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-patternreplacetests-initializer-a2e7b824/vx2EFAzEQNOCk25wa5lRXg] deleting index
[2019-06-03T16:00:47,785][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-icunormalizertests-fluent-5f5d9c35] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:47,990][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [fluentasync-00764273-analysiswithnormalizer] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:48,303][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-896961ea/2ibgS74nQw-F5o4u5VGgKw] create_mapping [_doc]
[2019-06-03T16:00:48,409][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-icunormalizertests-fluent-5f5d9c35/m9R4ypG7SuiOhSWzSk0LDA] deleting index
Failed   Tests.Document.Multiple.Bulk.BulkApiTests.ReturnsExpectedResponse
Error Message:
 Tests.Framework.EndpointTests.ResponseAssertionException : Object reference not set to an instance of an object.
Response Under Test:
Valid NEST response built from a successful low level call on POST: /nest-fluentasync-2af524b1/_bulk?pretty=true&error_trace=true&pipeline=default-pipeline
# Audit trail of this API call:
 - [1] HealthyResponse: Node: http://localhost:9200/ Took: 00:00:01.9410593
# Request:
{"index":{"_id":"Kub and Sons2000","routing":"Kub and Sons2000","pipeline":"pipeline"}}
{"dateString":"2015-01-01T00:00:00.0000000+11:00","join":"project","lastActivity":"0001-01-01T00:00:00","leadDeveloper":{"gender":"Male","firstName":"Martijn","id":0,"lastName":"Laarman"},"location":{"lat":42.1523,"lon":-80.321},"name":"Kub and Sons2000","numberOfContributors":0,"sourceOnly":{"notWrittenByDefaultSerializer":"written"},"startedOn":"2015-01-01T00:00:00","state":"BellyUp","type":"project","visibility":"Public"}
{"update":{"_id":"Kub and Sons2000"}}
{"doc":{"leadDeveloper":{"firstName":"martijn"}}}
{"create":{"_id":"Kub and Sons20001","routing":"Kub and Sons2000"}}
{"dateString":"2015-01-01T00:00:00.0000000+11:00","join":"project","lastActivity":"0001-01-01T00:00:00","leadDeveloper":{"gender":"Male","firstName":"Martijn","id":0,"lastName":"Laarman"},"location":{"lat":42.1523,"lon":-80.321},"name":"Kub and Sons2000","numberOfContributors":0,"sourceOnly":{"notWrittenByDefaultSerializer":"written"},"startedOn":"2015-01-01T00:00:00","state":"BellyUp","type":"project","visibility":"Public"}
{"delete":{"_id":"Kub and Sons20001","routing":"Kub and Sons2000"}}
{"create":{"_id":"Kub and Sons20002","routing":"Kub and Sons2000"}}
{"dateString":"2015-01-01T00:00:00.0000000+11:00","join":"project","lastActivity":"0001-01-01T00:00:00","leadDeveloper":{"gender":"Male","firstName":"Martijn","id":0,"lastName":"Laarman"},"location":{"lat":42.1523,"lon":-80.321},"name":"Kub and Sons2000","numberOfContributors":0,"sourceOnly":{"notWrittenByDefaultSerializer":"written"},"startedOn":"2015-01-01T00:00:00","state":"BellyUp","type":"project","visibility":"Public"}
{"update":{"_id":"Kub and Sons20002","routing":"Kub and Sons2000"}}
{"script":{"source":"ctx._source.numberOfCommits = params.commits","lang":"painless","params":{"commits":30}}}

# Response:
{
  "took" : 1882,
  "ingest_took" : 4,
  "errors" : false,
  "items" : [
    {
      "index" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons2000",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 0,
        "_primary_term" : 1,
        "status" : 201
      }
    },
    {
      "update" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons2000",
        "_version" : 2,
        "result" : "updated",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 1,
        "_primary_term" : 1,
        "status" : 200
      }
    },
    {
      "create" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons20001",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 2,
        "_primary_term" : 1,
        "status" : 201
      }
    },
    {
      "delete" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons20001",
        "_version" : 2,
        "result" : "deleted",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 3,
        "_primary_term" : 1,
        "status" : 200
      }
    },
    {
      "create" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons20002",
        "_version" : 1,
        "result" : "created",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 4,
        "_primary_term" : 1,
        "status" : 201
      }
    },
    {
      "update" : {
        "_index" : "nest-fluentasync-2af524b1",
        "_type" : "_doc",
        "_id" : "Kub and Sons20002",
        "_version" : 2,
        "result" : "updated",
        "_shards" : {
          "total" : 1,
          "successful" : 1,
          "failed" : 0
        },
        "_seq_no" : 5,
        "_primary_term" : 1,
        "status" : 200
      }
    }
  ]
}


---- System.NullReferenceException : Object reference not set to an instance of an object.
Stack Trace:
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void Tests.Document.Multiple.Bulk.BulkApiTests.ExpectResponse(BulkResponse response) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Document/Multiple/Bulk/BulkApiTests.cs:line 158
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
[2019-06-03T16:00:48,598][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-3b2ddc74] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:48,724][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-trimtests-initializerasync-88060d1d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:48,959][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [ois-014b5b5e-analysiswithnormalizer] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:49,354][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-a0eadea2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:49,564][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-trimtests-initializerasync-88060d1d/dSVqE5NWTISlE55yKYdhJA] deleting index
[2019-06-03T16:00:49,823][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-customtests-initializerasync-d0dfbe05] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:49,962][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-b36b1e70] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:50,350][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [oisasync-9faa8753-analysiswithnormalizer] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:50,673][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-customtests-initializerasync-d0dfbe05/TECvpRcqS_aFi69gXI5geQ] deleting index
[2019-06-03T16:00:50,839][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-3fef9f6f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:51,026][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-839f5522] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:51,189][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [fluent-8bde200f-analysiswithnormalizer/ePckMnx0SJamBRUSA0aCbA]
[2019-06-03T16:00:51,307][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [fluent-8bde200f-analysiswithnormalizer]
[2019-06-03T16:00:51,658][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ec9076e6] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:51,753][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[fluent-8bde200f-analysiswithnormalizer/ePckMnx0SJamBRUSA0aCbA]]
[2019-06-03T16:00:52,056][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-b719ebb1/M2P5TJi7TmyeKdGJpMrR7w] create_mapping [_doc]
[2019-06-03T16:00:52,060][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-3fef9f6f/6EmRiKdFSIyXmNPU7KMYMQ] create_mapping [_doc]
[2019-06-03T16:00:52,123][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-4cff9766] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:52,244][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[fluent-8bde200f-analysiswithnormalizer][1], [fluent-8bde200f-analysiswithnormalizer][0]] ...]).
[2019-06-03T16:00:52,460][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [fluentasync-00764273-analysiswithnormalizer/gdEE9txWSKi4--7Lc-NvxA]
[2019-06-03T16:00:52,503][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-03d29f27] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:52,605][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [fluentasync-00764273-analysiswithnormalizer]
[2019-06-03T16:00:53,046][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[fluentasync-00764273-analysiswithnormalizer/gdEE9txWSKi4--7Lc-NvxA]]
[2019-06-03T16:00:53,154][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-e55f10a4/vA4vRT6kRVKsjHaac-X0jg] create_mapping [_doc]
[2019-06-03T16:00:53,158][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-3b2ddc74/Jm9K_7LqTEGsesOqQ3cF9A] create_mapping [_doc]
[2019-06-03T16:00:53,161][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-ec9076e6/ogkRYzBETEKzj_cDw0QDWw] create_mapping [_doc]
[2019-06-03T16:00:53,383][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-a0eadea2/pt12qLpJQpOT2vNEEdeX2w] create_mapping [_doc]
[2019-06-03T16:00:53,387][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-c8b16d01/yLUIkQVdQL6uzzibs_BEyQ] create_mapping [_doc]
[2019-06-03T16:00:53,392][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-03d29f27/GytYu7hTTNyeFjUZWNlA5w] create_mapping [_doc]
[2019-06-03T16:00:53,498][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[fluentasync-00764273-analysiswithnormalizer][1], [fluentasync-00764273-analysiswithnormalizer][0]] ...]).
[2019-06-03T16:00:53,550][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-customtests-fluentasync-6fe31dc9] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:53,652][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [ois-014b5b5e-analysiswithnormalizer/-VQ4r70ZS2OqOz8-3VMbTg]
[2019-06-03T16:00:53,689][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-b36b1e70/550aA_sDSyG-Hvtik8nqoQ] create_mapping [_doc]
[2019-06-03T16:00:53,693][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-4cff9766/KIOCgbFBRXOBnKTJzLJu5w] create_mapping [_doc]
[2019-06-03T16:00:53,834][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [ois-014b5b5e-analysiswithnormalizer]
[2019-06-03T16:00:53,973][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-hunspelltests-initializerasync-487b01de] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:54,390][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-customtests-fluentasync-6fe31dc9/YpXtk3gcT26n_G1NpLYAnw] deleting index
[2019-06-03T16:00:54,641][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[ois-014b5b5e-analysiswithnormalizer/-VQ4r70ZS2OqOz8-3VMbTg]]
[2019-06-03T16:00:54,885][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-hunspelltests-initializerasync-487b01de/gPAo1W7FSse5UmgTijzNiQ] deleting index
[2019-06-03T16:00:55,259][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-aec4f4af] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:55,378][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ois-014b5b5e-analysiswithnormalizer][1], [ois-014b5b5e-analysiswithnormalizer][0]] ...]).
[2019-06-03T16:00:55,430][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [6943a71f] creating index, cause [api], templates [nest_tests], shards [3]/[0], mappings []
[2019-06-03T16:00:55,552][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] closing indices [oisasync-9faa8753-analysiswithnormalizer/7OQZp0caRju244hb6FYMBA]
[2019-06-03T16:00:55,896][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] completed closing of indices [oisasync-9faa8753-analysiswithnormalizer]
[2019-06-03T16:00:56,289][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-2619606a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:56,793][INFO ][o.e.c.m.MetaDataIndexStateService] [writable-node-475b8d9200] opening indices [[oisasync-9faa8753-analysiswithnormalizer/7OQZp0caRju244hb6FYMBA]]
[2019-06-03T16:00:57,007][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-0f410078] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:57,305][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-839f5522/wohBA7cTQwmeurQhsQMFcw] create_mapping [_doc]
[2019-06-03T16:00:57,436][INFO ][o.e.c.r.a.AllocationService] [writable-node-475b8d9200] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[oisasync-9faa8753-analysiswithnormalizer][1], [oisasync-9faa8753-analysiswithnormalizer][0]] ...]).
[2019-06-03T16:00:57,779][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-4cb8f811] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:57,899][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-93de1328] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:58,082][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-stoptests-initializerasync-53d6c1bd] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:58,708][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-acd8c89f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:58,835][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-stoptests-initializerasync-53d6c1bd/o2zZ79ZWT0OrDV8zEPknyw] deleting index
[2019-06-03T16:00:59,034][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-2619606a/GFdCu0G3Q9i7mo7is9BvxQ] create_mapping [_doc]
[2019-06-03T16:00:59,105][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-0f410078/ZVyofl-AR422GYUnLR0vsA] create_mapping [_doc]
[2019-06-03T16:00:59,369][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-aec4f4af/aN_DGol7S_e-i5pbsDlsUA] create_mapping [_doc]
[2019-06-03T16:00:59,425][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-975cb87a] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:00:59,537][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-4cb8f811/aUWxTKS1QHqX93x5oSX_pA] create_mapping [_doc]
[2019-06-03T16:00:59,836][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-2bbb10c1] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:00,345][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-975cb87a/6JDGJO9ES3-oVBr276scOg] create_mapping [_doc]
[2019-06-03T16:01:00,409][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-2bbb10c1/kMrtQ-_fQkOh0chOck6D_g] create_mapping [_doc]
[2019-06-03T16:01:00,602][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-93de1328/UbZuYty-QcWRCqwJh_ms0A] create_mapping [_doc]
[2019-06-03T16:01:00,669][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-acd8c89f/Jo3SiMFTQC6h0lyfZOAP1w] create_mapping [_doc]
[2019-06-03T16:01:01,107][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-removeduplicatestests-fluent-5c9cd194] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:01,493][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-removeduplicatestests-fluent-5c9cd194/_CG-tmh4S4ujcz0t3v-lcg] deleting index
[2019-06-03T16:01:02,014][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-f648fce4] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:02,169][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kstemtests-initializerasync-52ad817c] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:02,562][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-5e814d8d] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:02,723][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kstemtests-initializerasync-52ad817c/92C7s4DrT-2sE9VWIdUZgQ] deleting index
[2019-06-03T16:01:03,455][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-33b8dc1e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:04,148][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-ea2448e2] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:04,579][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-kuromojiiterationmarktests-initializer-a1c82a8f] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:04,778][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-initializerasync-ea2448e2/WfDtkaOzTjy03RzjXCQ7cw] deleting index
[2019-06-03T16:01:04,972][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-htmlstriptests-initializer-0c928a70] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:05,205][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-fluent-f648fce4/l-OvITT0SNCkM9mQbavZMg] deleting index
[2019-06-03T16:01:05,399][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-kuromojiiterationmarktests-initializer-a1c82a8f/aNNirqdDSeuaq-SlEssQOg] deleting index
[2019-06-03T16:01:05,610][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-initializer-33b8dc1e/Yb-2uVCDRx27LEce90Dnpg] deleting index
[2019-06-03T16:01:05,721][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-htmlstriptests-initializer-0c928a70/CV3oZ0v4Q56RZBJYDo4OJg] deleting index
[2019-06-03T16:01:05,844][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [nest-fluentasync-5e814d8d/HM7hBl_NSoK5H-y05VQwzA] deleting index
[2019-06-03T16:01:06,010][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-worddelimitertests-initializer-7e6a4bcb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:06,388][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-worddelimitertests-initializer-7e6a4bcb/eb1YoLeeRT-sF0Tz9VHWyA] deleting index
[2019-06-03T16:01:06,664][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-predicatetests-fluent-40a0ced0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:07,147][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-predicatetests-fluent-40a0ced0/_OnKTpi7R7uparQJFN8c3A] deleting index
[2019-06-03T16:01:07,324][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-fingerprinttests-fluent-3a11f46b] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:07,860][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-fingerprinttests-fluent-3a11f46b/akuQH9O8SqayAqol0EOPZw] deleting index
[2019-06-03T16:01:08,108][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluent-23b8a488] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:08,606][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-fluentasync-ef673f11] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:09,162][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializer-2fbf1e74] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:09,718][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [nest-initializerasync-9002a3f0] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:10,299][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializer-2fbf1e74/YeZ19cdXQeSrPK1f6-2GpA] create_mapping [_doc]
[2019-06-03T16:01:10,375][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluentasync-ef673f11/VZ2to88NShW3npbSR7SLWQ] create_mapping [_doc]
[2019-06-03T16:01:10,435][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-fluent-23b8a488/0IH_ATcUS5SOrlN6TFbtPg] create_mapping [_doc]
[2019-06-03T16:01:10,493][INFO ][o.e.c.m.MetaDataMappingService] [writable-node-475b8d9200] [nest-initializerasync-9002a3f0/x63bXO3ASLK-6g2JnoScBQ] create_mapping [_doc]
[2019-06-03T16:01:10,587][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-phonetictests-fluentasync-ca0a5830] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:10,735][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-keywordtests-initializer-c79e04b7] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:11,117][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-phonetictests-fluentasync-ca0a5830/B8H691N-QgmfLNfNrNRxng] deleting index
[2019-06-03T16:01:11,222][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-keywordtests-initializer-c79e04b7/flSTf7OWQNyBQBePaZhGfg] deleting index
[2019-06-03T16:01:11,332][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-shingletests-initializerasync-fa6a8686] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:11,452][INFO ][o.e.c.m.MetaDataCreateIndexService] [writable-node-475b8d9200] [test-snowballtests-fluentasync-a1000554] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:01:11,636][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-shingletests-initializerasync-fa6a8686/3rs6p4YCSnaoTx2ZZe-AQg] deleting index
[2019-06-03T16:01:11,815][INFO ][o.e.c.m.MetaDataDeleteIndexService] [writable-node-475b8d9200] [test-snowballtests-fluentasync-a1000554/1xinRCIhQHy7VxqIrXUbJA] deleting index
[2019-06-03T16:01:12,178][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] stopping ...
[2019-06-03T16:01:12,191][INFO ][o.e.x.w.WatcherService   ] [writable-node-475b8d9200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:01:12,537][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [writable-node-475b8d9200] [controller/15996] [Main.cc@148] Ml controller exiting
[2019-06-03T16:01:12,540][INFO ][o.e.x.m.p.NativeController] [writable-node-475b8d9200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:01:12,580][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluentasync-ad51acd5][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,636][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-c86ba45f][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,596][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-8534557b][1] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,596][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-8534557b][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:14,397][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] stopped
[2019-06-03T16:01:14,488][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] closing ...
[2019-06-03T16:01:13,477][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-0ebf21b3][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:13,199][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-5f3fd3d2][1] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:13,198][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-5f3fd3d2][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:13,124][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluentasync-d2d9bc6d][1] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:13,124][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluentasync-d2d9bc6d][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,843][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-731e8dc3][1] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,826][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-731e8dc3][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:12,649][WARN ][o.e.i.s.RetentionLeaseSyncAction] [writable-node-475b8d9200] [nest-fluent-c86ba45f][1] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [writable-node-475b8d9200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:01:14,828][INFO ][o.e.n.Node               ] [writable-node-475b8d9200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:01:15,144][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\data}
[2019-06-03T06:01:17,231][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\config}
[2019-06-03T06:01:17,235][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\logs}
[2019-06-03T06:01:17,238][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6\repositories}
[2019-06-03T06:01:17,239][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bd30a6}
[2019-06-03T06:01:17,477][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [Security|XPack|SSL]
[2019-06-03T06:01:17,478][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:01:17,479][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-ebc0cb]
[2019-06-03T06:01:17,479][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [True]
[2019-06-03T06:01:17,480][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [True]
[2019-06-03T06:01:17,480][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:01:17,481][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [x-pack]
[2019-06-03T06:01:17,481][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [Trial]
[2019-06-03T06:01:17,482][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:01:17,482][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:01:17,483][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:01:17,484][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:01:17,484][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:01:17,485][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:01:17,485][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:01:17,486][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:01:17,487][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home]
[2019-06-03T06:01:19,928][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:01:19,929][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb}
[2019-06-03T06:01:19,929][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config}
[2019-06-03T06:01:19,931][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config]
[2019-06-03T06:01:19,941][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} attempting to add xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\elasticsearch.yml]
[2019-06-03T06:01:19,945][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} saved xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\elasticsearch.yml]
[2019-06-03T06:01:19,948][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} adding roles to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\roles.yml
[2019-06-03T06:01:19,951][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} saved roles to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\roles.yml]
[2019-06-03T06:01:19,952][INFO ][Managed Elasticsearch    ]  {EnsureSecurityUsersInDefaultRealmAreAdded} using cached users and users_roles files from {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\config}
[2019-06-03T06:01:19,957][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} creating config files
[2019-06-03T06:01:19,959][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\node-certificates.zip
[2019-06-03T06:01:19,961][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates
[2019-06-03T06:01:19,979][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\unused-node-certificates.zip
[2019-06-03T06:01:19,980][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\unused-node-certificates
[2019-06-03T06:01:20,001][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack]
[2019-06-03T06:01:20,002][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\analysis]
[2019-06-03T06:01:20,014][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationInElasticsearchYaml} saved watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\elasticsearch.yml]
[2019-06-03T06:01:20,022][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [creating elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home\bin\elasticsearch-keystore.bat} {create}
Created elasticsearch keystore in C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config
[2019-06-03T06:01:30,002][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [creating elasticsearch.keystore] {0}
[2019-06-03T06:01:30,005][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home\bin\elasticsearch-keystore.bat} {add xpack.notification.slack.account.monitoring.secure_url -xf}
[2019-06-03T06:01:32,057][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {0}
[2019-06-03T06:01:32,058][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home\bin\elasticsearch-keystore.bat} {add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key -xf}
[2019-06-03T06:01:33,840][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {0}
[2019-06-03T06:01:33,841][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationSecretsInKeystore} added watcher action secrets to elasticsearch.keystore
[2019-06-03T06:01:33,845][INFO ][Managed Elasticsearch    ]  {EnsureNativeSecurityRealmEnabledInElasticsearchYaml} native security realm [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\elasticsearch.yml]
[2019-06-03T06:01:33,848][INFO ][Managed Elasticsearch    ] [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics.tar.gz already exists on disk using cached copy] DownloadMachineLearningSampleDataDistribution
[2019-06-03T06:01:33,848][INFO ][Managed Elasticsearch    ] [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics already exists and appears to have files, bailing out] DownloadMachineLearningSampleDataDistribution
[2019-06-03T06:01:33,848][INFO ][Managed Elasticsearch    ] [machinelearning-node-5f55a79200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home\bin\elasticsearch.bat]
[2019-06-03T06:01:33,849][INFO ][Managed Elasticsearch    ] [machinelearning-node-5f55a79200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-ebc0cb -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\logs -E xpack.security.enabled=true -E xpack.security.http.ssl.enabled=true -E xpack.security.transport.ssl.enabled=true -E xpack.security.authc.realms.pki.pki1.enabled=true -E xpack.security.authc.token.enabled=true -E xpack.security.transport.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\node01\node01.key -E xpack.security.transport.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\node01\node01.crt -E xpack.security.transport.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\ca\ca.crt -E xpack.security.http.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\node01\node01.key -E xpack.security.http.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\node01\node01.crt -E xpack.security.http.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\node-certificates\ca\ca.crt -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E xpack.ml.node_concurrent_job_allocations=4 -E xpack.ml.max_open_jobs=30 -E node.name=machinelearning-node-5f55a79200 -E http.port=9200 -E cluster.initial_master_nodes=machinelearning-node-5f55a79200}
[2019-06-03T16:01:38,384][INFO ][o.e.e.NodeEnvironment    ] [machinelearning-node-5f55a79200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:01:38,389][INFO ][o.e.e.NodeEnvironment    ] [machinelearning-node-5f55a79200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:01:38,395][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] node name [machinelearning-node-5f55a79200], node ID [YbfvxNYzTT6yyB1GMKeI2A]
[2019-06-03T16:01:38,396][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] version[7.0.0], pid[9200], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:01:38,397][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:01:38,398][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:01:56,488][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [aggs-matrix-stats]
[2019-06-03T16:01:56,489][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [analysis-common]
[2019-06-03T16:01:56,489][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [ingest-common]
[2019-06-03T16:01:56,490][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [ingest-geoip]
[2019-06-03T16:01:56,490][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [ingest-user-agent]
[2019-06-03T16:01:56,491][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [lang-expression]
[2019-06-03T16:01:56,491][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [lang-mustache]
[2019-06-03T16:01:56,491][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [lang-painless]
[2019-06-03T16:01:56,492][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [mapper-extras]
[2019-06-03T16:01:56,492][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [parent-join]
[2019-06-03T16:01:56,492][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [percolator]
[2019-06-03T16:01:56,493][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [rank-eval]
[2019-06-03T16:01:56,493][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [reindex]
[2019-06-03T16:01:56,493][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [repository-url]
[2019-06-03T16:01:56,494][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [transport-netty4]
[2019-06-03T16:01:56,495][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-ccr]
[2019-06-03T16:01:56,496][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-core]
[2019-06-03T16:01:56,496][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-deprecation]
[2019-06-03T16:01:56,497][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-graph]
[2019-06-03T16:01:56,498][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-ilm]
[2019-06-03T16:01:56,499][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-logstash]
[2019-06-03T16:01:56,499][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-ml]
[2019-06-03T16:01:56,500][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-monitoring]
[2019-06-03T16:01:56,500][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-rollup]
[2019-06-03T16:01:56,500][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-security]
[2019-06-03T16:01:56,501][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-sql]
[2019-06-03T16:01:56,502][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] loaded module [x-pack-watcher]
[2019-06-03T16:01:56,503][INFO ][o.e.p.PluginsService     ] [machinelearning-node-5f55a79200] no plugins loaded
[2019-06-03T16:02:01,979][INFO ][o.e.x.s.a.s.FileRolesStore] [machinelearning-node-5f55a79200] parsed [3] roles from file [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config\roles.yml]
[2019-06-03T16:02:02,784][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [controller/16012] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:02:03,221][DEBUG][o.e.a.ActionModule       ] [machinelearning-node-5f55a79200] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2019-06-03T16:02:03,541][INFO ][o.e.d.DiscoveryModule    ] [machinelearning-node-5f55a79200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:02:04,486][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] initialized
[2019-06-03T16:02:04,487][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] starting ...
[2019-06-03T16:02:05,515][INFO ][o.e.t.TransportService   ] [machinelearning-node-5f55a79200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:02:05,524][WARN ][o.e.b.BootstrapChecks    ] [machinelearning-node-5f55a79200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:02:05,538][INFO ][o.e.c.c.ClusterBootstrapService] [machinelearning-node-5f55a79200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:02:08,542][INFO ][o.e.c.c.Coordinator      ] [machinelearning-node-5f55a79200] setting initial configuration to VotingConfiguration{YbfvxNYzTT6yyB1GMKeI2A}
[2019-06-03T16:02:08,716][INFO ][o.e.c.s.MasterService    ] [machinelearning-node-5f55a79200] elected-as-master ([1] nodes joined)[{machinelearning-node-5f55a79200}{YbfvxNYzTT6yyB1GMKeI2A}{PHkXqV8kRIWeY6ZdW-0cYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=30, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{machinelearning-node-5f55a79200}{YbfvxNYzTT6yyB1GMKeI2A}{PHkXqV8kRIWeY6ZdW-0cYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=30, gateway=true}]}
[2019-06-03T16:02:08,787][INFO ][o.e.c.s.ClusterApplierService] [machinelearning-node-5f55a79200] master node changed {previous [], current [{machinelearning-node-5f55a79200}{YbfvxNYzTT6yyB1GMKeI2A}{PHkXqV8kRIWeY6ZdW-0cYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=30, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:02:08,937][INFO ][o.e.g.GatewayService     ] [machinelearning-node-5f55a79200] recovered [0] indices into cluster_state
[2019-06-03T16:02:09,206][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:02:09,256][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:02:09,307][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:02:09,378][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:02:09,451][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:02:09,511][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:02:09,615][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:02:09,687][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:02:09,695][INFO ][o.e.h.AbstractHttpServerTransport] [machinelearning-node-5f55a79200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:02:09,696][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] started
[2019-06-03T06:02:09,699][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T16:02:09,765][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [machinelearning-node-5f55a79200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:02:10,281][INFO ][o.e.l.LicenseService     ] [machinelearning-node-5f55a79200] license [a7afa221-91ea-4464-b0b6-dc9bcd122ccc] mode [basic] - valid
[2019-06-03T06:02:10,741][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:02:10,786][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} attempting to post license json
[2019-06-03T16:02:10,894][INFO ][o.e.l.LicenseService     ] [machinelearning-node-5f55a79200] license [integ-test-license] mode [platinum] - valid
[2019-06-03T06:02:10,899][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:02:11,129][INFO ][Managed Elasticsearch    ]  All good! kicking off [MachineLearningCluster] tests now
[2019-06-03T16:02:11,209][INFO ][o.e.c.m.MetaDataIndexTemplateService] [machinelearning-node-5f55a79200] adding template [server-metrics] for index patterns [*]
[2019-06-03T16:02:11,341][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [server-metrics] creating index, cause [api], templates [server-metrics], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:11,819][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[server-metrics][0]] ...]).
Bulk importing starting ...
Indexed docs from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics\server-metrics_1.json
Indexed docs from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics\server-metrics_2.json
Indexed docs from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics\server-metrics_3.json
Indexed docs from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\server_metrics\server-metrics_4.json
Bulk importing finished.
[2019-06-03T16:02:26,451][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-shared] creating index, cause [api], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:26,526][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-annotations-6] creating index, cause [api], templates [server-metrics], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:26,824][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-annotations-6][0]] ...]).
[2019-06-03T16:02:26,966][INFO ][o.e.x.m.MlInitializationService] [machinelearning-node-5f55a79200] Created ML annotations index and aliases
[2019-06-03T16:02:26,973][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-config] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-config], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:27,149][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-config][0]] ...]).
[2019-06-03T16:02:27,392][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-notifications] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-notifications], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:27,642][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-notifications][0]] ...]).
[2019-06-03T16:02:31,515][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-7707c900]
[2019-06-03T16:02:31,530][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-state] creating index, cause [api], templates [server-metrics, .ml-state], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:31,669][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-state][0]] ...]).
[2019-06-03T16:02:31,722][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:02:32,336][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-7707c900]
[2019-06-03T16:02:32,385][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] [autodetect/16912] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:02:32,588][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-7707c900], because [close job (api)]
[2019-06-03T16:02:32,590][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] [autodetect/16912] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:02:32,591][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] [autodetect/16912] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:02:32,591][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] State output finished
[2019-06-03T16:02:32,604][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] 0 buckets parsed from autodetect output
[2019-06-03T16:02:32,719][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-7707c900] job closed
[2019-06-03T16:02:36,807][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-72786c77]
[2019-06-03T16:02:36,816][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:02:37,260][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-72786c77]
[2019-06-03T16:02:37,327][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] [autodetect/7556] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:02:37,461][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-72786c77], because [close job (api)]
[2019-06-03T16:02:37,462][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] [autodetect/7556] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:02:37,462][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] [autodetect/7556] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:02:37,463][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] State output finished
[2019-06-03T16:02:37,468][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] 0 buckets parsed from autodetect output
[2019-06-03T16:02:37,570][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-72786c77] job closed
[2019-06-03T16:02:42,353][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-7f18a925]
[2019-06-03T16:02:42,371][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:02:42,920][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-7f18a925]
[2019-06-03T16:02:42,985][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] [autodetect/12432] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:02:43,128][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-7f18a925], because [close job (api)]
[2019-06-03T16:02:43,129][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] [autodetect/12432] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:02:43,130][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] [autodetect/12432] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:02:43,130][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] State output finished
[2019-06-03T16:02:43,135][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] 0 buckets parsed from autodetect output
[2019-06-03T16:02:43,246][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-7f18a925] job closed
[2019-06-03T16:02:47,658][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-1ae9a277]
[2019-06-03T16:02:47,667][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:02:48,197][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-1ae9a277]
[2019-06-03T16:02:48,264][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] [autodetect/17892] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:02:48,372][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-1ae9a277], because [close job (api)]
[2019-06-03T16:02:48,373][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] [autodetect/17892] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:02:48,373][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] [autodetect/17892] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:02:48,373][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] State output finished
[2019-06-03T16:02:48,379][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] 0 buckets parsed from autodetect output
[2019-06-03T16:02:48,473][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-1ae9a277] job closed
[2019-06-03T16:02:52,917][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Reverting to snapshot 'first'
[2019-06-03T16:02:53,284][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Deleting results after 'Thu Jun 02 10:00:00 AEST 2016'
[2019-06-03T16:02:53,333][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Reverting to snapshot 'first'
[2019-06-03T16:02:53,696][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Deleting results after 'Thu Jun 02 10:00:00 AEST 2016'
[2019-06-03T16:02:53,705][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Reverting to snapshot 'first'
[2019-06-03T16:02:54,100][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Deleting results after 'Thu Jun 02 10:00:00 AEST 2016'
[2019-06-03T16:02:54,113][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Reverting to snapshot 'first'
[2019-06-03T16:02:54,522][INFO ][o.e.x.m.a.TransportRevertModelSnapshotAction] [machinelearning-node-5f55a79200] Deleting results after 'Thu Jun 02 10:00:00 AEST 2016'
[2019-06-03T16:02:56,546][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-meta] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-meta], shards [1]/[0], mappings [_doc]
[2019-06-03T16:02:56,677][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-meta][0]] ...]).
[2019-06-03T16:02:56,712][INFO ][o.e.c.m.MetaDataMappingService] [machinelearning-node-5f55a79200] [.ml-meta/P4WNi2RaRFqr7ekAY5UUSw] update_mapping [_doc]
[2019-06-03T16:02:58,383][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-734c6e4b]
[2019-06-03T16:02:58,393][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:02:58,933][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-734c6e4b]
[2019-06-03T16:02:58,986][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] [autodetect/15248] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:03,212][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-734c6e4b], because [close job (api)]
[2019-06-03T16:03:03,214][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] [autodetect/15248] [CCmdSkeleton.cc@45] Handled 3009 records
[2019-06-03T16:03:03,214][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] [autodetect/15248] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:03,236][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] State output finished
[2019-06-03T16:03:03,461][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] 3000 buckets parsed from autodetect output
[2019-06-03T16:03:03,818][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-734c6e4b] job closed
[2019-06-03T16:03:04,262][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-26b85c39]
[2019-06-03T16:03:04,270][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:04,795][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-26b85c39]
[2019-06-03T16:03:04,860][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] [autodetect/18336] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:09,056][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-26b85c39], because [close job (api)]
[2019-06-03T16:03:09,059][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] [autodetect/18336] [CCmdSkeleton.cc@45] Handled 3009 records
[2019-06-03T16:03:09,059][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] [autodetect/18336] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:09,086][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] State output finished
[2019-06-03T16:03:09,258][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] 3000 buckets parsed from autodetect output
[2019-06-03T16:03:09,634][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-26b85c39] job closed
[2019-06-03T16:03:10,028][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-037204da]
[2019-06-03T16:03:10,035][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-037204da] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:10,554][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-037204da]
[2019-06-03T16:03:10,620][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-037204da] [autodetect/14604] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:14,222][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-037204da], because [close job (api)]
[2019-06-03T16:03:14,223][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-037204da] [autodetect/14604] [CCmdSkeleton.cc@45] Handled 3009 records
[2019-06-03T16:03:14,223][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-037204da] [autodetect/14604] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:14,245][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-037204da] State output finished
[2019-06-03T16:03:14,450][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-037204da] 3000 buckets parsed from autodetect output
[2019-06-03T16:03:14,923][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-037204da] job closed
[2019-06-03T16:03:15,437][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-3bfc478f]
[2019-06-03T16:03:15,442][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:15,885][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-3bfc478f]
[2019-06-03T16:03:15,927][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] [autodetect/5884] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:18,420][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-3bfc478f], because [close job (api)]
[2019-06-03T16:03:18,422][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] [autodetect/5884] [CCmdSkeleton.cc@45] Handled 3009 records
[2019-06-03T16:03:18,422][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] [autodetect/5884] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:18,473][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] State output finished
[2019-06-03T16:03:18,728][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] 3000 buckets parsed from autodetect output
[2019-06-03T16:03:19,139][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-3bfc478f] job closed
[2019-06-03T16:03:21,364][INFO ][o.e.c.m.MetaDataMappingService] [machinelearning-node-5f55a79200] [.ml-config/4gXxS04USheHGbLBiYb_8g] update_mapping [_doc]
[2019-06-03T16:03:22,055][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluent-734c6e4b]
[2019-06-03T16:03:23,685][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluent-734c6e4b] deleted
[2019-06-03T16:03:24,311][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluentasync-26b85c39]
[2019-06-03T16:03:25,845][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluentasync-26b85c39] deleted
[2019-06-03T16:03:26,474][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializer-037204da]
[2019-06-03T16:03:27,629][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializer-037204da] deleted
[2019-06-03T16:03:28,142][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializerasync-3bfc478f]
[2019-06-03T16:03:29,698][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializerasync-3bfc478f] deleted
[2019-06-03T16:03:30,966][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-725303b1]
[2019-06-03T16:03:30,971][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:31,529][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-725303b1]
[2019-06-03T16:03:31,584][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:31,913][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:03:32,149][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,302][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,428][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,549][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,674][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,741][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-d5316e1d]
[2019-06-03T16:03:32,762][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:32,829][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:32,974][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:33,088][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:33,207][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:33,350][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:33,537][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-d5316e1d]
[2019-06-03T16:03:33,549][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:35,065][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:03:35,181][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:35,293][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:35,723][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:35,747][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] Lookback has finished
[2019-06-03T16:03:35,750][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:35,750][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CAnomalyJob.cc@1013] Background persist starting data copy
[2019-06-03T16:03:35,750][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CBackgroundPersister.cc@190] Background persist starting background thread
[2019-06-03T16:03:35,833][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:35,951][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:36,075][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:36,179][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:36,271][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:36,372][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:36,674][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-721a0f2e]
[2019-06-03T16:03:36,695][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:37,176][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:37,334][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-721a0f2e]
[2019-06-03T16:03:37,339][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] [autodetect/11236] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:38,479][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:03:38,603][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:38,715][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:38,848][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:38,980][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,101][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,211][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,315][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,400][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,499][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,616][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:03:39,641][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-88f78a4e]
[2019-06-03T16:03:39,651][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:03:40,005][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:40,006][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CAnomalyJob.cc@1013] Background persist starting data copy
[2019-06-03T16:03:40,006][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CBackgroundPersister.cc@190] Background persist starting background thread
[2019-06-03T16:03:40,006][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] Lookback has finished
[2019-06-03T16:03:40,235][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] [autodetect/12440] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:03:40,312][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-88f78a4e]
[2019-06-03T16:03:41,348][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:03:41,437][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializerasync-88f78a4e-datafeed] [16]
[2019-06-03T16:03:41,439][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e]
[2019-06-03T16:03:41,439][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e]...
[2019-06-03T16:03:41,443][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] attempt to stop datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e]
[2019-06-03T16:03:41,443][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e], acquired [true]...
[2019-06-03T16:03:41,443][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e] was already stopped
[2019-06-03T16:03:41,444][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-initializerasync-88f78a4e-datafeed] for job [nest-initializerasync-88f78a4e] has been stopped
[2019-06-03T16:03:41,542][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluentasync-d5316e1d-datafeed] [12]
[2019-06-03T16:03:41,542][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluentasync-d5316e1d-datafeed] for job [nest-fluentasync-d5316e1d]
[2019-06-03T16:03:41,543][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-fluentasync-d5316e1d-datafeed] for job [nest-fluentasync-d5316e1d]...
[2019-06-03T16:03:41,543][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-fluentasync-d5316e1d-datafeed] for job [nest-fluentasync-d5316e1d], acquired [true]...
[2019-06-03T16:03:41,543][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-fluentasync-d5316e1d-datafeed] for job [nest-fluentasync-d5316e1d] has been stopped
[2019-06-03T16:03:41,630][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializer-721a0f2e-datafeed] [14]
[2019-06-03T16:03:41,631][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e]
[2019-06-03T16:03:41,631][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e]...
[2019-06-03T16:03:41,692][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e], acquired [true]...
[2019-06-03T16:03:41,692][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] attempt to stop datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e]
[2019-06-03T16:03:41,693][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e] has been stopped
[2019-06-03T16:03:41,693][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] datafeed [nest-initializer-721a0f2e-datafeed] for job [nest-initializer-721a0f2e] was already stopped
[2019-06-03T16:03:41,895][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluent-725303b1-datafeed] [10]
[2019-06-03T16:03:41,896][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluent-725303b1-datafeed] for job [nest-fluent-725303b1]
[2019-06-03T16:03:41,896][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-fluent-725303b1-datafeed] for job [nest-fluent-725303b1]...
[2019-06-03T16:03:41,896][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-fluent-725303b1-datafeed] for job [nest-fluent-725303b1], acquired [true]...
[2019-06-03T16:03:41,900][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-fluent-725303b1-datafeed] for job [nest-fluent-725303b1] has been stopped
[2019-06-03T16:03:42,058][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-725303b1], because [close job (api)]
[2019-06-03T16:03:42,060][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:03:42,060][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] [autodetect/7744] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:42,163][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] State output finished
[2019-06-03T16:03:42,634][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] 288 buckets parsed from autodetect output
[2019-06-03T16:03:43,492][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-725303b1] job closed
[2019-06-03T16:03:43,690][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-d5316e1d], because [close job (api)]
[2019-06-03T16:03:43,691][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:03:43,691][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] [autodetect/10796] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:43,712][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] State output finished
[2019-06-03T16:03:43,850][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] 288 buckets parsed from autodetect output
[2019-06-03T16:03:44,881][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-d5316e1d] job closed
[2019-06-03T16:03:45,083][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-721a0f2e], because [close job (api)]
[2019-06-03T16:03:45,084][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] [autodetect/11236] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:03:45,084][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] [autodetect/11236] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:45,103][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] State output finished
[2019-06-03T16:03:45,258][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] 288 buckets parsed from autodetect output
[2019-06-03T16:03:46,187][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-721a0f2e] job closed
[2019-06-03T16:03:46,484][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-88f78a4e], because [close job (api)]
[2019-06-03T16:03:46,486][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] [autodetect/12440] [CCmdSkeleton.cc@45] Handled 9009 records
[2019-06-03T16:03:46,487][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] [autodetect/12440] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:03:46,508][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] State output finished
[2019-06-03T16:03:46,790][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] 14 buckets parsed from autodetect output
[2019-06-03T16:03:47,195][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-88f78a4e] job closed
[2019-06-03T16:03:48,431][INFO ][o.e.c.m.MetaDataMappingService] [machinelearning-node-5f55a79200] [.ml-meta/P4WNi2RaRFqr7ekAY5UUSw] update_mapping [_doc]
[2019-06-03T16:03:50,896][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Deleting expired data
[2019-06-03T16:03:51,440][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Completed deletion of expired data
[2019-06-03T16:03:51,446][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Deleting expired data
[2019-06-03T16:03:51,472][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Completed deletion of expired data
[2019-06-03T16:03:51,474][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Deleting expired data
[2019-06-03T16:03:51,504][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Completed deletion of expired data
[2019-06-03T16:03:51,508][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Deleting expired data
[2019-06-03T16:03:51,538][INFO ][o.e.x.m.a.TransportDeleteExpiredDataAction] [machinelearning-node-5f55a79200] Completed deletion of expired data
[2019-06-03T16:03:51,553][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-nest-fluent-5efa08e2] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:03:51,713][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-anomalies-nest-fluent-5efa08e2][0]] ...]).
[2019-06-03T16:03:53,851][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-nest-fluentasync-2f3912f8] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:03:53,976][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-anomalies-nest-fluentasync-2f3912f8][0]] ...]).
[2019-06-03T16:03:56,087][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-nest-initializer-a428f618] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:03:56,200][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-anomalies-nest-initializer-a428f618][0]] ...]).
[2019-06-03T16:03:58,327][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-nest-initializerasync-afc074e3] creating index, cause [auto(bulk api)], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:03:58,442][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-anomalies-nest-initializerasync-afc074e3][0]] ...]).
[2019-06-03T16:04:02,335][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializer-0acdf69a]
[2019-06-03T16:04:02,472][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializer-0acdf69a] deleted
[2019-06-03T16:04:02,669][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializerasync-39cdcad8]
[2019-06-03T16:04:02,805][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializerasync-39cdcad8] deleted
[2019-06-03T16:04:02,947][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluentasync-df285acb]
[2019-06-03T16:04:03,082][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluentasync-df285acb] deleted
[2019-06-03T16:04:03,224][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluent-ac58bb92]
[2019-06-03T16:04:03,365][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluent-ac58bb92] deleted
[2019-06-03T16:04:07,974][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-cc027e1b]
[2019-06-03T16:04:07,977][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:08,498][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-cc027e1b]
[2019-06-03T16:04:08,565][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:09,129][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-3b094712]
[2019-06-03T16:04:09,134][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:09,674][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-3b094712]
[2019-06-03T16:04:09,707][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:10,310][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-98709739]
[2019-06-03T16:04:10,313][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-98709739] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:10,878][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-98709739]
[2019-06-03T16:04:10,926][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:11,358][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-c0241be2]
[2019-06-03T16:04:11,362][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:11,902][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-c0241be2]
[2019-06-03T16:04:11,948][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:12,217][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CForecastRunner.cc@461] Forecast duration not specified, setting to 1 day
[2019-06-03T16:04:12,218][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CForecastRunner.cc@124] Start forecasting from 2019-06-03T04:00:00+0000 to 2019-06-04T04:00:00+0000
[2019-06-03T16:04:12,221][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CForecastRunner.cc@213] Finished forecasting, wrote 24 records
[2019-06-03T16:04:12,322][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CForecastRunner.cc@461] Forecast duration not specified, setting to 1 day
[2019-06-03T16:04:12,323][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CForecastRunner.cc@124] Start forecasting from 2019-06-03T04:00:00+0000 to 2019-06-04T04:00:00+0000
[2019-06-03T16:04:12,324][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CForecastRunner.cc@213] Finished forecasting, wrote 24 records
[2019-06-03T16:04:12,463][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CForecastRunner.cc@461] Forecast duration not specified, setting to 1 day
[2019-06-03T16:04:12,463][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CForecastRunner.cc@124] Start forecasting from 2019-06-03T04:00:00+0000 to 2019-06-04T04:00:00+0000
[2019-06-03T16:04:12,464][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CForecastRunner.cc@213] Finished forecasting, wrote 24 records
[2019-06-03T16:04:12,596][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CForecastRunner.cc@461] Forecast duration not specified, setting to 1 day
[2019-06-03T16:04:12,596][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CForecastRunner.cc@124] Start forecasting from 2019-06-03T04:00:00+0000 to 2019-06-04T04:00:00+0000
[2019-06-03T16:04:12,597][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CForecastRunner.cc@213] Finished forecasting, wrote 24 records
[2019-06-03T16:04:12,764][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-cc027e1b], because [close job (api)]
[2019-06-03T16:04:12,764][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CCmdSkeleton.cc@45] Handled 100 records
[2019-06-03T16:04:12,765][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] [autodetect/17124] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:12,777][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] State output finished
[2019-06-03T16:04:13,195][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] 48 buckets parsed from autodetect output
[2019-06-03T16:04:13,416][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-cc027e1b] job closed
[2019-06-03T16:04:13,951][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluent-cc027e1b]
[2019-06-03T16:04:14,427][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluent-cc027e1b] deleted
[2019-06-03T16:04:14,453][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-3b094712], because [close job (api)]
[2019-06-03T16:04:14,454][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CCmdSkeleton.cc@45] Handled 100 records
[2019-06-03T16:04:14,454][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] [autodetect/11324] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:14,466][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] State output finished
[2019-06-03T16:04:14,589][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] 48 buckets parsed from autodetect output
[2019-06-03T16:04:14,887][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-3b094712] job closed
[2019-06-03T16:04:15,408][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluentasync-3b094712]
[2019-06-03T16:04:15,953][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluentasync-3b094712] deleted
[2019-06-03T16:04:15,982][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-98709739], because [close job (api)]
[2019-06-03T16:04:15,983][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CCmdSkeleton.cc@45] Handled 100 records
[2019-06-03T16:04:15,983][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-98709739] [autodetect/2496] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:15,993][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-98709739] State output finished
[2019-06-03T16:04:16,119][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-98709739] 48 buckets parsed from autodetect output
[2019-06-03T16:04:16,508][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-98709739] job closed
[2019-06-03T16:04:17,340][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializer-98709739]
[2019-06-03T16:04:17,939][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializer-98709739] deleted
[2019-06-03T16:04:17,971][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-c0241be2], because [close job (api)]
[2019-06-03T16:04:17,972][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CCmdSkeleton.cc@45] Handled 100 records
[2019-06-03T16:04:17,972][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] [autodetect/13864] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:17,985][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] State output finished
[2019-06-03T16:04:18,129][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] 48 buckets parsed from autodetect output
[2019-06-03T16:04:18,445][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-c0241be2] job closed
[2019-06-03T16:04:19,005][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializerasync-c0241be2]
[2019-06-03T16:04:19,600][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializerasync-c0241be2] deleted
[2019-06-03T16:04:30,951][INFO ][o.e.c.m.MetaDataCreateIndexService] [machinelearning-node-5f55a79200] [.ml-anomalies-custom-server-metrics] creating index, cause [api], templates [server-metrics, .ml-anomalies-], shards [1]/[0], mappings [_doc]
[2019-06-03T16:04:31,086][INFO ][o.e.c.r.a.AllocationService] [machinelearning-node-5f55a79200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ml-anomalies-custom-server-metrics][0]] ...]).
[2019-06-03T16:04:48,502][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-84c29058]
[2019-06-03T16:04:48,505][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:48,938][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-84c29058]
[2019-06-03T16:04:48,978][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] [autodetect/17332] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:49,407][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-19ddda8d]
[2019-06-03T16:04:49,410][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:49,833][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-19ddda8d]
[2019-06-03T16:04:49,901][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:50,261][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-1b730fbb]
[2019-06-03T16:04:50,264][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:50,760][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-1b730fbb]
[2019-06-03T16:04:50,835][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:51,192][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-ff0422d9]
[2019-06-03T16:04:51,195][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:04:51,613][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-ff0422d9]
[2019-06-03T16:04:51,681][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:04:52,001][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:04:52,086][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,103][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:04:52,175][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,207][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,263][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,299][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,303][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:04:52,352][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,415][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,428][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,466][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,527][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,570][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,572][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,665][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,682][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,692][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,768][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,771][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,786][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,832][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] Datafeed started (from: 1970-01-01T00:00:00.000Z to: real-time) with frequency [600000ms]
[2019-06-03T16:04:52,853][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,884][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluent-84c29058-datafeed] [27]
[2019-06-03T16:04:52,884][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058]
[2019-06-03T16:04:52,884][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058]...
[2019-06-03T16:04:52,946][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 10000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:52,962][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,060][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 20000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,065][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,148][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 30000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,177][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,237][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 40000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,314][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 50000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,408][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 60000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,435][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,514][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 70000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,545][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,597][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 80000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,690][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 90000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,824][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] attempt to stop datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058]
[2019-06-03T16:04:53,824][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [no_realtime] datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058] was already stopped
[2019-06-03T16:04:53,825][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058], acquired [true]...
[2019-06-03T16:04:53,826][INFO ][o.e.x.m.j.p.DataCountsReporter] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 100000 records written to autodetect; missingFieldCount=0, invalidDateCount=0, outOfOrderCount=0
[2019-06-03T16:04:53,826][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-fluent-84c29058-datafeed] for job [nest-fluent-84c29058] has been stopped
[2019-06-03T16:04:54,080][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-84c29058], because [close job (api)]
[2019-06-03T16:04:54,084][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] [autodetect/17332] [CCmdSkeleton.cc@45] Handled 40005 records
[2019-06-03T16:04:54,084][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] [autodetect/17332] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:54,149][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] State output finished
[2019-06-03T16:04:55,910][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:55,910][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] Lookback has finished
[2019-06-03T16:04:55,910][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CAnomalyJob.cc@1013] Background persist starting data copy
[2019-06-03T16:04:55,910][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CBackgroundPersister.cc@190] Background persist starting background thread
[2019-06-03T16:04:56,232][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] Lookback has finished
[2019-06-03T16:04:56,232][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] 63 buckets parsed from autodetect output
[2019-06-03T16:04:56,232][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:56,233][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CAnomalyJob.cc@1013] Background persist starting data copy
[2019-06-03T16:04:56,233][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CBackgroundPersister.cc@190] Background persist starting background thread
[2019-06-03T16:04:56,234][INFO ][o.e.x.m.d.DatafeedJob    ] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] Lookback has finished
[2019-06-03T16:04:56,236][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:56,236][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CAnomalyJob.cc@1013] Background persist starting data copy
[2019-06-03T16:04:56,237][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CBackgroundPersister.cc@190] Background persist starting background thread
[2019-06-03T16:04:56,841][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-84c29058] job closed
[2019-06-03T16:04:57,175][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluentasync-19ddda8d-datafeed] [28]
[2019-06-03T16:04:57,175][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-fluentasync-19ddda8d-datafeed] for job [nest-fluentasync-19ddda8d]
[2019-06-03T16:04:57,175][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-fluentasync-19ddda8d-datafeed] for job [nest-fluentasync-19ddda8d]...
[2019-06-03T16:04:57,175][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-fluentasync-19ddda8d-datafeed] for job [nest-fluentasync-19ddda8d], acquired [true]...
[2019-06-03T16:04:57,176][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-fluentasync-19ddda8d-datafeed] for job [nest-fluentasync-19ddda8d] has been stopped
[2019-06-03T16:04:57,240][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-19ddda8d], because [close job (api)]
[2019-06-03T16:04:57,241][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:04:57,241][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] [autodetect/11192] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:57,259][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] State output finished
[2019-06-03T16:04:57,403][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] 288 buckets parsed from autodetect output
[2019-06-03T16:04:58,389][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-19ddda8d] job closed
[2019-06-03T16:04:58,595][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializer-1b730fbb-datafeed] [25]
[2019-06-03T16:04:58,595][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializer-1b730fbb-datafeed] for job [nest-initializer-1b730fbb]
[2019-06-03T16:04:58,596][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-initializer-1b730fbb-datafeed] for job [nest-initializer-1b730fbb]...
[2019-06-03T16:04:58,596][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-initializer-1b730fbb-datafeed] for job [nest-initializer-1b730fbb], acquired [true]...
[2019-06-03T16:04:58,596][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-initializer-1b730fbb-datafeed] for job [nest-initializer-1b730fbb] has been stopped
[2019-06-03T16:04:58,645][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-1b730fbb], because [close job (api)]
[2019-06-03T16:04:58,646][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:04:58,646][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] [autodetect/15248] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:58,658][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] State output finished
[2019-06-03T16:04:58,792][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] 288 buckets parsed from autodetect output
[2019-06-03T16:04:59,599][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-1b730fbb] job closed
[2019-06-03T16:04:59,793][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializerasync-ff0422d9-datafeed] [26]
[2019-06-03T16:04:59,793][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] attempt to stop datafeed [nest-initializerasync-ff0422d9-datafeed] for job [nest-initializerasync-ff0422d9]
[2019-06-03T16:04:59,793][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] try lock [5m] to stop datafeed [nest-initializerasync-ff0422d9-datafeed] for job [nest-initializerasync-ff0422d9]...
[2019-06-03T16:04:59,793][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] stopping datafeed [nest-initializerasync-ff0422d9-datafeed] for job [nest-initializerasync-ff0422d9], acquired [true]...
[2019-06-03T16:04:59,794][INFO ][o.e.x.m.d.DatafeedManager] [machinelearning-node-5f55a79200] [stop_datafeed (api)] datafeed [nest-initializerasync-ff0422d9-datafeed] for job [nest-initializerasync-ff0422d9] has been stopped
[2019-06-03T16:04:59,860][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-ff0422d9], because [close job (api)]
[2019-06-03T16:04:59,864][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CCmdSkeleton.cc@45] Handled 181188 records
[2019-06-03T16:04:59,864][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] [autodetect/18156] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:04:59,879][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] State output finished
[2019-06-03T16:05:00,005][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] 288 buckets parsed from autodetect output
[2019-06-03T16:05:01,034][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-ff0422d9] job closed
[2019-06-03T16:05:10,187][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-6d5408a3]
[2019-06-03T16:05:10,191][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:10,752][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-6d5408a3]
[2019-06-03T16:05:10,768][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] [autodetect/12640] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:11,104][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-93733003]
[2019-06-03T16:05:11,107][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:11,682][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-93733003]
[2019-06-03T16:05:11,740][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] [autodetect/14632] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:12,012][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-73828e83]
[2019-06-03T16:05:12,015][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:12,574][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-73828e83]
[2019-06-03T16:05:12,626][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] [autodetect/3920] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:12,884][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-89670580]
[2019-06-03T16:05:12,887][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:13,450][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-89670580]
[2019-06-03T16:05:13,497][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] [autodetect/13112] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:13,609][ERROR][o.e.x.m.j.p.a.w.JsonDataToProcessWriter] [machinelearning-node-5f55a79200] Cannot parse timestamp '2017-09-01T00:00:00' as epoch value
[2019-06-03T16:05:13,616][ERROR][o.e.x.m.j.p.a.w.JsonDataToProcessWriter] [machinelearning-node-5f55a79200] Cannot parse timestamp '2017-09-01T00:00:00' as epoch value
[2019-06-03T16:05:13,619][ERROR][o.e.x.m.j.p.a.w.JsonDataToProcessWriter] [machinelearning-node-5f55a79200] Cannot parse timestamp '2017-09-01T00:00:00' as epoch value
[2019-06-03T16:05:13,622][ERROR][o.e.x.m.j.p.a.w.JsonDataToProcessWriter] [machinelearning-node-5f55a79200] Cannot parse timestamp '2017-09-01T00:00:00' as epoch value
[2019-06-03T16:05:13,653][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-6d5408a3], because [close job (api)]
[2019-06-03T16:05:13,654][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] [autodetect/12640] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:13,654][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] [autodetect/12640] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:13,655][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] State output finished
[2019-06-03T16:05:13,655][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] 0 buckets parsed from autodetect output
[2019-06-03T16:05:13,750][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-6d5408a3] job closed
[2019-06-03T16:05:13,942][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-93733003], because [close job (api)]
[2019-06-03T16:05:13,943][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] [autodetect/14632] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:13,943][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] [autodetect/14632] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:13,943][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] State output finished
[2019-06-03T16:05:13,947][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] 0 buckets parsed from autodetect output
[2019-06-03T16:05:14,041][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-93733003] job closed
[2019-06-03T16:05:14,228][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-73828e83], because [close job (api)]
[2019-06-03T16:05:14,228][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] [autodetect/3920] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:14,228][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] [autodetect/3920] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:14,228][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] State output finished
[2019-06-03T16:05:14,231][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] 0 buckets parsed from autodetect output
[2019-06-03T16:05:14,324][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-73828e83] job closed
[2019-06-03T16:05:14,513][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-89670580], because [close job (api)]
[2019-06-03T16:05:14,513][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] [autodetect/13112] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:14,514][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] [autodetect/13112] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:14,514][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] State output finished
[2019-06-03T16:05:14,518][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] 0 buckets parsed from autodetect output
[2019-06-03T16:05:14,615][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-89670580] job closed
[2019-06-03T16:05:29,467][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-b35ed7b7]
[2019-06-03T16:05:29,470][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:29,901][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-b35ed7b7]
[2019-06-03T16:05:29,956][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] [autodetect/16004] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:30,225][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-710731e3]
[2019-06-03T16:05:30,228][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:30,752][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-710731e3]
[2019-06-03T16:05:30,804][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] [autodetect/16276] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:31,215][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-82e4c249]
[2019-06-03T16:05:31,219][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:31,640][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-82e4c249]
[2019-06-03T16:05:31,705][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] [autodetect/15724] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:31,952][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-ce7262f8]
[2019-06-03T16:05:31,956][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:32,513][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-ce7262f8]
[2019-06-03T16:05:32,568][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] [autodetect/15076] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:32,684][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-b35ed7b7], because [close job (api)]
[2019-06-03T16:05:32,684][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] [autodetect/16004] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:32,684][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] [autodetect/16004] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:32,685][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] State output finished
[2019-06-03T16:05:32,688][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] 0 buckets parsed from autodetect output
[2019-06-03T16:05:32,796][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-b35ed7b7] job closed
[2019-06-03T16:05:32,988][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-82e4c249], because [close job (api)]
[2019-06-03T16:05:32,988][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] [autodetect/15724] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:32,988][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] [autodetect/15724] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:32,988][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] State output finished
[2019-06-03T16:05:32,992][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] 0 buckets parsed from autodetect output
[2019-06-03T16:05:33,080][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-82e4c249] job closed
[2019-06-03T16:05:33,275][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-ce7262f8], because [close job (api)]
[2019-06-03T16:05:33,275][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] [autodetect/15076] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:33,275][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] [autodetect/15076] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:33,275][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] State output finished
[2019-06-03T16:05:33,279][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] 0 buckets parsed from autodetect output
[2019-06-03T16:05:33,375][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-ce7262f8] job closed
[2019-06-03T16:05:33,573][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-710731e3], because [close job (api)]
[2019-06-03T16:05:33,573][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] [autodetect/16276] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:33,573][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] [autodetect/16276] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:33,574][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] State output finished
[2019-06-03T16:05:33,577][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] 0 buckets parsed from autodetect output
[2019-06-03T16:05:33,696][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-710731e3] job closed
[2019-06-03T16:05:34,131][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-d38ca37f]
[2019-06-03T16:05:34,136][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:34,594][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-d38ca37f]
[2019-06-03T16:05:34,628][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] [autodetect/13056] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:34,985][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-1f01cc62]
[2019-06-03T16:05:34,988][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:35,409][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-1f01cc62]
[2019-06-03T16:05:35,475][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] [autodetect/17996] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:35,722][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-5d6b1f08]
[2019-06-03T16:05:35,725][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:36,250][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-5d6b1f08]
[2019-06-03T16:05:36,319][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] [autodetect/14632] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:36,576][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-7d5e4e4c]
[2019-06-03T16:05:36,579][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:36,997][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-7d5e4e4c]
[2019-06-03T16:05:37,064][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] [autodetect/7556] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:37,224][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluent-d38ca37f], because [close job (api)]
[2019-06-03T16:05:37,225][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] [autodetect/13056] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:37,225][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] [autodetect/13056] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:37,239][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] State output finished
[2019-06-03T16:05:37,347][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] 0 buckets parsed from autodetect output
[2019-06-03T16:05:37,634][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluent-d38ca37f] job closed
[2019-06-03T16:05:37,814][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-fluentasync-1f01cc62], because [close job (api)]
[2019-06-03T16:05:37,815][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] [autodetect/17996] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:37,815][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] [autodetect/17996] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:37,823][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] State output finished
[2019-06-03T16:05:37,940][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] 0 buckets parsed from autodetect output
[2019-06-03T16:05:38,286][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-fluentasync-1f01cc62] job closed
[2019-06-03T16:05:38,481][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializer-5d6b1f08], because [close job (api)]
[2019-06-03T16:05:38,482][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] [autodetect/14632] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:38,483][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] [autodetect/14632] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:38,492][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] State output finished
[2019-06-03T16:05:38,599][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] 0 buckets parsed from autodetect output
[2019-06-03T16:05:38,881][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializer-5d6b1f08] job closed
[2019-06-03T16:05:39,071][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Closing job [nest-initializerasync-7d5e4e4c], because [close job (api)]
[2019-06-03T16:05:39,072][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] [autodetect/7556] [CCmdSkeleton.cc@45] Handled 0 records
[2019-06-03T16:05:39,073][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] [autodetect/7556] [CAnomalyJob.cc@1369] Pruning all models
[2019-06-03T16:05:39,084][INFO ][o.e.x.m.p.AbstractNativeProcess] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] State output finished
[2019-06-03T16:05:39,284][INFO ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] 0 buckets parsed from autodetect output
[2019-06-03T16:05:39,620][INFO ][o.e.x.m.j.p.a.AutodetectCommunicator] [machinelearning-node-5f55a79200] [nest-initializerasync-7d5e4e4c] job closed
[2019-06-03T16:05:41,141][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluent-eddd3458]
[2019-06-03T16:05:41,274][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluent-eddd3458] deleted
[2019-06-03T16:05:41,435][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluentasync-e79d823b]
[2019-06-03T16:05:41,580][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluentasync-e79d823b] deleted
[2019-06-03T16:05:41,740][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializer-6b67559d]
[2019-06-03T16:05:41,877][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializer-6b67559d] deleted
[2019-06-03T16:05:42,022][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializerasync-f257321a]
[2019-06-03T16:05:42,181][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializerasync-f257321a] deleted
[2019-06-03T16:05:42,447][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluent-756dfedf-job]
[2019-06-03T16:05:42,451][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluent-756dfedf-job] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:42,867][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluent-756dfedf-job]
[2019-06-03T16:05:42,941][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluent-756dfedf-job] [autodetect/16436] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:44,589][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-fluentasync-27bc6942-job]
[2019-06-03T16:05:44,593][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-fluentasync-27bc6942-job] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:45,123][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-fluentasync-27bc6942-job]
[2019-06-03T16:05:45,180][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-fluentasync-27bc6942-job] [autodetect/4424] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:46,766][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializer-5b4ecb9d-job]
[2019-06-03T16:05:46,769][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializer-5b4ecb9d-job] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:47,170][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializer-5b4ecb9d-job]
[2019-06-03T16:05:47,247][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializer-5b4ecb9d-job] [autodetect/15064] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:49,033][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Opening job [nest-initializerasync-46d945f4-job]
[2019-06-03T16:05:49,035][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] [nest-initializerasync-46d945f4-job] Loading model snapshot [N/A], job latest_record_timestamp [N/A]
[2019-06-03T16:05:49,575][INFO ][o.e.x.m.j.p.a.AutodetectProcessManager] [machinelearning-node-5f55a79200] Successfully set job state to [opened] for job [nest-initializerasync-46d945f4-job]
[2019-06-03T16:05:49,645][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [nest-initializerasync-46d945f4-job] [autodetect/14624] [CResourceMonitor.cc@68] Setting model memory limit to 1024 MB
[2019-06-03T16:05:51,133][INFO ][o.e.x.m.a.TransportDeleteForecastAction] [machinelearning-node-5f55a79200] Deleted forecast(s) [[nest-fluentasync-27bc6942]] from job [nest-fluentasync-27bc6942-job]
[2019-06-03T16:05:51,313][INFO ][o.e.x.m.a.TransportDeleteForecastAction] [machinelearning-node-5f55a79200] Deleted forecast(s) [[nest-fluent-756dfedf]] from job [nest-fluent-756dfedf-job]
[2019-06-03T16:05:51,490][INFO ][o.e.x.m.a.TransportDeleteForecastAction] [machinelearning-node-5f55a79200] Deleted forecast(s) [[nest-initializer-5b4ecb9d]] from job [nest-initializer-5b4ecb9d-job]
[2019-06-03T16:05:51,678][INFO ][o.e.x.m.a.TransportDeleteForecastAction] [machinelearning-node-5f55a79200] Deleted forecast(s) [[nest-initializerasync-46d945f4]] from job [nest-initializerasync-46d945f4-job]
[2019-06-03T16:05:54,379][WARN ][o.e.x.m.a.T.OpenJobPersistentTasksExecutor] [machinelearning-node-5f55a79200] [nest-fluent-f6469bd7] Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
[2019-06-03T16:05:54,391][WARN ][o.e.x.m.a.T.OpenJobPersistentTasksExecutor] [machinelearning-node-5f55a79200] [nest-initializer-5b2e9ab1] Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-initializer-5b2e9ab1] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
[2019-06-03T16:05:54,402][WARN ][o.e.x.m.a.T.OpenJobPersistentTasksExecutor] [machinelearning-node-5f55a79200] [nest-initializerasync-4ce74dd5] Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-initializerasync-4ce74dd5] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
[2019-06-03T16:05:54,413][WARN ][o.e.x.m.a.T.OpenJobPersistentTasksExecutor] [machinelearning-node-5f55a79200] [nest-fluentasync-a0605488] Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluentasync-a0605488] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
[2019-06-03T16:05:54,558][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluent-f6469bd7]
[2019-06-03T16:05:54,701][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluent-f6469bd7] deleted
Failed   Tests.XPack.MachineLearning.PreviewDataFeed.PreviewDatafeedApiTests.ReturnsExpectedStatusCode
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : expected:'{', actual:'[', at offset:0
---- Elasticsearch.Net.Utf8Json.JsonParsingException : expected:'{', actual:'[', at offset:0
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonReader.ReadIsBeginObjectWithVerify() in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonReader.cs:line 466
   at Deserialize(Object[] , JsonReader& , IJsonFormatterResolver )
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters)
Failed   Tests.XPack.MachineLearning.PreviewDataFeed.PreviewDatafeedApiTests.ReturnsExpectedResponse
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : expected:'{', actual:'[', at offset:0
---- Elasticsearch.Net.Utf8Json.JsonParsingException : expected:'{', actual:'[', at offset:0
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonReader.ReadIsBeginObjectWithVerify() in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonReader.cs:line 466
   at Deserialize(Object[] , JsonReader& , IJsonFormatterResolver )
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters)
Failed   Tests.XPack.MachineLearning.PreviewDataFeed.PreviewDatafeedApiTests.ReturnsExpectedIsValid
Error Message:
 Elasticsearch.Net.UnexpectedElasticsearchClientException : expected:'{', actual:'[', at offset:0
---- Elasticsearch.Net.Utf8Json.JsonParsingException : expected:'{', actual:'[', at offset:0
Stack Trace:
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters) in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Transport\Transport.cs:line 146
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_1.<<Calls>b__6>d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at System.Threading.Tasks.ValueTask`1.get_Result()
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 114
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at Elasticsearch.Net.Utf8Json.JsonReader.ReadIsBeginObjectWithVerify() in c:\Source\elasticsearch-net-7.x\src\Elasticsearch.Net\Utf8Json\JsonReader.cs:line 466
   at Deserialize(Object[] , JsonReader& , IJsonFormatterResolver )
   at Elasticsearch.Net.Utf8Json.JsonSerializer.Deserialize[T](Byte[] bytes, Int32 offset, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.Utf8Json.JsonSerializer.DeserializeAsync[T](Stream stream, IJsonFormatterResolver resolver)
   at Elasticsearch.Net.ResponseBuilder.SetBodyAsync[TResponse](ApiCallDetails details, RequestData requestData, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.ResponseBuilder.ToResponseAsync[TResponse](RequestData requestData, Exception ex, Nullable`1 statusCode, IEnumerable`1 warnings, Stream responseStream, String mimeType, CancellationToken cancellationToken)
   at Elasticsearch.Net.HttpConnection.RequestAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.RequestPipeline.CallElasticsearchAsync[TResponse](RequestData requestData, CancellationToken cancellationToken)
   at Elasticsearch.Net.Transport`1.RequestAsync[TResponse](HttpMethod method, String path, CancellationToken cancellationToken, PostData data, IRequestParameters requestParameters)
[2019-06-03T16:05:54,911][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-fluentasync-a0605488]
[2019-06-03T16:05:55,166][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-fluentasync-a0605488] deleted
[2019-06-03T16:05:55,328][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializer-5b2e9ab1]
[2019-06-03T16:05:55,466][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializer-5b2e9ab1] deleted
[2019-06-03T16:05:55,619][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Running DBQ on [.ml-anomalies-shared] for job [nest-initializerasync-4ce74dd5]
[2019-06-03T16:05:55,753][INFO ][o.e.x.m.a.TransportDeleteJobAction] [machinelearning-node-5f55a79200] Job [nest-initializerasync-4ce74dd5] deleted
Failed   Tests.XPack.MachineLearning.OpenJob.OpenJobApiTests.ReturnsExpectedIsValid
Error Message:
 Tests.Framework.EndpointTests.ResponseAssertionException : Expected response.IsValid to be True because Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0120226
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\t... 16 more
"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\t... 16 more
"
  },
  "status" : 429
}

, but found False.
Response Under Test:
Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0120226
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


---- Expected response.IsValid to be True because Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0120226
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\t... 16 more
"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)
\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)
\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)
\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)
\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)
\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)
\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)
\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)
\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)
\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)
\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)
\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
\tat java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)
\t... 16 more
"
  },
  "status" : 429
}

, but found False.
Stack Trace:
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void FluentAssertions.Execution.XUnit2TestFramework.Throw(string message) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/XUnit2TestFramework.cs:line 32
   at Continuation FluentAssertions.Execution.AssertionScope.FailWith(Func<FailReason> failReasonFunc) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/AssertionScope.cs:line 181
   at AndConstraint<BooleanAssertions> FluentAssertions.Primitives.BooleanAssertions.Be(bool expected, string because, object[] becauseArgs) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Primitives/BooleanAssertions.cs:line 80
   at void Tests.Core.Extensions.ShouldExtensions.ShouldHaveExpectedIsValid(IResponse response, bool expectedIsValid) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests.Core/Extensions/ShouldExtensions.cs:line 12
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
Failed   Tests.XPack.MachineLearning.OpenJob.OpenJobApiTests.ReturnsExpectedResponse
Error Message:
 Tests.Framework.EndpointTests.ResponseAssertionException : Expected response.Opened to be true, but found False.
Response Under Test:
Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0120226
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


---- Expected response.Opened to be true, but found False.
Stack Trace:
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void FluentAssertions.Execution.XUnit2TestFramework.Throw(string message) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/XUnit2TestFramework.cs:line 32
   at Continuation FluentAssertions.Execution.AssertionScope.FailWith(Func<FailReason> failReasonFunc) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/AssertionScope.cs:line 181
   at AndConstraint<BooleanAssertions> FluentAssertions.Primitives.BooleanAssertions.BeTrue(string because, object[] becauseArgs) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Primitives/BooleanAssertions.cs:line 59
   at void Tests.XPack.MachineLearning.OpenJob.OpenJobApiTests.ExpectResponse(OpenJobResponse response) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/XPack/MachineLearning/OpenJob/OpenJobApiTests.cs:line 44
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
Failed   Tests.XPack.MachineLearning.OpenJob.OpenJobApiTests.ReturnsExpectedStatusCode
Error Message:
 Tests.Framework.EndpointTests.ResponseAssertionException : Expected response.Opened to be true, but found False.
Response Under Test:
Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0120226
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-f6469bd7/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-f6469bd7] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


---- Expected response.Opened to be true, but found False.
Stack Trace:
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void FluentAssertions.Execution.XUnit2TestFramework.Throw(string message) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/XUnit2TestFramework.cs:line 32
   at Continuation FluentAssertions.Execution.AssertionScope.FailWith(Func<FailReason> failReasonFunc) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/AssertionScope.cs:line 181
   at AndConstraint<BooleanAssertions> FluentAssertions.Primitives.BooleanAssertions.BeTrue(string because, object[] becauseArgs) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Primitives/BooleanAssertions.cs:line 59
   at void Tests.XPack.MachineLearning.OpenJob.OpenJobApiTests.ExpectResponse(OpenJobResponse response) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/XPack/MachineLearning/OpenJob/OpenJobApiTests.cs:line 44
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
[2019-06-03T16:06:04,154][WARN ][o.e.x.m.a.T.OpenJobPersistentTasksExecutor] [machinelearning-node-5f55a79200] [nest-fluent-84d5da9d] Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]
Failed   Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.ReturnsExpectedResponse
Error Message:
 System.Exception : Problem opening job nest-fluent-84d5da9d for integration test: Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0114300
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


Stack Trace:
   at Tests.XPack.MachineLearning.MachineLearningIntegrationTestBase`4.OpenJob(IElasticClient client, String jobId) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\MachineLearningIntegrationTestBase.cs:line 140
   at Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\PostJobData\PostJobDataApiTests.cs:line 67
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
Failed   Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.ReturnsExpectedIsValid
Error Message:
 System.Exception : Problem opening job nest-fluent-84d5da9d for integration test: Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0114300
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


Stack Trace:
   at Tests.XPack.MachineLearning.MachineLearningIntegrationTestBase`4.OpenJob(IElasticClient client, String jobId) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\MachineLearningIntegrationTestBase.cs:line 140
   at Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\PostJobData\PostJobDataApiTests.cs:line 67
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedIsValid() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 47
--- End of stack trace from previous location where exception was thrown ---
Failed   Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.ReturnsExpectedStatusCode
Error Message:
 System.Exception : Problem opening job nest-fluent-84d5da9d for integration test: Invalid NEST response built from a unsuccessful low level call on POST: /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] BadResponse: Node: https://localhost:9200/ Took: 00:00:00.0114300
# OriginalException: Elasticsearch.Net.ElasticsearchClientException: Request failed to execute. Call: Status code 429 from: POST /_ml/anomaly_detectors/nest-fluent-84d5da9d/_open?pretty=true&error_trace=true. ServerError: Type: status_exception Reason: "Could not open job because no ML nodes with sufficient capacity were found" CausedBy: "Type: illegal_state_exception Reason: "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]""
# Request:
{}
# Response:
{
  "error" : {
    "root_cause" : [
      {
        "type" : "status_exception",
        "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
        "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
      }
    ],
    "type" : "status_exception",
    "reason" : "Could not open job because no ML nodes with sufficient capacity were found",
    "caused_by" : {
      "type" : "illegal_state_exception",
      "reason" : "Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]",
      "stack_trace" : "java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n"
    },
    "stack_trace" : "ElasticsearchStatusException[Could not open job because no ML nodes with sufficient capacity were found]; nested: IllegalStateException[Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]];\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:790)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:632)\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction$OpenJobPersistentTasksExecutor.validate(TransportOpenJobAction.java:529)\r\n\tat org.elasticsearch.persistent.PersistentTasksClusterService$1.execute(PersistentTasksClusterService.java:105)\r\n\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\r\n\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\r\n\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\r\n\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\r\n\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\r\n\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\r\n\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\r\n\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Could not open job because no suitable nodes were found, allocation explanation [Not opening job [nest-fluent-84d5da9d] on node [{machinelearning-node-5f55a79200}{ml.machine_memory=17010651136}{ml.max_open_jobs=30}], because this node has insufficient available memory. Available memory for ML [5103195340], memory required by existing jobs [4714397696], estimated memory required for this job [1178599424]]\r\n\tat org.elasticsearch.xpack.ml.action.TransportOpenJobAction.makeNoSuitableNodesException(TransportOpenJobAction.java:789)\r\n\t... 16 more\r\n"
  },
  "status" : 429
}


Stack Trace:
   at Tests.XPack.MachineLearning.MachineLearningIntegrationTestBase`4.OpenJob(IElasticClient client, String jobId) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\MachineLearningIntegrationTestBase.cs:line 140
   at Tests.XPack.MachineLearning.PostJobData.PostJobDataApiTests.IntegrationSetup(IElasticClient client, CallUniqueValues values) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\MachineLearning\PostJobData\PostJobDataApiTests.cs:line 67
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.<>c__DisplayClass37_0.<<Calls>b__0>d.MoveNext() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 96
--- End of stack trace from previous location where exception was thrown ---
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 130
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
[2019-06-03T16:06:15,912][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] stopping ...
[2019-06-03T16:06:15,923][INFO ][o.e.x.w.WatcherService   ] [machinelearning-node-5f55a79200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:06:16,001][WARN ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluent-756dfedf-job] some results not processed due to the process being killed
[2019-06-03T16:06:16,009][WARN ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-fluentasync-27bc6942-job] some results not processed due to the process being killed
[2019-06-03T16:06:16,025][WARN ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializer-5b4ecb9d-job] some results not processed due to the process being killed
[2019-06-03T16:06:16,030][WARN ][o.e.x.m.j.p.a.o.AutoDetectResultProcessor] [machinelearning-node-5f55a79200] [nest-initializerasync-46d945f4-job] some results not processed due to the process being killed
[2019-06-03T16:06:16,033][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [machinelearning-node-5f55a79200] [controller/16012] [Main.cc@148] Ml controller exiting
[2019-06-03T16:06:16,034][INFO ][o.e.x.m.p.NativeController] [machinelearning-node-5f55a79200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:06:16,346][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] stopped
[2019-06-03T16:06:16,346][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] closing ...
[2019-06-03T16:06:16,383][INFO ][o.e.n.Node               ] [machinelearning-node-5f55a79200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:06:16,527][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\data}
[2019-06-03T06:06:16,606][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\config}
[2019-06-03T06:06:16,612][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\logs}
[2019-06-03T06:06:16,614][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb\repositories}
[2019-06-03T06:06:16,614][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-ebc0cb}
[2019-06-03T06:06:16,772][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [Security|XPack|SSL]
[2019-06-03T06:06:16,772][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:06:16,772][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-8f58a7]
[2019-06-03T06:06:16,773][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [True]
[2019-06-03T06:06:16,773][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [True]
[2019-06-03T06:06:16,773][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:06:16,774][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [x-pack]
[2019-06-03T06:06:16,774][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [Trial]
[2019-06-03T06:06:16,774][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:06:16,775][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:06:16,775][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:06:16,775][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:06:16,776][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:06:16,776][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:06:16,776][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:06:16,777][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:06:16,777][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home]
[2019-06-03T06:06:18,536][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:06:18,537][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7}
[2019-06-03T06:06:18,538][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config}
[2019-06-03T06:06:18,539][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config]
[2019-06-03T06:06:18,552][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} attempting to add xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\elasticsearch.yml]
[2019-06-03T06:06:18,553][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} saved xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\elasticsearch.yml]
[2019-06-03T06:06:18,554][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} adding roles to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\roles.yml
[2019-06-03T06:06:18,556][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} saved roles to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\roles.yml]
[2019-06-03T06:06:18,557][INFO ][Managed Elasticsearch    ]  {EnsureSecurityUsersInDefaultRealmAreAdded} using cached users and users_roles files from {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\config}
[2019-06-03T06:06:18,557][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} creating config files
[2019-06-03T06:06:18,557][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\node-certificates.zip
[2019-06-03T06:06:18,558][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates
[2019-06-03T06:06:18,564][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\unused-node-certificates.zip
[2019-06-03T06:06:18,564][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\unused-node-certificates
[2019-06-03T06:06:18,573][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack]
[2019-06-03T06:06:18,575][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\analysis]
[2019-06-03T06:06:18,581][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationInElasticsearchYaml} saved watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\elasticsearch.yml]
[2019-06-03T06:06:18,582][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [creating elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home\bin\elasticsearch-keystore.bat} {create}
Created elasticsearch keystore in C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config
[2019-06-03T06:06:24,894][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [creating elasticsearch.keystore] {0}
[2019-06-03T06:06:24,895][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home\bin\elasticsearch-keystore.bat} {add xpack.notification.slack.account.monitoring.secure_url -xf}
[2019-06-03T06:06:26,519][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {0}
[2019-06-03T06:06:26,519][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home\bin\elasticsearch-keystore.bat} {add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key -xf}
[2019-06-03T06:06:27,976][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {0}
[2019-06-03T06:06:27,977][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationSecretsInKeystore} added watcher action secrets to elasticsearch.keystore
[2019-06-03T06:06:27,978][INFO ][Managed Elasticsearch    ]  {EnsureNativeSecurityRealmEnabledInElasticsearchYaml} native security realm [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\elasticsearch.yml]
[2019-06-03T06:06:27,979][INFO ][Managed Elasticsearch    ] [xpack-node-eddf039200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home\bin\elasticsearch.bat]
[2019-06-03T06:06:27,980][INFO ][Managed Elasticsearch    ] [xpack-node-eddf039200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-8f58a7 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\logs -E xpack.security.enabled=true -E xpack.security.http.ssl.enabled=true -E xpack.security.transport.ssl.enabled=true -E xpack.security.authc.realms.pki.pki1.enabled=true -E xpack.security.authc.token.enabled=true -E xpack.security.transport.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\node01\node01.key -E xpack.security.transport.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\node01\node01.crt -E xpack.security.transport.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\ca\ca.crt -E xpack.security.http.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\node01\node01.key -E xpack.security.http.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\node01\node01.crt -E xpack.security.http.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\node-certificates\ca\ca.crt -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=xpack-node-eddf039200 -E http.port=9200 -E cluster.initial_master_nodes=xpack-node-eddf039200}
[2019-06-03T16:06:31,362][INFO ][o.e.e.NodeEnvironment    ] [xpack-node-eddf039200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:06:31,365][INFO ][o.e.e.NodeEnvironment    ] [xpack-node-eddf039200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:06:31,370][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] node name [xpack-node-eddf039200], node ID [9_ulPjASQ4G7hjVGqIntjQ]
[2019-06-03T16:06:31,371][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] version[7.0.0], pid[16036], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:06:31,372][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:06:31,372][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:06:45,422][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [aggs-matrix-stats]
[2019-06-03T16:06:45,422][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [analysis-common]
[2019-06-03T16:06:45,422][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [ingest-common]
[2019-06-03T16:06:45,422][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [ingest-geoip]
[2019-06-03T16:06:45,423][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [ingest-user-agent]
[2019-06-03T16:06:45,423][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [lang-expression]
[2019-06-03T16:06:45,423][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [lang-mustache]
[2019-06-03T16:06:45,423][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [lang-painless]
[2019-06-03T16:06:45,424][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [mapper-extras]
[2019-06-03T16:06:45,424][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [parent-join]
[2019-06-03T16:06:45,424][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [percolator]
[2019-06-03T16:06:45,424][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [rank-eval]
[2019-06-03T16:06:45,424][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [reindex]
[2019-06-03T16:06:45,425][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [repository-url]
[2019-06-03T16:06:45,425][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [transport-netty4]
[2019-06-03T16:06:45,425][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-ccr]
[2019-06-03T16:06:45,425][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-core]
[2019-06-03T16:06:45,425][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-deprecation]
[2019-06-03T16:06:45,426][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-graph]
[2019-06-03T16:06:45,426][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-ilm]
[2019-06-03T16:06:45,426][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-logstash]
[2019-06-03T16:06:45,426][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-ml]
[2019-06-03T16:06:45,427][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-monitoring]
[2019-06-03T16:06:45,427][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-rollup]
[2019-06-03T16:06:45,427][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-security]
[2019-06-03T16:06:45,427][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-sql]
[2019-06-03T16:06:45,427][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] loaded module [x-pack-watcher]
[2019-06-03T16:06:45,428][INFO ][o.e.p.PluginsService     ] [xpack-node-eddf039200] no plugins loaded
[2019-06-03T16:06:49,597][INFO ][o.e.x.s.a.s.FileRolesStore] [xpack-node-eddf039200] parsed [3] roles from file [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config\roles.yml]
[2019-06-03T16:06:50,299][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [xpack-node-eddf039200] [controller/11692] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:06:50,619][DEBUG][o.e.a.ActionModule       ] [xpack-node-eddf039200] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2019-06-03T16:06:50,900][INFO ][o.e.d.DiscoveryModule    ] [xpack-node-eddf039200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:06:51,633][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] initialized
[2019-06-03T16:06:51,634][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] starting ...
[2019-06-03T16:06:52,486][INFO ][o.e.t.TransportService   ] [xpack-node-eddf039200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:06:52,494][WARN ][o.e.b.BootstrapChecks    ] [xpack-node-eddf039200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:06:52,507][INFO ][o.e.c.c.ClusterBootstrapService] [xpack-node-eddf039200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:06:55,513][INFO ][o.e.c.c.Coordinator      ] [xpack-node-eddf039200] setting initial configuration to VotingConfiguration{9_ulPjASQ4G7hjVGqIntjQ}
[2019-06-03T16:06:55,675][INFO ][o.e.c.s.MasterService    ] [xpack-node-eddf039200] elected-as-master ([1] nodes joined)[{xpack-node-eddf039200}{9_ulPjASQ4G7hjVGqIntjQ}{vZdWemdgQjKfpyMklnSiRA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{xpack-node-eddf039200}{9_ulPjASQ4G7hjVGqIntjQ}{vZdWemdgQjKfpyMklnSiRA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:06:55,771][INFO ][o.e.c.s.ClusterApplierService] [xpack-node-eddf039200] master node changed {previous [], current [{xpack-node-eddf039200}{9_ulPjASQ4G7hjVGqIntjQ}{vZdWemdgQjKfpyMklnSiRA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:06:55,955][INFO ][o.e.g.GatewayService     ] [xpack-node-eddf039200] recovered [0] indices into cluster_state
[2019-06-03T16:06:56,122][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:06:56,187][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:06:56,258][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:06:56,312][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:06:56,376][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:06:56,433][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:06:56,487][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:06:56,537][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:06:56,587][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [xpack-node-eddf039200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:06:56,758][INFO ][o.e.l.LicenseService     ] [xpack-node-eddf039200] license [af7e352e-c3b2-4d80-bbf8-68ac510245da] mode [basic] - valid
[2019-06-03T16:06:57,115][INFO ][o.e.h.AbstractHttpServerTransport] [xpack-node-eddf039200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:06:57,116][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] started
[2019-06-03T06:06:57,117][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T06:06:57,306][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:06:57,357][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} attempting to post license json
[2019-06-03T16:06:57,547][INFO ][o.e.l.LicenseService     ] [xpack-node-eddf039200] license [integ-test-license] mode [platinum] - valid
[2019-06-03T06:06:57,552][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:06:57,746][INFO ][Managed Elasticsearch    ]  All good! kicking off [XPackCluster] tests now
[2019-06-03T16:06:57,809][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [xpack-node-eddf039200] failed to delete templates [nest_tests]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [nest_tests] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:06:57,897][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:57,903][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:57,905][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:57,929][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:57,934][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:57,936][INFO ][o.e.c.s.ClusterSettings  ] [xpack-node-eddf039200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:06:58,005][WARN ][o.e.t.OutboundHandler    ] [xpack-node-eddf039200] send message failed [channel: Netty4TcpChannel{localAddress=/127.0.0.1:52335, remoteAddress=/127.0.0.1:9300}]
javax.net.ssl.SSLException: SSLEngine closed already
	at io.netty.handler.ssl.SslHandler.wrap(...) (Unknown Source) ~[?:?]
[2019-06-03T16:06:58,010][WARN ][o.e.x.c.s.t.n.SecurityNetty4Transport] [xpack-node-eddf039200] client did not trust this server's certificate, closing connection Netty4TcpChannel{localAddress=0.0.0.0/0.0.0.0:9300, remoteAddress=/127.0.0.1:52335}
[2019-06-03T16:06:58,014][WARN ][o.e.t.TcpTransport       ] [xpack-node-eddf039200] exception caught on transport layer [Netty4TcpChannel{localAddress=/127.0.0.1:52335, remoteAddress=/127.0.0.1:9300}], closing connection
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Handshaker.checkThrown(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.checkTaskThrown(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.readNetRecord(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.unwrap(Unknown Source) ~[?:?]
	at javax.net.ssl.SSLEngine.unwrap(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:295) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1301) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Alerts.getSSLException(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.fatal(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.fatal(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.fatalSE(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.fatalSE(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.checkServerCerts(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.serverCertificate(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.processMessage(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.processLoop(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at sun.security.ssl.Handshaker$DelegatedTask.run(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1464) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1369) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
Caused by: java.security.cert.CertificateException: No subject alternative names present
	at sun.security.util.HostnameChecker.matchIP(Unknown Source) ~[?:?]
	at sun.security.util.HostnameChecker.match(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkIdentity(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkIdentity(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkTrusted(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.checkServerCerts(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.serverCertificate(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.processMessage(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.processLoop(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at sun.security.ssl.Handshaker$DelegatedTask.run(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1464) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1369) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
[2019-06-03T16:06:58,015][WARN ][o.e.t.RemoteClusterConnection] [xpack-node-eddf039200] fetching nodes from external cluster [remote-cluster] failed
org.elasticsearch.transport.ConnectTransportException: [][127.0.0.1:9300] general node connection failure
	at org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener$1.onFailure(TcpTransport.java:1284) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker$HandshakeResponseHandler.handleLocalException(TransportHandshaker.java:155) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker.lambda$sendHandshake$0(TransportHandshaker.java:67) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$wrap$0(ActionListener.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:97) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:39) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(Unknown Source) ~[?:?]
	at org.elasticsearch.common.concurrent.CompletableContext.complete(CompletableContext.java:61) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.netty4.Netty4TcpChannel.lambda$new$0(Netty4TcpChannel.java:51) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103) ~[?:?]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[?:?]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1152) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:768) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:744) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:615) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.close(DefaultChannelPipeline.java:1376) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:624) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:608) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:465) ~[?:?]
	at io.netty.handler.ssl.SslUtils.handleHandshakeFailure(SslUtils.java:350) ~[?:?]
	at io.netty.handler.ssl.SslHandler.setHandshakeFailure(SslHandler.java:1581) ~[?:?]
	at io.netty.handler.ssl.SslHandler.handleUnwrapThrowable(SslHandler.java:1239) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1209) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[?:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) ~[?:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) ~[?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: handshake failed because connection reset
	... 47 more
[2019-06-03T16:06:58,063][WARN ][o.e.t.RemoteClusterService] [xpack-node-eddf039200] failed to update seed list for cluster: remote-cluster
org.elasticsearch.transport.ConnectTransportException: [][127.0.0.1:9300] general node connection failure
	at org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener$1.onFailure(TcpTransport.java:1284) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker$HandshakeResponseHandler.handleLocalException(TransportHandshaker.java:155) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker.lambda$sendHandshake$0(TransportHandshaker.java:67) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$wrap$0(ActionListener.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:97) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:39) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(Unknown Source) ~[?:?]
	at org.elasticsearch.common.concurrent.CompletableContext.complete(CompletableContext.java:61) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.netty4.Netty4TcpChannel.lambda$new$0(Netty4TcpChannel.java:51) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103) ~[?:?]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[?:?]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1152) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:768) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:744) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:615) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.close(DefaultChannelPipeline.java:1376) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:624) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:608) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:465) ~[?:?]
	at io.netty.handler.ssl.SslUtils.handleHandshakeFailure(SslUtils.java:350) ~[?:?]
	at io.netty.handler.ssl.SslHandler.setHandshakeFailure(SslHandler.java:1581) ~[?:?]
	at io.netty.handler.ssl.SslHandler.handleUnwrapThrowable(SslHandler.java:1239) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1209) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[?:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) ~[?:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) ~[?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: handshake failed because connection reset
	... 47 more
[2019-06-03T16:06:58,070][INFO ][o.e.c.m.MetaDataIndexTemplateService] [xpack-node-eddf039200] adding template [nest_tests] for index patterns [*]
[2019-06-03T16:06:58,260][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [devs] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:06:58,467][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [project] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:06:58,595][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [queries] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:06:59,082][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[queries][0]] ...]).
[2019-06-03T16:06:59,419][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [project/Op_Sz5beTkihMuFJlU0wCA] update_mapping [_doc]
[2019-06-03T16:07:00,408][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [project/Op_Sz5beTkihMuFJlU0wCA] update_mapping [_doc]
[2019-06-03T16:07:02,509[xUnit.net 00:10:03.3494246]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.GlobalStatsResponse [SKIP]
[xUnit.net 00:10:03.3516986]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.GetReturnsAndIsMapped [SKIP]
][[xUnit.net 00:10:03.3522050]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.DeleteIsAcked [SKIP]
INFO ][[xUnit.net 00:10:03.3527152]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.CreateIsAcked [SKIP]
o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [nest-fluent-7a39cf7e] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:02,704][INFO ][o.e.x.s.s.SecurityIndexManager] [xpack-node-eddf039200] security index does not exist. Creating [.security-7]Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.GlobalStatsResponse
 with alias [.securitySkipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.GetReturnsAndIsMapped
]
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.DeleteIsAcked
[2019-06-03T16:07:02,892]Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationAutoFollowTests.CreateIsAcked
[INFO ][o.e.x.s.s.SecurityIndexManager] [xpack-node-eddf039200] security index does not exist. Creating [.security-7] with alias [.security]
[2019-06-03T16:07:02,907][INFO ][o.e.x.s.s.SecurityIndexManager] [xpack-node-eddf039200] security index does not exist. Creating [.security-7] with alias [.security]
[xUnit.net 00:10:09.7643479]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowAfterCloseIsAcked [SKIP]
[xUnit.net 00:10:09.7645398]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowStatsResponseAgain [SKIP]
[xUnit.net 00:10:09.7646544]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.LeadersAreDeleted [SKIP]
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowAfterCloseIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowStatsResponseAgain
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.LeadersAreDeleted
[xUnit.net 00:10:09.7652394]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowWithoutCloseIsAcked [SKIP]
[xUnit.net 00:10:09.7653857]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.ResumeIsAcked [SKIP]
[xUnit.net 00:10:09.7655031]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.PauseBeforeCloseIsAcked [SKIP]
[xUnit.net 00:10:09.7656160]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.IndexingDataIsOk [SKIP]
[xUnit.net 00:10:09.7657284]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CreateReadOnlyIndexIsOk [SKIP]
[xUnit.net 00:10:09.7658388]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowStatsResponse [SKIP]
[xUnit.net 00:10:09.7659545]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.PauseIsAcked [SKIP]
[xUnit.net 00:10:09.7660673]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CountBeforeHasDocs [SKIP]
[xUnit.net 00:10:09.7661844]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowReturns [SKIP]
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowWithoutCloseIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.ResumeIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.PauseBeforeCloseIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.IndexingDataIsOk
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CreateReadOnlyIndexIsOk
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowStatsResponse
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.PauseIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CountBeforeHasDocs
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.UnfollowReturns
[xUnit.net 00:10:09.7667870]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowResponseIsValid [SKIP]
[xUnit.net 00:10:09.7669277]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CloseIsAcked [SKIP]
[xUnit.net 00:10:09.7670465]     Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.GlobalStatsResponse [SKIP]
[xUnit.net 00:10:09.7671766]     Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedStatusCode [SKIP]
[xUnit.net 00:10:09.7672909]     Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedResponse [SKIP]
[xUnit.net 00:10:09.7674058]     Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedIsValid [SKIP]
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.FollowResponseIsValid
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.CloseIsAcked
Skipped  Tests.XPack.CrossClusterReplication.CrossClusterReplicationFollowTests.GlobalStatsResponse
Skipped  Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedStatusCode
Skipped  Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedResponse
Skipped  Tests.XPack.CrossClusterReplication.AutoFollow.GetAutoFollowPattern.GetAutoFollowPatternApiTests.ReturnsExpectedIsValid
Failed   Tests.XPack.Sql.TranslateSql.TranslateSqlApiTests.ReturnsExpectedResponse
Error Message:
 Tests.Framework.EndpointTests.ResponseAssertionException : Expected search.Size not to be <null>.
Response Under Test:
Valid NEST response built from a successful low level call on POST: /_sql/translate?pretty=true&error_trace=true
# Audit trail of this API call:
 - [1] HealthyResponse: Node: https://localhost:9200/ Took: 00:00:00.0217925
# Request:
{"fetch_size":5,"query":"SELECT type, name, startedOn, numberOfCommits\r\nFROM project\r\nWHERE type = 'project'\r\nORDER BY numberOfContributors DESC"}
# Response:
{
  "size" : 5,
  "query" : {
    "term" : {
      "type" : {
        "value" : "project",
        "boost" : 1.0
      }
    }
  },
  "_source" : false,
  "stored_fields" : "_none_",
  "docvalue_fields" : [
    {
      "field" : "type"
    },
    {
      "field" : "name"
    },
    {
      "field" : "startedOn",
      "format" : "epoch_millis"
    },
    {
      "field" : "numberOfCommits"
    }
  ],
  "sort" : [
    {
      "numberOfContributors" : {
        "order" : "desc",
        "missing" : "_first",
        "unmapped_type" : "integer"
      }
    }
  ]
}


---- Expected search.Size not to be <null>.
Stack Trace:
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.<>c__DisplayClass17_0.<AssertOnAllResponses>b__0(TResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 71
   at Tests.Framework.EndpointTests.RequestResponseApiTestBase`5.AssertOnAllResponses(Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\RequestResponseApiTestBase.cs:line 131
   at Tests.Framework.EndpointTests.ApiIntegrationTestBase`5.ReturnsExpectedResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\ApiIntegrationTestBase.cs:line 49
--- End of stack trace from previous location where exception was thrown ---
----- Inner Stack Trace -----
   at void FluentAssertions.Execution.XUnit2TestFramework.Throw(string message) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/XUnit2TestFramework.cs:line 32
   at Continuation FluentAssertions.Execution.AssertionScope.FailWith(Func<FailReason> failReasonFunc) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Execution/AssertionScope.cs:line 181
   at AndConstraint<TAssertions> FluentAssertions.Primitives.ReferenceTypeAssertions<TSubject, TAssertions>.NotBeNull(string because, object[] becauseArgs) in C:/projects/fluentassertions-vf06b/Src/FluentAssertions/Primitives/ReferenceTypeAssertions.cs:line 62
   at void Tests.XPack.Sql.TranslateSql.TranslateSqlApiTests.ExpectResponse(TranslateSqlResponse response) in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/XPack/Sql/TranslateSql/TranslateSqlQueryApiTests.cs:line 61
   at Task Tests.Framework.EndpointTests.ApiIntegrationTestBase<TCluster, TResponse, TInterface, TDescriptor, TInitializer>.AssertOnAllResponses(Action<TResponse> assert)+(TResponse r) => { } in c:/Source/elasticsearch-net-7.x/src/Tests/Tests/Framework/EndpointTests/ApiIntegrationTestBase.cs:line 66
[2019-06-03T16:07:03,205][INFO ][o.e.x.s.s.SecurityIndexManager] [xpack-node-eddf039200] security index does not exist. Creating [.security-7] with alias [.security]
[2019-06-03T16:07:03,417][ERROR][o.e.x.s.a.e.NativeUsersStore] [xpack-node-eddf039200] security index is unavailable. short circuiting retrieval of user [es_admin]
[2019-06-03T16:07:03,447][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm file1 failed - Password authentication failed for es_admin
[2019-06-03T16:07:03,492][INFO ][o.e.x.s.s.SecurityIndexManager] [xpack-node-eddf039200] security index does not exist. Creating [.security-7] with alias [.security]
[2019-06-03T16:07:03,577][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [.security-7] creating index, cause [api], templates [nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:07:03,886][ERROR][o.e.x.s.a.e.NativeUsersStore] [xpack-node-eddf039200] security index is unavailable. short circuiting retrieval of user [es_admin]
[2019-06-03T16:07:03,886][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm file1 failed - Password authentication failed for es_admin
[2019-06-03T16:07:04,443][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [.watches] creating index, cause [auto(bulk api)], templates [.watches, nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:07:04,853][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm file1 failed - Password authentication failed for es_admin
[2019-06-03T16:07:05,014][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.security-7/zYmqZ7QhRomMwn9DALGcTg] update_mapping [_doc]
[2019-06-03T16:07:05,148][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [nest-fluentasync-420cce40] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:05,187][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm file1 failed - Password authentication failed for es_admin
[2019-06-03T16:07:05,570][INFO ][o.e.x.w.WatcherService   ] [xpack-node-eddf039200] reloading watcher, reason [new local watcher shard allocation ids], cancelled [0] queued tasks
[2019-06-03T16:07:05,804][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-f-39829331]
[2019-06-03T16:07:05,868][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluentasync-420cce40][0]] ...]).
[2019-06-03T16:07:05,918][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.security-7/zYmqZ7QhRomMwn9DALGcTg] update_mapping [_doc]
[2019-06-03T16:07:05,959][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [nest-initializer-54fb15eb] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:06,221][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializer-54fb15eb][1]] ...]).
[2019-06-03T16:07:06,281][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [nest-initializerasync-8a74bb71] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:06,292][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializerasync-4ce422d3]
[2019-06-03T16:07:06,682][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.watches/HKzU-zBaQnOTSvmr--aiNQ] update_mapping [_doc]
[2019-06-03T16:07:06,743][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializerasync-8a74bb71][1], [nest-initializerasync-8a74bb71][0]] ...]).
[2019-06-03T16:07:06,826][INFO ][o.e.c.m.MetaDataDeleteIndexService] [xpack-node-eddf039200] [nest-fluent-7a39cf7e/uy07NCTASh2CWNhbD1yGsQ] deleting index
[2019-06-03T16:07:06,929][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializerasync-3471ba8a]
[2019-06-03T16:07:12,334][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [nest-initializerasync-2ad9fac2]
[2019-06-03T16:07:09,870][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-f-39829331]
[2019-06-03T16:07:07,621][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluentasync-e3bdd420]
[2019-06-03T16:07:07,322][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-fa-7aedc855]
[2019-06-03T16:07:17,809][ERROR][o.e.x.w.a.e.ExecutableEmailAction] [xpack-node-eddf039200] failed to execute action [_inlined_/email_admin]
java.lang.IllegalArgumentException: no accounts of type [email] configured. Please set up an account using the [xpack.notification.email] settings
	at org.elasticsearch.xpack.watcher.notification.NotificationService.getAccount(NotificationService.java:114) ~[?:?]
	at org.elasticsearch.xpack.watcher.notification.email.EmailService.send(EmailService.java:140) ~[?:?]
	at org.elasticsearch.xpack.watcher.actions.email.ExecutableEmailAction.execute(ExecutableEmailAction.java:72) ~[?:?]
	at org.elasticsearch.xpack.core.watcher.actions.ActionWrapper.execute(ActionWrapper.java:144) [x-pack-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.executeInner(ExecutionService.java:460) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.execute(ExecutionService.java:299) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.transport.actions.execute.TransportExecuteWatchAction$1.doRun(TransportExecuteWatchAction.java:159) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService$WatchExecutionTask.run(ExecutionService.java:549) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:07:07,008][INFO ][o.e.c.m.MetaDataDeleteIndexService] [xpack-node-eddf039200] [nest-fluentasync-420cce40/aLzyvf4zQXevw2_R4nkdwQ] deleting index
[2019-06-03T16:07:17,790][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-fluent-685d8e96-role]
[2019-06-03T16:07:17,767][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [ufluent-d91aa928]
[2019-06-03T16:07:17,951][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [test] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:18,061][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [test-nest-fluent-593cbec8] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:18,148][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluent-2567a0ef]
[2019-06-03T16:07:18,148][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-o-cf2137fa]
[2019-06-03T16:07:18,196][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [test-nest-fluent-367efd65] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:07:18,249][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [.triggered_watches] creating index, cause [auto(bulk api)], templates [.triggered_watches, nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:07:18,297][INFO ][o.e.c.m.MetaDataDeleteIndexService] [xpack-node-eddf039200] [nest-initializer-54fb15eb/0k32LMmaT6G5DCXaAnF2VQ] deleting index
[2019-06-03T16:07:18,473][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-o-cf2137fa]
[2019-06-03T16:07:18,473][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluent-1a7a0165]
[2019-06-03T16:07:18,532][INFO ][o.e.c.m.MetaDataDeleteIndexService] [xpack-node-eddf039200] [nest-initializerasync-8a74bb71/JOp_1eq2Qe-4Emcwlpg55g] deleting index
[2019-06-03T16:07:18,660][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-fluentasync-bdcbf5c1-role]
[2019-06-03T16:07:18,699][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[test-nest-fluent-367efd65][0]] ...]).
[2019-06-03T16:07:18,728][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.security-7/zYmqZ7QhRomMwn9DALGcTg] update_mapping [_doc]
[2019-06-03T16:07:18,731][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.security-7/zYmqZ7QhRomMwn9DALGcTg] update_mapping [_doc]
[2019-06-03T16:07:18,801][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [xpack-node-eddf039200] adding index lifecycle policy [policyf-39829331]
[2019-06-03T16:07:18,827][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [nest-initializer-b9b05b56]
[2019-06-03T16:07:18,864][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [xpack-node-eddf039200] adding index lifecycle policy [policyfa-7aedc855]
[2019-06-03T16:07:18,913][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [xpack-node-eddf039200] adding index lifecycle policy [policyo-cf2137fa]
[2019-06-03T16:07:18,956][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [xpack-node-eddf039200] adding index lifecycle policy [policyoa-29483748]
[2019-06-03T16:07:19,000][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [ufluentasync-1bcc8196]
[2019-06-03T16:07:19,216][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializerasync-4fb49e26]
[2019-06-03T16:07:19,441][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-fa-7aedc855]
[2019-06-03T16:07:19,474][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [test/jY-zX3FLQGy6wuv-nMNtNA] create_mapping [_doc]
[2019-06-03T16:07:19,526][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:19,535][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [test-nest-fluent-593cbec8/IdHVAohdT2SbKEaKiK2QSQ] create_mapping [_doc]
[2019-06-03T16:07:19,584][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:19,587][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializer-fa4c8090]
[2019-06-03T16:07:19,590][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializer-86d06051]
[2019-06-03T16:07:19,611][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [test-nest-fluent-367efd65/xVEu0YQpSC2O5VMWkbj3Lg] create_mapping [_doc]
[2019-06-03T16:07:19,682][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [.watcher-history-9-2019.06.03] creating index, cause [auto(bulk api)], templates [.watch-history-9, nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:07:19,773][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-oa-29483748]
[2019-06-03T16:07:19,892][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.watcher-history-9-2019.06.03][0]] ...]).
[2019-06-03T16:07:19,967][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-ois-b00094b8-role]
[2019-06-03T16:07:20,060][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [nest-fluent-2b23708f]
[2019-06-03T16:07:20,257][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [uois-89cce45b]
[2019-06-03T16:07:20,413][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-initializer-418278a9]
[2019-06-03T16:07:20,676][ERROR][o.e.x.w.a.e.ExecutableEmailAction] [xpack-node-eddf039200] failed to execute action [_inlined_/email_admin]
java.lang.IllegalArgumentException: no accounts of type [email] configured. Please set up an account using the [xpack.notification.email] settings
	at org.elasticsearch.xpack.watcher.notification.NotificationService.getAccount(NotificationService.java:114) ~[?:?]
	at org.elasticsearch.xpack.watcher.notification.email.EmailService.send(EmailService.java:140) ~[?:?]
	at org.elasticsearch.xpack.watcher.actions.email.ExecutableEmailAction.execute(ExecutableEmailAction.java:72) ~[?:?]
	at org.elasticsearch.xpack.core.watcher.actions.ActionWrapper.execute(ActionWrapper.java:144) [x-pack-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.executeInner(ExecutionService.java:460) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.execute(ExecutionService.java:299) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.transport.actions.execute.TransportExecuteWatchAction$1.doRun(TransportExecuteWatchAction.java:159) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService$WatchExecutionTask.run(ExecutionService.java:549) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:07:20,872][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-oa-29483748]
[2019-06-03T16:07:21,030][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluentasync-d05a33c6]
Failed   Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.PutRoleResponse
Error Message:
 Expected boolean to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.<>c.<PutRoleResponse>b__10_0(String v, PutRoleResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 198
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 35
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.PutRoleResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 193
--- End of stack trace from previous location where exception was thrown ---
[2019-06-03T16:07:21,164][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [user-f-39829331]
[2019-06-03T16:07:21,337][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [nest-fluentasync-4484970e]
[2019-06-03T16:07:21,339][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [uoisasync-0fe6969f]
[2019-06-03T16:07:21,339][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluent-ab3dcc92]
[2019-06-03T16:07:21,340][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-oisasync-dfee09a2-role]
[2019-06-03T16:07:21,343][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:21,675][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [user-f-39829331]
[2019-06-03T16:07:21,839][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] added role [role-nest-fluentasync-836bafa9]
[2019-06-03T16:07:22,003][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [user-fa-7aedc855]
[2019-06-03T16:07:22,161][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-fluent-685d8e96-role]
[2019-06-03T16:07:22,409][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [ufluent-d91aa928]
[2019-06-03T16:07:22,547][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [user-o-cf2137fa]
[2019-06-03T16:07:22,741][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [user-o-cf2137fa]
[2019-06-03T16:07:22,750][ERROR][o.e.x.w.a.e.ExecutableEmailAction] [xpack-node-eddf039200] failed to execute action [_inlined_/email_admin]
java.lang.IllegalArgumentException: no accounts of type [email] configured. Please set up an account using the [xpack.notification.email] settings
	at org.elasticsearch.xpack.watcher.notification.NotificationService.getAccount(NotificationService.java:114) ~[?:?]
	at org.elasticsearch.xpack.watcher.notification.email.EmailService.send(EmailService.java:140) ~[?:?]
	at org.elasticsearch.xpack.watcher.actions.email.ExecutableEmailAction.execute(ExecutableEmailAction.java:72) ~[?:?]
	at org.elasticsearch.xpack.core.watcher.actions.ActionWrapper.execute(ActionWrapper.java:144) [x-pack-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.executeInner(ExecutionService.java:460) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.execute(ExecutionService.java:299) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.transport.actions.execute.TransportExecuteWatchAction$1.doRun(TransportExecuteWatchAction.java:159) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService$WatchExecutionTask.run(ExecutionService.java:549) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:07:22,944][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-fluentasync-bdcbf5c1-role]
[2019-06-03T16:07:22,967][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:23,254][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [ufluentasync-1bcc8196]
[2019-06-03T16:07:23,268][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] added user [user-oa-29483748]
[2019-06-03T16:07:23,270][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [user-fa-7aedc855]
[2019-06-03T16:07:23,469][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-ois-b00094b8-role]
[2019-06-03T16:07:23,582][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [uois-89cce45b]
[2019-06-03T16:07:23,978][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [user-oa-29483748]
Failed   Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.PutUserResponse
Error Message:
 Expected boolean to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.<>c.<PutUserResponse>b__11_0(String v, PutUserResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 204
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 35
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.PutUserResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 200
--- End of stack trace from previous location where exception was thrown ---
[2019-06-03T16:07:24,100][INFO ][o.e.x.s.a.r.TransportPutRoleAction] [xpack-node-eddf039200] updated role [role-oisasync-dfee09a2-role]
[2019-06-03T16:07:24,386][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-o-cf2137fa
[2019-06-03T16:07:24,399][INFO ][o.e.x.s.a.u.TransportPutUserAction] [xpack-node-eddf039200] updated user [uoisasync-0fe6969f]
[2019-06-03T16:07:24,408][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.watcher-history-9-2019.06.03/71cal8l5SXmxoStzTBGqNA] update_mapping [_doc]
[2019-06-03T16:07:24,669][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-o-cf2137fa
[2019-06-03T16:07:26,323][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-f-39829331
[2019-06-03T16:07:26,343][ERROR][o.e.x.w.a.e.ExecutableEmailAction] [xpack-node-eddf039200] failed to execute action [_inlined_/email_admin]
java.lang.IllegalArgumentException: no accounts of type [email] configured. Please set up an account using the [xpack.notification.email] settings
	at org.elasticsearch.xpack.watcher.notification.NotificationService.getAccount(NotificationService.java:114) ~[?:?]
	at org.elasticsearch.xpack.watcher.notification.email.EmailService.send(EmailService.java:140) ~[?:?]
	at org.elasticsearch.xpack.watcher.actions.email.ExecutableEmailAction.execute(ExecutableEmailAction.java:72) ~[?:?]
	at org.elasticsearch.xpack.core.watcher.actions.ActionWrapper.execute(ActionWrapper.java:144) [x-pack-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.executeInner(ExecutionService.java:460) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService.execute(ExecutionService.java:299) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.transport.actions.execute.TransportExecuteWatchAction$1.doRun(TransportExecuteWatchAction.java:159) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.xpack.watcher.execution.ExecutionService$WatchExecutionTask.run(ExecutionService.java:549) [x-pack-watcher-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:07:26,416][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-fa-7aedc855
[2019-06-03T16:07:26,666][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:26,868][INFO ][o.e.c.m.MetaDataCreateIndexService] [xpack-node-eddf039200] [.watcher-history-9-2016.11.17] creating index, cause [auto(bulk api)], templates [.watch-history-9, nest_tests], shards [1]/[0], mappings [_doc]
[2019-06-03T16:07:27,140][INFO ][o.e.c.r.a.AllocationService] [xpack-node-eddf039200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.watcher-history-9-2016.11.17][0]] ...]).
[2019-06-03T16:07:27,497][INFO ][o.e.c.m.MetaDataMappingService] [xpack-node-eddf039200] [.watcher-history-9-2016.11.17/U5aONm9nR1mYaNSTctqy-A] update_mapping [_doc]
[2019-06-03T16:07:27,561][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-oa-29483748
[2019-06-03T16:07:27,684][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-f-39829331
[2019-06-03T16:07:27,792][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-fa-7aedc855
[2019-06-03T16:07:28,073][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
Failed   Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.GetUserPrivilegesResponse
Error Message:
 Expected r.IsValid to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.<>c.<GetUserPrivilegesResponse>b__13_0(String v, GetUserPrivilegesResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 221
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 35
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.GetUserPrivilegesResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 219
--- End of stack trace from previous location where exception was thrown ---
Failed   Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.HasPrivilegesResponse
Error Message:
 Expected r.ApiCall.HttpStatusCode to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.<>c.<HasPrivilegesResponse>b__12_0(String v, HasPrivilegesResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 209
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 35
   at Tests.XPack.Security.Privileges.ApplicationPrivilegesApiTests.HasPrivilegesResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\Privileges\ApplicationPrivilegesApiTests.cs:line 206
--- End of stack trace from previous location where exception was thrown ---
[2019-06-03T16:07:28,613][WARN ][o.e.x.w.e.ExecutionService] [xpack-node-eddf039200] failed to execute watch [nest-fluent-367efd65]
[2019-06-03T16:07:28,613][WARN ][o.e.x.w.e.ExecutionService] [xpack-node-eddf039200] failed to execute watch [nest-fluent-367efd65]
[2019-06-03T16:07:28,679][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-oa-29483748
[2019-06-03T16:07:28,849][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:28,917][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-f-39829331
[2019-06-03T16:07:29,022][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-fa-7aedc855
[2019-06-03T16:07:29,054][INFO ][o.e.x.w.a.l.ExecutableLoggingAction] [xpack-node-eddf039200] 404 recently encountered
[2019-06-03T16:07:29,157][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-oa-29483748
[2019-06-03T16:07:29,280][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-f-39829331
[2019-06-03T16:07:29,414][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-fa-7aedc855
[2019-06-03T16:07:29,841][WARN ][o.e.x.s.a.AuthenticationService] [xpack-node-eddf039200] Authentication to realm native1 failed - Password authentication failed for user-oa-29483748
Failed   Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityInvalidateApiKeyResponse
Error Message:
 Expected r.IsValid to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.<>c.<SecurityInvalidateApiKeyResponse>b__10_0(InvalidateApiKeyResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 292
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 26
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityInvalidateApiKeyResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 290
--- End of stack trace from previous location where exception was thrown ---
Failed   Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityGetApiKeyResponse
Error Message:
 Expected r.IsValid to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.<>c.<SecurityGetApiKeyResponse>b__9_0(GetApiKeyResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 275
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 26
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityGetApiKeyResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 273
--- End of stack trace from previous location where exception was thrown ---
Failed   Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityCreateApiKeyResponse
Error Message:
 Expected r.IsValid to be true, but found False.
Stack Trace:
   at FluentAssertions.Execution.XUnit2TestFramework.Throw(String message) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\XUnit2TestFramework.cs:line 32
   at FluentAssertions.Execution.AssertionScope.FailWith(Func`1 failReasonFunc) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Execution\AssertionScope.cs:line 181
   at FluentAssertions.Primitives.BooleanAssertions.BeTrue(String because, Object[] becauseArgs) in C:\projects\fluentassertions-vf06b\Src\FluentAssertions\Primitives\BooleanAssertions.cs:line 59
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.<>c.<SecurityCreateApiKeyResponse>b__8_0(CreateApiKeyResponse r) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 266
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.AssertOnAllResponses[TResponse](String name, LazyResponses responses, Action`2 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 47
   at Tests.Framework.EndpointTests.CoordinatedIntegrationTestBase`1.Assert[TResponse](String name, Action`1 assert) in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\Framework\EndpointTests\CoordinatedIntegrationTestBase.cs:line 26
   at Tests.XPack.Security.ApiKey.SecurityApiKeyTests.SecurityCreateApiKeyResponse() in c:\Source\elasticsearch-net-7.x\src\Tests\Tests\XPack\Security\ApiKey\SecurityApiKeyTests.cs:line 264
--- End of stack trace from previous location where exception was thrown ---
[2019-06-03T16:07:33,344][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] stopping ...
[2019-06-03T16:07:33,355][INFO ][o.e.x.w.WatcherService   ] [xpack-node-eddf039200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:07:33,408][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [xpack-node-eddf039200] [controller/11692] [Main.cc@148] Ml controller exiting
[2019-06-03T16:07:33,408][INFO ][o.e.x.m.p.NativeController] [xpack-node-eddf039200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:07:34,029][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] stopped
[2019-06-03T16:07:34,029][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] closing ...
[2019-06-03T16:07:34,039][INFO ][o.e.n.Node               ] [xpack-node-eddf039200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:07:34,212][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\data}
[2019-06-03T06:07:34,293][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\config}
[2019-06-03T06:07:34,299][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\logs}
[2019-06-03T06:07:34,301][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7\repositories}
[2019-06-03T06:07:34,301][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-8f58a7}
[2019-06-03T06:07:34,505][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T06:07:34,506][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:07:34,506][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-53ffa4]
[2019-06-03T06:07:34,506][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T06:07:34,507][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T06:07:34,507][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:07:34,508][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [ingest-geoip, ingest-attachment]
[2019-06-03T06:07:34,508][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T06:07:34,509][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:07:34,509][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:07:34,509][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:07:34,510][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:07:34,510][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:07:34,511][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:07:34,511][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:07:34,511][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:07:34,512][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-ingest-attachmentingest-geoip} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\home]
[2019-06-03T06:07:36,927][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:07:36,928][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4}
[2019-06-03T06:07:36,929][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\config}
[2019-06-03T06:07:36,930][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\config]
[2019-06-03T06:07:36,935][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x-ingest-attachmentingest-geoip]
[2019-06-03T06:07:36,936][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\config\analysis]
[2019-06-03T06:07:36,939][INFO ][Managed Elasticsearch    ] [intrusiveoperation-node-72ade59200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\home\bin\elasticsearch.bat]
[2019-06-03T06:07:36,940][INFO ][Managed Elasticsearch    ] [intrusiveoperation-node-72ade59200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-53ffa4 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=intrusiveoperation-node-72ade59200 -E http.port=9200 -E cluster.initial_master_nodes=intrusiveoperation-node-72ade59200}
[2019-06-03T16:07:45,380][INFO ][o.e.e.NodeEnvironment    ] [intrusiveoperation-node-72ade59200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:07:45,384][INFO ][o.e.e.NodeEnvironment    ] [intrusiveoperation-node-72ade59200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:07:45,391][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] node name [intrusiveoperation-node-72ade59200], node ID [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:07:45,393][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] version[7.0.0], pid[3036], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:07:45,394][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:07:45,395][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:08:01,148][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [aggs-matrix-stats]
[2019-06-03T16:08:01,148][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [analysis-common]
[2019-06-03T16:08:01,148][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [ingest-common]
[2019-06-03T16:08:01,148][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [ingest-geoip]
[2019-06-03T16:08:01,148][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [ingest-user-agent]
[2019-06-03T16:08:01,149][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [lang-expression]
[2019-06-03T16:08:01,149][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [lang-mustache]
[2019-06-03T16:08:01,149][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [lang-painless]
[2019-06-03T16:08:01,149][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [mapper-extras]
[2019-06-03T16:08:01,149][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [parent-join]
[2019-06-03T16:08:01,150][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [percolator]
[2019-06-03T16:08:01,150][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [rank-eval]
[2019-06-03T16:08:01,150][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [reindex]
[2019-06-03T16:08:01,150][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [repository-url]
[2019-06-03T16:08:01,150][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [transport-netty4]
[2019-06-03T16:08:01,151][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-ccr]
[2019-06-03T16:08:01,151][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-core]
[2019-06-03T16:08:01,151][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-deprecation]
[2019-06-03T16:08:01,151][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-graph]
[2019-06-03T16:08:01,152][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-ilm]
[2019-06-03T16:08:01,152][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-logstash]
[2019-06-03T16:08:01,152][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-ml]
[2019-06-03T16:08:01,152][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-monitoring]
[2019-06-03T16:08:01,152][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-rollup]
[2019-06-03T16:08:01,153][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-security]
[2019-06-03T16:08:01,153][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-sql]
[2019-06-03T16:08:01,153][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded module [x-pack-watcher]
[2019-06-03T16:08:01,154][INFO ][o.e.p.PluginsService     ] [intrusiveoperation-node-72ade59200] loaded plugin [ingest-attachment]
[2019-06-03T16:08:04,793][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [intrusiveoperation-node-72ade59200] [controller/13248] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:08:05,361][INFO ][o.e.d.DiscoveryModule    ] [intrusiveoperation-node-72ade59200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:08:06,124][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] initialized
[2019-06-03T16:08:06,125][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] starting ...
[2019-06-03T16:08:06,838][INFO ][o.e.t.TransportService   ] [intrusiveoperation-node-72ade59200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:08:06,844][WARN ][o.e.b.BootstrapChecks    ] [intrusiveoperation-node-72ade59200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:08:06,857][INFO ][o.e.c.c.ClusterBootstrapService] [intrusiveoperation-node-72ade59200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:08:09,865][INFO ][o.e.c.c.Coordinator      ] [intrusiveoperation-node-72ade59200] setting initial configuration to VotingConfiguration{1m29zWsXS_e2WTvcjeyzRw}
[2019-06-03T16:08:10,009][INFO ][o.e.c.s.MasterService    ] [intrusiveoperation-node-72ade59200] elected-as-master ([1] nodes joined)[{intrusiveoperation-node-72ade59200}{1m29zWsXS_e2WTvcjeyzRw}{iFQ4TCF5SZ-Bg--Ical7Lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{intrusiveoperation-node-72ade59200}{1m29zWsXS_e2WTvcjeyzRw}{iFQ4TCF5SZ-Bg--Ical7Lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:08:10,095][INFO ][o.e.c.s.ClusterApplierService] [intrusiveoperation-node-72ade59200] master node changed {previous [], current [{intrusiveoperation-node-72ade59200}{1m29zWsXS_e2WTvcjeyzRw}{iFQ4TCF5SZ-Bg--Ical7Lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:08:10,404][INFO ][o.e.g.GatewayService     ] [intrusiveoperation-node-72ade59200] recovered [0] indices into cluster_state
[2019-06-03T16:08:10,660][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:08:10,730][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:08:10,834][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:08:10,895][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:08:10,953][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:08:11,012][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:08:11,069][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:08:11,123][INFO ][o.e.c.m.MetaDataIndexTemplateService] [intrusiveoperation-node-72ade59200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:08:11,290][INFO ][o.e.l.LicenseService     ] [intrusiveoperation-node-72ade59200] license [467ad2f3-0276-4ea6-a45e-92fb16298909] mode [basic] - valid
[2019-06-03T16:08:11,297][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [intrusiveoperation-node-72ade59200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:08:11,344][INFO ][o.e.h.AbstractHttpServerTransport] [intrusiveoperation-node-72ade59200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:08:11,345][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] started
[2019-06-03T06:08:11,347][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T06:08:11,503][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:08:11,519][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T06:08:11,520][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T06:08:11,520][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:08:11,618][INFO ][Managed Elasticsearch    ]  {ValidatePluginsTask} validating the cluster is running the requested plugins
[2019-06-03T06:08:11,628][INFO ][Managed Elasticsearch    ]  All good! kicking off [IntrusiveOperationCluster] tests now
[2019-06-03T16:08:11,673][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-f6bf4e04a3a0af972991bd9d] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:11,911][INFO ][o.e.c.r.a.AllocationService] [intrusiveoperation-node-72ade59200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[project-copy-f6bf4e04a3a0af972991bd9d][0]] ...]).
[2019-06-03T16:08:12,025][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-56f6481dacb002ff1b4525b5] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:12,152][INFO ][o.e.c.r.a.AllocationService] [intrusiveoperation-node-72ade59200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[project-copy-56f6481dacb002ff1b4525b5][0]] ...]).
[2019-06-03T16:08:12,224][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-56f6481dacb002ff1b4525b5][0] failed to execute bulk item (index) index {[project-copy-56f6481dacb002ff1b4525b5][_doc][200], source[{"id":200,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '200'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:12,234][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-56f6481dacb002ff1b4525b5/L9izQu2sRgGX_Xc1zEZwlw] update_mapping [_doc]
[2019-06-03T16:08:12,249][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-56f6481dacb002ff1b4525b5][0] failed to execute bulk item (index) index {[project-copy-56f6481dacb002ff1b4525b5][_doc][201], source[{"id":201,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '201'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:12,434][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-705e4288a17e9af1ef25c312] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:12,546][INFO ][o.e.c.r.a.AllocationService] [intrusiveoperation-node-72ade59200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[project-copy-705e4288a17e9af1ef25c312][0]] ...]).
[2019-06-03T16:08:12,583][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-705e4288a17e9af1ef25c312][0] failed to execute bulk item (index) index {[project-copy-705e4288a17e9af1ef25c312][_doc][200], source[{"id":200,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '200'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:12,589][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-705e4288a17e9af1ef25c312/9dNQLjjdQreZpfSzYmhb9g] update_mapping [_doc]
[2019-06-03T16:08:12,596][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-705e4288a17e9af1ef25c312][0] failed to execute bulk item (index) index {[project-copy-705e4288a17e9af1ef25c312][_doc][201], source[{"id":201,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '201'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:12,936][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-ae40467e8c1ace91db983ee6] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:13,065][INFO ][o.e.c.r.a.AllocationService] [intrusiveoperation-node-72ade59200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[project-copy-ae40467e8c1ace91db983ee6][0]] ...]).
[2019-06-03T16:08:13,106][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-ae40467e8c1ace91db983ee6][0] failed to execute bulk item (index) index {[project-copy-ae40467e8c1ace91db983ee6][_doc][200], source[{"id":200,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '200'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:13,115][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-ae40467e8c1ace91db983ee6/OWY5uKrCRSuAyiYIA1zykw] update_mapping [_doc]
[2019-06-03T16:08:13,124][DEBUG][o.e.a.b.TransportShardBulkAction] [intrusiveoperation-node-72ade59200] [project-copy-ae40467e8c1ace91db983ee6][0] failed to execute bulk item (index) index {[project-copy-ae40467e8c1ace91db983ee6][_doc][201], source[{"id":201,"number":"Not excepted"}]}
org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [number] of type [float] in document with id '201'
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:280) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:468) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseValue(DocumentParser.java:596) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.innerParseObject(DocumentParser.java:407) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrNested(DocumentParser.java:381) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.internalParseDocument(DocumentParser.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:267) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.prepareIndex(IndexShard.java:770) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperation(IndexShard.java:747) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.applyIndexOperationOnPrimary(IndexShard.java:719) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:452) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:475) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:450) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:218) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:161) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:153) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:141) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:79) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1033) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1011) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:413) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.lambda$doRun$0(TransportReplicationAction.java:359) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.acquirePrimaryOperationPermit(TransportReplicationAction.java:970) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:358) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:313) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:305) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:63) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:687) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.IllegalArgumentException: Float value passed as String
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.checkCoerceString(AbstractXContentParser.java:52) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.floatValue(AbstractXContentParser.java:220) ~[elasticsearch-x-content-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:293) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$2.parse(NumberFieldMapper.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.NumberFieldMapper.parseCreateField(NumberFieldMapper.java:1044) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:274) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 39 more
[2019-06-03T16:08:17,011][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-list-detailed] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:17,248][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-list-detailed/SHzVhDf6TE-cXqNrMsv-5w] create_mapping [_doc]
[2019-06-03T16:08:17,316][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-list-detailed/SHzVhDf6TE-cXqNrMsv-5w] update_mapping [_doc]
[2019-06-03T16:08:17,386][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-list-detailed/SHzVhDf6TE-cXqNrMsv-5w] update_mapping [_doc]
[2019-06-03T16:08:17,453][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-list-detailed/SHzVhDf6TE-cXqNrMsv-5w] update_mapping [_doc]
[2019-06-03T16:08:25,011][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [tasks-lists-detailed] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:08:25,291][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [fluent-c73d88b8-repository]
[2019-06-03T16:08:25,407][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [fluentasync-5c332f37-repository]
[2019-06-03T16:08:25,462][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [tasks-lists-detailed/udRbxTpyS3Kr1BD37gd8Pg] update_mapping [_doc]
[2019-06-03T16:08:25,518][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [ois-25a681a9-repository]
[2019-06-03T16:08:25,663][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [oisasync-59c84a8d-repository]
[2019-06-03T16:08:25,807][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] update repository [fluent-c73d88b8-repository]
[2019-06-03T16:08:25,911][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] update repository [fluentasync-5c332f37-repository]
[2019-06-03T16:08:25,994][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] update repository [ois-25a681a9-repository]
[2019-06-03T16:08:26,117][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] update repository [oisasync-59c84a8d-repository]
[2019-06-03T16:08:26,330][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] delete repository [fluent-c73d88b8-repository]
[2019-06-03T16:08:26,510][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] delete repository [fluentasync-5c332f37-repository]
[2019-06-03T16:08:26,670][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] delete repository [ois-25a681a9-repository]
[2019-06-03T16:08:26,757][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] delete repository [oisasync-59c84a8d-repository]
[2019-06-03T16:08:27,071][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-3e622892] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:27,388][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-3e622892/1eQpcKeuR6aMdzAE1f0mAw] create_mapping [_doc]
[2019-06-03T16:08:27,948][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-4757f45d] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:28,546][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-4757f45d/m25mMo3uR9K_Q8LNBp5IqQ] create_mapping [_doc]
[2019-06-03T16:08:30,399][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-e07031b7] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:30,645][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-e07031b7/OKXQ4t9ZTp2KXWMqs5MWKA] create_mapping [_doc]
[2019-06-03T16:08:31,146][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-05c52b42] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:31,338][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-05c52b42/QKcgVJopTgm-LpP0oXbYkQ] create_mapping [_doc]
[2019-06-03T16:08:33,175][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-7b15df86] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:34,015][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-7b15df86/9SnFVj6ARXCUbBQ29QMFeA] update_mapping [_doc]
[2019-06-03T16:08:34,184][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-7b15df86-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:35,054][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-82768896] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:35,615][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-82768896/E6l9XaRqQt6C7W5-Rg6nIQ] update_mapping [_doc]
[2019-06-03T16:08:35,902][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-82768896-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:37,073][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-e2078f8a] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:37,366][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-e2078f8a/X2JEQ5HiRdeS2I5laTpVPA] update_mapping [_doc]
[2019-06-03T16:08:37,524][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-e2078f8a-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:38,350][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-40558db1] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:38,640][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-40558db1/4lo4NJszRMi9aCGxEI6MUg] update_mapping [_doc]
[2019-06-03T16:08:38,805][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-40558db1-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:39,616][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [.tasks] creating index, cause [auto(task api)], templates [], shards [1]/[1], mappings [task]
[2019-06-03T16:08:39,619][INFO ][o.e.c.r.a.AllocationService] [intrusiveoperation-node-72ade59200] updating number_of_replicas to [0] for indices [.tasks]
[2019-06-03T16:08:40,447][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 418 finished with response BulkByScrollResponse[took=259.3ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:08:40,450][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 387 finished with response BulkByScrollResponse[took=244.9ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:08:40,451][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 429 finished with response BulkByScrollResponse[took=460.8ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:08:40,452][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 398 finished with response BulkByScrollResponse[took=237.5ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:08:41,325][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-a58307c6] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:41,746][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-a58307c6/6LxNc5zERNGLL0-ToXjjlw] update_mapping [_doc]
[2019-06-03T16:08:42,050][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-a58307c6-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:43,979][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-af919638] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:44,374][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-af919638/3aTryDqqRV-SOBQSpFCtBA] update_mapping [_doc]
[2019-06-03T16:08:44,950][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-af919638-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:45,637][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-c64c5f4d] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:45,944][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-c64c5f4d/faTdpUUgRPODvXOu0LascQ] update_mapping [_doc]
[2019-06-03T16:08:46,103][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-c64c5f4d-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:47,031][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-78d84edc] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:08:47,324][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-78d84edc/dDEH6Nh9TSK4Bngh0tuRew] update_mapping [_doc]
[2019-06-03T16:08:47,494][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-78d84edc-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:48,753][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-9593d9df] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:48,962][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-9593d9df/p27qbLcRTB-j2zu_BigWgQ] create_mapping [_doc]
[2019-06-03T16:08:49,282][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-33e01c8b] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:49,450][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-33e01c8b/Ks6B3FppS9mnnAMwzzS2Ng] create_mapping [_doc]
[2019-06-03T16:08:49,734][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-066cb726] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:49,920][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-066cb726/Sk7-EwA7ROKYA47Kwz08gA] create_mapping [_doc]
[2019-06-03T16:08:50,223][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ae3f9118] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:50,393][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ae3f9118/2yQnPVSqRdmEiBGZtdbfug] create_mapping [_doc]
[2019-06-03T16:08:50,741][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-066cb726-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:50,956][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-066cb726-clone/d2aNlwkZQIm8GCtBMk2MeA] create_mapping [_doc]
[2019-06-03T16:08:51,342][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 122 finished with response BulkByScrollResponse[took=26.1s,timed_out=false,sliceId=null,updated=0,created=10000,deleted=0,batches=10,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:08:51,416][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-9593d9df-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:51,546][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-9593d9df-clone/nPQt7IyuTAizF_mPtbSspQ] create_mapping [_doc]
[2019-06-03T16:08:51,659][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ae3f9118-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:51,791][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ae3f9118-clone/U9zpvQ25SCWH0taic6PLcw] create_mapping [_doc]
[2019-06-03T16:08:51,896][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-33e01c8b-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:52,041][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-33e01c8b-clone/-ugOL34pTrqhOTV2Yo78fg] create_mapping [_doc]
[2019-06-03T16:08:52,203][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [8ad72d65]
[2019-06-03T16:08:52,286][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [f33b78f2] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:52,537][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [f33b78f2/WFCpuEn7QJuxqMUDH_rYLw] update_mapping [_doc]
[2019-06-03T16:08:52,846][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [geoshapes] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:08:54,070][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [ec7962c9]
[2019-06-03T16:08:54,121][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [940b4e6f80c26622eb587d79] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:54,340][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluent-7bb0bd82-snapshot/sPhSUqqaSXSVArMUgmKJbg] started
[2019-06-03T16:08:54,426][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluent-7bb0bd82-snapshot/sPhSUqqaSXSVArMUgmKJbg] completed with state [SUCCESS]
[2019-06-03T16:08:54,504][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluentasync-8ddabec5-snapshot/OYLw43wcRTabT9wBIO6BTA] started
[2019-06-03T16:08:54,583][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluentasync-8ddabec5-snapshot/OYLw43wcRTabT9wBIO6BTA] completed with state [SUCCESS]
[2019-06-03T16:08:54,628][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:ois-030a95d8-snapshot/-ws9Wk4KQpOF455KtdqR6Q] started
[2019-06-03T16:08:54,705][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:ois-030a95d8-snapshot/-ws9Wk4KQpOF455KtdqR6Q] completed with state [SUCCESS]
[2019-06-03T16:08:54,750][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:oisasync-afc714f9-snapshot/v3ZnSjkPQBOXIHix7URQ5A] started
[2019-06-03T16:08:54,824][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:oisasync-afc714f9-snapshot/v3ZnSjkPQBOXIHix7URQ5A] completed with state [SUCCESS]
[2019-06-03T16:08:54,976][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluent-7bb0bd82-snapshot/sPhSUqqaSXSVArMUgmKJbg] deleted
[2019-06-03T16:08:55,031][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:fluentasync-8ddabec5-snapshot/OYLw43wcRTabT9wBIO6BTA] deleted
[2019-06-03T16:08:55,084][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:ois-030a95d8-snapshot/-ws9Wk4KQpOF455KtdqR6Q] deleted
[2019-06-03T16:08:55,125][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [ec7962c9:oisasync-afc714f9-snapshot/v3ZnSjkPQBOXIHix7URQ5A] deleted
[2019-06-03T16:08:55,206][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-bf9740d5] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:55,364][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-bf9740d5/JW7JUA_rTjGOhCii0GsDSw] create_mapping [_doc]
[2019-06-03T16:08:55,504][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-64549308] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:55,634][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-64549308/AkbhDTehTy2bwWqE5C-iCA] create_mapping [_doc]
[2019-06-03T16:08:55,770][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-6c27018e] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:55,925][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-6c27018e/RYJuqTjfScCNgrzJ6bJJxw] create_mapping [_doc]
[2019-06-03T16:08:56,063][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-746ead6e] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:56,212][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-746ead6e/ijZ7kl5cS868QU62rXemew] create_mapping [_doc]
[2019-06-03T16:08:56,866][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project2f5853c6] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:08:58,139][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDEEE+Calibri-Light are not implemented in PDFBox and will be ignored
[2019-06-03T16:08:58,175][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored
[2019-06-03T16:08:58,285][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project2f5853c6/atoZZbZLRbW5JfBKCUtdbg] update_mapping [_doc]
[2019-06-03T16:08:58,610][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project2f5853c62] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:58,746][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project2f5853c62/hbT5NKBVSTaviprgrauDRg] create_mapping [_doc]
[2019-06-03T16:08:58,944][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-cee59c31] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:59,116][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-a9c0a0e1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:59,274][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-6cfa4ca4] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:59,425][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-e64d2f16] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:59,583][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-5aaec903] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:08:59,723][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-5aaec903/dd7prDRVRlyeynk96Wrucg] create_mapping [_doc]
[2019-06-03T16:08:59,853][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-5baeab5d] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:00,030][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-5baeab5d/kLkYF2yNTI2CZtEf8-bT1w] create_mapping [_doc]
[2019-06-03T16:09:00,207][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-3804577d] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:00,341][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-3804577d/3nCWoN4BS_eFSGmgm4hu0A] create_mapping [_doc]
[2019-06-03T16:09:00,495][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-1831b604] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:00,639][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-1831b604/ekYQ-UooQeOTPJo6kKyTpw] create_mapping [_doc]
[2019-06-03T16:09:02,021][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-9db1542e] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:02,162][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-9db1542e/w5IVUpQcT0eug0XW5SUP0Q] create_mapping [_doc]
[2019-06-03T16:09:02,791][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-16ed5bda] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:02,960][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-16ed5bda/YYWHRhT9Ru2ATvQEr3JgMg] create_mapping [_doc]
[2019-06-03T16:09:03,514][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-983231e8] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:03,679][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-983231e8/-Q_p2Pz1S6Cztq4qKDe8dw] create_mapping [_doc]
[2019-06-03T16:09:04,095][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-00939868] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:04,277][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-00939868/kAMGU-0sQUieFP0xRrgDLw] create_mapping [_doc]
[2019-06-03T16:09:04,615][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-9db1542e-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:04,659][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Received ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1400] on the node [1m29zWsXS_e2WTvcjeyzRw], reason: [by user request]
[2019-06-03T16:09:04,672][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Received ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1392] on the node [1m29zWsXS_e2WTvcjeyzRw], reason: [by user request]
[2019-06-03T16:09:04,677][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Received ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1388] on the node [1m29zWsXS_e2WTvcjeyzRw], reason: [by user request]
[2019-06-03T16:09:04,681][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Received ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1404] on the node [1m29zWsXS_e2WTvcjeyzRw], reason: [by user request]
[2019-06-03T16:09:04,718][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-16ed5bda-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:04,784][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-983231e8-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:04,874][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-00939868-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:04,929][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-d99f69a7] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:05,153][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-16ed5bda-clone/xlePXYDVT8yEdIF3sfZ4Qg] create_mapping [_doc]
[2019-06-03T16:09:05,156][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-9db1542e-clone/iAeTtteYThm3C5Le4TSqsw] create_mapping [_doc]
[2019-06-03T16:09:05,159][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-983231e8-clone/2FCHCCtJQFSvUyxtnaMgsw] create_mapping [_doc]
[2019-06-03T16:09:05,279][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-00939868-clone/JvF90t0vTWe3Z65ew5JQRw] create_mapping [_doc]
[2019-06-03T16:09:05,323][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-68457cd0] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:05,348][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Sending remove ban for tasks with the parent [1m29zWsXS_e2WTvcjeyzRw:1388] to the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,349][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Removing ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1388] on the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,349][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 1388 finished with response BulkByScrollResponse[took=753.7ms,timed_out=false,sliceId=null,updated=0,created=1000,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,canceled=by user request,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:05,350][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Sending remove ban for tasks with the parent [1m29zWsXS_e2WTvcjeyzRw:1392] to the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,351][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Removing ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1392] on the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,351][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 1392 finished with response BulkByScrollResponse[took=745.3ms,timed_out=false,sliceId=null,updated=0,created=1000,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,canceled=by user request,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:05,351][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Sending remove ban for tasks with the parent [1m29zWsXS_e2WTvcjeyzRw:1400] to the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,352][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Removing ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1400] on the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,352][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 1400 finished with response BulkByScrollResponse[took=719.1ms,timed_out=false,sliceId=null,updated=0,created=1000,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,canceled=by user request,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:05,396][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Sending remove ban for tasks with the parent [1m29zWsXS_e2WTvcjeyzRw:1404] to the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,397][DEBUG][o.e.a.a.c.n.t.c.TransportCancelTasksAction] [intrusiveoperation-node-72ade59200] Removing ban for the parent [1m29zWsXS_e2WTvcjeyzRw:1404] on the node [1m29zWsXS_e2WTvcjeyzRw]
[2019-06-03T16:09:05,397][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 1404 finished with response BulkByScrollResponse[took=765.7ms,timed_out=false,sliceId=null,updated=0,created=1000,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,canceled=by user request,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:05,474][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-5965bd3f] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:05,624][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c8846e99] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:05,808][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-fluent-d99f69a7][0] starting segment upgrade upgradeOnlyAncientSegments=false
[2019-06-03T16:09:05,809][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-fluent-d99f69a7][0] finished segment upgrade
[2019-06-03T16:09:05,838][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-initializer-5965bd3f][0] starting segment upgrade upgradeOnlyAncientSegments=false
[2019-06-03T16:09:05,839][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-initializer-5965bd3f][0] finished segment upgrade
[2019-06-03T16:09:05,860][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-fluentasync-68457cd0][0] starting segment upgrade upgradeOnlyAncientSegments=false
[2019-06-03T16:09:05,861][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-fluentasync-68457cd0][0] finished segment upgrade
[2019-06-03T16:09:05,884][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c8846e99][0] starting segment upgrade upgradeOnlyAncientSegments=false
[2019-06-03T16:09:05,885][INFO ][o.e.i.e.Engine           ] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c8846e99][0] finished segment upgrade
[2019-06-03T16:09:05,937][INFO ][o.e.c.s.ClusterSettings  ] [intrusiveoperation-node-72ade59200] updating [indices.recovery.max_bytes_per_sec] from [40mb] to [41mb]
[2019-06-03T16:09:05,982][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-830a4a09800a5b80e1913e77] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:06,158][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-830a4a09800a5b80e1913e77/G0GPOFdySPqkOxqX4lw5vg] create_mapping [_doc]
[2019-06-03T16:09:06,316][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-ef555956] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:06,471][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-51f95f99] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:06,625][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-fddc6d73] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:06,763][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-5a424982] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:06,926][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-40563191] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:07,120][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-40563191/6LSeoZdzSHuqSKM_9e9RLQ] update_mapping [_doc]
[2019-06-03T16:09:07,506][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-0d8bb669] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:07,666][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-0d8bb669/pyQRZBweSSG3rzwD-k2bUA] update_mapping [_doc]
[2019-06-03T16:09:08,055][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-64d04ca0] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:08,242][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-64d04ca0/aHjPGUSBSu6E3cy06AyJ8g] update_mapping [_doc]
[2019-06-03T16:09:08,645][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ac0bedd1] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:08,829][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-ac0bedd1/DQN-Yne7TkytzH56i6tuQA] update_mapping [_doc]
[2019-06-03T16:09:09,234][INFO ][o.e.r.RepositoriesService] [intrusiveoperation-node-72ade59200] put repository [0208fa88]
[2019-06-03T16:09:09,279][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [e2d9790c] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:09,461][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [0208fa88:fcd44be9/8T-Q2RupTxORYBKQesKOnQ] started
[2019-06-03T16:09:09,528][INFO ][o.e.s.SnapshotsService   ] [intrusiveoperation-node-72ade59200] snapshot [0208fa88:fcd44be9/8T-Q2RupTxORYBKQesKOnQ] completed with state [SUCCESS]
[2019-06-03T16:09:09,573][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-cafd46c69ae26842e837bb9f] creating index, cause [api], templates [], shards [10]/[0], mappings []
[2019-06-03T16:09:10,253][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-cafd46c69ae26842e837bb9f/Jzd-tzRwTiK1dFqO5_BCKQ] create_mapping [_doc]
[xUnit.net 00:12:16.1921838]     Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedIsValid [SKIP]
[xUnit.net 00:12:16.1923745]     Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedStatusCode [SKIP]
[xUnit.net 00:12:16.1924944]     Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedResponse [SKIP]
[2019-06-03T16:09:15,542][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-72597b26] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:15,901][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-72597b26/jdjgkWHxRHy8HknZq1qbbg] update_mapping [_doc]
[2019-06-03T16:09:15,943][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-6143d57c] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:16,299][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-6143d57c/dcVTgSZBRVe7nDAewWB6AA] update_mapping [_doc]
[2019-06-03T16:09:16,331][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-fba230c3] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:16,684][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-fba230c3/Y1aKGpg-QJKRgk9HDYa3Yg] update_mapping [_doc]
[2019-06-03T16:09:16,713][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-65baf917] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:17,037][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-65baf917/uaZ3oINvS6yVohTcW9avtQ] update_mapping [_doc]
Skipped  Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedIsValid
Skipped  Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedStatusCode
Skipped  Tests.Document.Single.Index.IndexIngestGeoIpApiTests.ReturnsExpectedResponse
[2019-06-03T16:09:17,682][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-884f4320a1269cdb14f5eca9] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:17,820][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-884f4320a1269cdb14f5eca9/v7llSkLOTyet8NG1E-j-Rg] create_mapping [_doc]
[2019-06-03T16:09:18,111][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-47a901be] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:18,539][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-47a901be/LEEnE883QL6oZOUxgo29Qw] update_mapping [_doc]
[2019-06-03T16:09:18,571][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-df99b9ac] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:19,035][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-df99b9ac/vPJossoySU6gqbBN8LmlEA] update_mapping [_doc]
[2019-06-03T16:09:19,062][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-0e872010] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:19,397][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-0e872010/8xZHxUdWSjS6me2ETspWvA] update_mapping [_doc]
[2019-06-03T16:09:19,425][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-17f32842] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:19,781][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-17f32842/DyjcCY42Qu2Gdlr_mOJ5Hg] update_mapping [_doc]
[2019-06-03T16:09:19,837][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-5bc9ac24] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:19,837][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 6691 finished with response BulkByScrollResponse[took=15.4ms,timed_out=false,sliceId=null,updated=2,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:19,838][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 6709 finished with response BulkByScrollResponse[took=11.4ms,timed_out=false,sliceId=null,updated=2,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:19,838][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 6718 finished with response BulkByScrollResponse[took=11.6ms,timed_out=false,sliceId=null,updated=2,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:19,839][INFO ][o.e.t.LoggingTaskListener] [intrusiveoperation-node-72ade59200] 6700 finished with response BulkByScrollResponse[took=12.6ms,timed_out=false,sliceId=null,updated=2,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:09:19,989][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-962fc6de] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:20,163][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-592bd080] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:20,389][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-e64747bb] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:20,653][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-1ee9f0d0] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:20,824][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-1ee9f0d0/XKqgYnngQbOqD9c8FCYvfw] create_mapping [_doc]
[2019-06-03T16:09:21,788][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-75336cc2] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:21,919][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-75336cc2/ng4pbvzsSLKhV7psgw5XcQ] create_mapping [_doc]
[2019-06-03T16:09:22,947][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-cdeaa4cc] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:23,071][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-cdeaa4cc/ZTn5uC0BS-Gzuv_-bfOidA] create_mapping [_doc]
[2019-06-03T16:09:24,090][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c6f5b307] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:24,257][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c6f5b307/lrbpuhSIQOK22mBX48N4Qw] create_mapping [_doc]
[2019-06-03T16:09:25,237][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-cdeaa4cc-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:25,372][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-cdeaa4cc-clone/-D-X21hpQRK8cOMPkTtoYg] create_mapping [_doc]
[2019-06-03T16:09:25,503][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-75336cc2-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:25,632][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-75336cc2-clone/XiNmzzXXRuyZL5XdwIs9Tg] create_mapping [_doc]
[2019-06-03T16:09:25,747][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-1ee9f0d0-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:25,891][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-1ee9f0d0-clone/EtLOIPiWSEKyULST0Vwi7Q] create_mapping [_doc]
[2019-06-03T16:09:26,004][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c6f5b307-clone] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:26,135][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-c6f5b307-clone/8FHHIII6QO6oWey5tu0oIw] create_mapping [_doc]
[2019-06-03T16:09:26,272][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-392177f7] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:26,402][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-392177f7/lExCuu11QmewUJmzpCq1eA] create_mapping [_doc]
[2019-06-03T16:09:27,384][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-71c3c182] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:27,517][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-71c3c182/Ce5VHpkiQv2CZXkDDLPPcA] create_mapping [_doc]
[2019-06-03T16:09:28,499][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-82d63d95] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:28,639][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-82d63d95/3YJBUBBJR_Gb9JSxX_Braw] create_mapping [_doc]
[2019-06-03T16:09:29,655][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-e3b11257] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:29,795][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-e3b11257/tbm8UGtjSeygRejy-qNDzQ] create_mapping [_doc]
[2019-06-03T16:09:30,973][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:31,134][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project/rGslzXC1QFqChx25SRtCQw] create_mapping [_doc]
[2019-06-03T16:09:31,570][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-19b162be] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:31,699][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-ba18246a] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:31,840][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-f203c143] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:31,972][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-b28e8182] creating index, cause [api], templates [], shards [1]/[1], mappings [_doc]
[2019-06-03T16:09:32,156][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDEEE+Calibri-Light are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,172][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,185][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-ba18246a/CJ4hhgVPTjWHOukZ_wjDlw] update_mapping [_doc]
[2019-06-03T16:09:32,382][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDEEE+Calibri-Light are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,397][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,410][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-19b162be/dnOlTQhyT0-4n02T_Ldqeg] update_mapping [_doc]
[2019-06-03T16:09:32,590][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDEEE+Calibri-Light are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,606][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,615][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-f203c143/1nECQmAuT0qMk5S_xtWulw] update_mapping [_doc]
[2019-06-03T16:09:32,775][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDEEE+Calibri-Light are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,790][INFO ][o.a.p.p.f.PDCIDFontType2 ] [intrusiveoperation-node-72ade59200] OpenType Layout tables used in font BCDHEE+Calibri are not implemented in PDFBox and will be ignored
[2019-06-03T16:09:32,800][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-b28e8182/uQpIMJF2RlOjlgJzrBpZqg] update_mapping [_doc]
[2019-06-03T16:09:33,002][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-bc324a78af02dd26c21cae6d] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:33,163][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-bc324a78af02dd26c21cae6d/vXU4AMZ5SEaBs07bkml6Sg] create_mapping [_doc]
[2019-06-03T16:09:33,641][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [wkt-geoshapes] creating index, cause [api], templates [], shards [1]/[0], mappings [_doc]
[2019-06-03T16:09:39,202][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-cfa64a939e0f0895dfb8df7d] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:39,358][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-cfa64a939e0f0895dfb8df7d/Pwr7DemjT-W_whiuZ94L5Q] create_mapping [_doc]
[2019-06-03T16:09:42,515][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [project-copy-ae0947128d59557d7326a29f] creating index, cause [auto(bulk api)], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:42,699][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [project-copy-ae0947128d59557d7326a29f/e1pFlIrCRu2JV3HLkBiAog] create_mapping [_doc]
[2019-06-03T16:09:45,883][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-50975ceb] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:09:46,087][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluent-50975ceb/XN9UPMMhQQOma70hRF3yZw] update_mapping [_doc]
[2019-06-03T16:09:46,228][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-50975ceb-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:46,708][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-c0564f4c] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:09:47,010][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-c0564f4c/Os368KXvTX2EnArNt6UV4g] update_mapping [_doc]
[2019-06-03T16:09:47,169][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-c0564f4c-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:47,629][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-67952040] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:09:47,826][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializer-67952040/tA6kmPqgSHm8D0ROC6k37Q] update_mapping [_doc]
[2019-06-03T16:09:47,924][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-67952040-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:48,277][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-a4e08d5b] creating index, cause [api], templates [], shards [2]/[0], mappings [_doc]
[2019-06-03T16:09:48,456][INFO ][o.e.c.m.MetaDataMappingService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-a4e08d5b/qVSYIhY-QD2L4eN38uThkQ] update_mapping [_doc]
[2019-06-03T16:09:48,559][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-a4e08d5b-clone] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:49,476][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluent-66f986a6] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:49,611][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-fluentasync-ff95f3f7] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:49,746][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializer-6bb519d9] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:49,900][INFO ][o.e.c.m.MetaDataCreateIndexService] [intrusiveoperation-node-72ade59200] [nest-initializerasync-5b70ea47] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2019-06-03T16:09:50,180][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] stopping ...
[2019-06-03T16:09:50,188][INFO ][o.e.x.w.WatcherService   ] [intrusiveoperation-node-72ade59200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:09:50,613][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [intrusiveoperation-node-72ade59200] [controller/13248] [Main.cc@148] Ml controller exiting
[2019-06-03T16:09:50,613][INFO ][o.e.x.m.p.NativeController] [intrusiveoperation-node-72ade59200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:09:50,691][WARN ][o.e.i.s.RetentionLeaseSyncAction] [intrusiveoperation-node-72ade59200] [nest-fluent-1ee9f0d0][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [intrusiveoperation-node-72ade59200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:09:50,787][WARN ][o.e.i.s.RetentionLeaseSyncAction] [intrusiveoperation-node-72ade59200] [nest-initializer-066cb726-clone][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [intrusiveoperation-node-72ade59200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:09:51,443][WARN ][o.e.i.s.RetentionLeaseSyncAction] [intrusiveoperation-node-72ade59200] [nest-fluent-9593d9df-clone][0] retention lease background sync failed
org.elasticsearch.transport.SendRequestTransportException: [intrusiveoperation-node-72ade59200][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2062) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$16(IndexShard.java:2564) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2512) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2568) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 30 more
[2019-06-03T16:09:52,369][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] stopped
[2019-06-03T16:09:52,369][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] closing ...
[2019-06-03T16:09:52,378][INFO ][o.e.n.Node               ] [intrusiveoperation-node-72ade59200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:09:52,550][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\data}
[2019-06-03T06:09:53,077][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\config}
[2019-06-03T06:09:53,080][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\logs}
[2019-06-03T06:09:53,081][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4\repositories}
[2019-06-03T06:09:53,085][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-53ffa4}
[2019-06-03T06:09:53,289][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T06:09:53,290][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:09:53,290][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-4556f6]
[2019-06-03T06:09:53,290][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T06:09:53,291][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T06:09:53,291][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:09:53,292][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} []
[2019-06-03T06:09:53,292][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T06:09:53,292][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:09:53,293][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:09:53,293][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:09:53,293][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:09:53,294][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:09:53,294][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:09:53,295][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:09:53,295][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:09:53,297][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\home]
[2019-06-03T06:09:55,332][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:09:55,333][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6}
[2019-06-03T06:09:55,334][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\config}
[2019-06-03T06:09:55,334][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\config]
[2019-06-03T06:09:55,341][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x]
[2019-06-03T06:09:55,341][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\config\analysis]
[2019-06-03T06:09:55,345][INFO ][Managed Elasticsearch    ] [reindex-node-9215609200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\home\bin\elasticsearch.bat]
[2019-06-03T06:09:55,346][INFO ][Managed Elasticsearch    ] [reindex-node-9215609200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-4556f6 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=reindex-node-9215609200 -E http.port=9200 -E cluster.initial_master_nodes=reindex-node-9215609200}
[2019-06-03T16:10:03,523][INFO ][o.e.e.NodeEnvironment    ] [reindex-node-9215609200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:10:03,527][INFO ][o.e.e.NodeEnvironment    ] [reindex-node-9215609200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:10:03,532][INFO ][o.e.n.Node               ] [reindex-node-9215609200] node name [reindex-node-9215609200], node ID [x3tES0GhQYG1Ue21QkTu8w]
[2019-06-03T16:10:03,532][INFO ][o.e.n.Node               ] [reindex-node-9215609200] version[7.0.0], pid[14260], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:10:03,533][INFO ][o.e.n.Node               ] [reindex-node-9215609200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:10:03,534][INFO ][o.e.n.Node               ] [reindex-node-9215609200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:10:17,707][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [aggs-matrix-stats]
[2019-06-03T16:10:17,707][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [analysis-common]
[2019-06-03T16:10:17,707][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [ingest-common]
[2019-06-03T16:10:17,708][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [ingest-geoip]
[2019-06-03T16:10:17,708][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [ingest-user-agent]
[2019-06-03T16:10:17,708][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [lang-expression]
[2019-06-03T16:10:17,708][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [lang-mustache]
[2019-06-03T16:10:17,708][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [lang-painless]
[2019-06-03T16:10:17,709][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [mapper-extras]
[2019-06-03T16:10:17,709][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [parent-join]
[2019-06-03T16:10:17,709][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [percolator]
[2019-06-03T16:10:17,709][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [rank-eval]
[2019-06-03T16:10:17,709][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [reindex]
[2019-06-03T16:10:17,710][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [repository-url]
[2019-06-03T16:10:17,710][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [transport-netty4]
[2019-06-03T16:10:17,710][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-ccr]
[2019-06-03T16:10:17,710][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-core]
[2019-06-03T16:10:17,710][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-deprecation]
[2019-06-03T16:10:17,711][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-graph]
[2019-06-03T16:10:17,711][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-ilm]
[2019-06-03T16:10:17,711][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-logstash]
[2019-06-03T16:10:17,711][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-ml]
[2019-06-03T16:10:17,711][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-monitoring]
[2019-06-03T16:10:17,712][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-rollup]
[2019-06-03T16:10:17,712][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-security]
[2019-06-03T16:10:17,712][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-sql]
[2019-06-03T16:10:17,712][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] loaded module [x-pack-watcher]
[2019-06-03T16:10:17,713][INFO ][o.e.p.PluginsService     ] [reindex-node-9215609200] no plugins loaded
[2019-06-03T16:10:22,241][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [reindex-node-9215609200] [controller/3412] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:10:23,231][INFO ][o.e.d.DiscoveryModule    ] [reindex-node-9215609200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:10:24,249][INFO ][o.e.n.Node               ] [reindex-node-9215609200] initialized
[2019-06-03T16:10:24,250][INFO ][o.e.n.Node               ] [reindex-node-9215609200] starting ...
[2019-06-03T16:10:24,917][INFO ][o.e.t.TransportService   ] [reindex-node-9215609200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:10:24,923][WARN ][o.e.b.BootstrapChecks    ] [reindex-node-9215609200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:10:24,939][INFO ][o.e.c.c.ClusterBootstrapService] [reindex-node-9215609200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:10:27,945][INFO ][o.e.c.c.Coordinator      ] [reindex-node-9215609200] setting initial configuration to VotingConfiguration{x3tES0GhQYG1Ue21QkTu8w}
[2019-06-03T16:10:28,046][INFO ][o.e.c.s.MasterService    ] [reindex-node-9215609200] elected-as-master ([1] nodes joined)[{reindex-node-9215609200}{x3tES0GhQYG1Ue21QkTu8w}{R4os1NyET7Ghc8JHVGdNJw}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{reindex-node-9215609200}{x3tES0GhQYG1Ue21QkTu8w}{R4os1NyET7Ghc8JHVGdNJw}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:10:28,099][INFO ][o.e.c.s.ClusterApplierService] [reindex-node-9215609200] master node changed {previous [], current [{reindex-node-9215609200}{x3tES0GhQYG1Ue21QkTu8w}{R4os1NyET7Ghc8JHVGdNJw}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:10:28,218][INFO ][o.e.g.GatewayService     ] [reindex-node-9215609200] recovered [0] indices into cluster_state
[2019-06-03T16:10:28,354][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:10:28,461][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:10:28,518][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:10:28,576][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:10:28,643][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:10:28,708][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:10:28,763][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:10:28,820][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:10:28,888][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [reindex-node-9215609200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:10:29,031][INFO ][o.e.h.AbstractHttpServerTransport] [reindex-node-9215609200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:10:29,032][INFO ][o.e.n.Node               ] [reindex-node-9215609200] started
[2019-06-03T06:10:29,035][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T16:10:29,047][INFO ][o.e.l.LicenseService     ] [reindex-node-9215609200] license [d3ea2af5-76e4-47d2-aa2d-fa634e447421] mode [basic] - valid
[2019-06-03T06:10:29,226][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:10:29,282][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T06:10:29,283][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T06:10:29,283][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:10:29,393][INFO ][Managed Elasticsearch    ]  All good! kicking off [ReindexCluster] tests now
[2019-06-03T16:10:29,429][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [reindex-node-9215609200] failed to delete templates [nest_tests]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [nest_tests] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:10:29,466][INFO ][o.e.c.s.ClusterSettings  ] [reindex-node-9215609200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:10:29,469][INFO ][o.e.c.s.ClusterSettings  ] [reindex-node-9215609200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:10:29,492][INFO ][o.e.c.s.ClusterSettings  ] [reindex-node-9215609200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:10:29,494][INFO ][o.e.c.s.ClusterSettings  ] [reindex-node-9215609200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:10:29,556][INFO ][o.e.c.m.MetaDataIndexTemplateService] [reindex-node-9215609200] adding template [nest_tests] for index patterns [*]
[2019-06-03T16:10:29,739][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [project] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:10:29,875][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [devs] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:10:30,063][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [queries] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:10:30,378][INFO ][o.e.c.r.a.AllocationService] [reindex-node-9215609200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[queries][0]] ...]).
[2019-06-03T16:10:30,520][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluent-f8f1560e] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:30,625][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluent-57acbc7b] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:30,764][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [project/4sf0MoHFS6e6N8rPYGpu0w] update_mapping [_doc]
[2019-06-03T16:10:30,865][INFO ][o.e.c.r.a.AllocationService] [reindex-node-9215609200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluent-57acbc7b][1], [nest-fluent-57acbc7b][0]] ...]).
[2019-06-03T16:10:31,782][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] create_mapping [_doc]
[2019-06-03T16:10:31,925][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] update_mapping [_doc]
[2019-06-03T16:10:31,945][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] create_mapping [_doc]
[2019-06-03T16:10:31,952][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] update_mapping [_doc]
[2019-06-03T16:10:32,117][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] update_mapping [_doc]
[2019-06-03T16:10:32,290][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] update_mapping [_doc]
[2019-06-03T16:10:32,479][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] update_mapping [_doc]
[2019-06-03T16:10:32,494][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] update_mapping [_doc]
[2019-06-03T16:10:32,500][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] update_mapping [_doc]
[2019-06-03T16:10:33,129][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] update_mapping [_doc]
[2019-06-03T16:10:33,256][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-57acbc7b/OnXVGwI7QISOBlEvAj1Ikg] update_mapping [_doc]
[2019-06-03T16:10:33,264][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-f8f1560e/MnFDELKmR5KTbOFu-6jW0Q] update_mapping [_doc]
[2019-06-03T16:10:34,122][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:34,778][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializer-6c25db74] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:35,065][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluentasync-74a63f46] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:35,115][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluent-9bfb5660] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:35,249][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [.tasks] creating index, cause [auto(task api)], templates [nest_tests], shards [1]/[0], mappings [task]
[2019-06-03T16:10:35,655][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluentasync-6df0471d] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:35,697][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-fluentasync-aea358d7] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:36,408][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-6c25db74/mbuGgauuRfW03UHZKmJX7g] create_mapping [_doc]
[2019-06-03T16:10:36,422][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c/zRfCcEiIQY2HI9EypVqoRA] create_mapping [_doc]
[2019-06-03T16:10:36,429][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c/zRfCcEiIQY2HI9EypVqoRA] update_mapping [_doc]
[2019-06-03T16:10:36,435][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-6c25db74/mbuGgauuRfW03UHZKmJX7g] update_mapping [_doc]
[2019-06-03T16:10:36,675][INFO ][o.e.c.r.a.AllocationService] [reindex-node-9215609200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-fluentasync-74a63f46][1]] ...]).
[2019-06-03T16:10:36,754][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-6c25db74/mbuGgauuRfW03UHZKmJX7g] update_mapping [_doc]
[2019-06-03T16:10:36,791][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c/zRfCcEiIQY2HI9EypVqoRA] update_mapping [_doc]
[2019-06-03T16:10:36,796][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-6c25db74/mbuGgauuRfW03UHZKmJX7g] update_mapping [_doc]
[2019-06-03T16:10:36,799][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c/zRfCcEiIQY2HI9EypVqoRA] update_mapping [_doc]
[2019-06-03T16:10:36,874][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-6c25db74/mbuGgauuRfW03UHZKmJX7g] update_mapping [_doc]
[2019-06-03T16:10:36,914][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-d8fe9b4c/zRfCcEiIQY2HI9EypVqoRA] update_mapping [_doc]
[2019-06-03T16:10:37,060][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-9bfb5660/RKXKGJdFQCi_s4C9P_NyXg] create_mapping [_doc]
[2019-06-03T16:10:37,064][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-9bfb5660/RKXKGJdFQCi_s4C9P_NyXg] update_mapping [_doc]
[2019-06-03T16:10:37,075][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 194 finished with response BulkByScrollResponse[took=732.8ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=0,batches=1,versionConflicts=100,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:37,124][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-aea358d7/51RJt_nZQWOwXxgEmuUxCg] create_mapping [_doc]
[2019-06-03T16:10:37,128][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-aea358d7/51RJt_nZQWOwXxgEmuUxCg] update_mapping [_doc]
[2019-06-03T16:10:37,187][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-9bfb5660/RKXKGJdFQCi_s4C9P_NyXg] update_mapping [_doc]
[2019-06-03T16:10:37,190][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-9bfb5660/RKXKGJdFQCi_s4C9P_NyXg] update_mapping [_doc]
[2019-06-03T16:10:37,256][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-aea358d7/51RJt_nZQWOwXxgEmuUxCg] update_mapping [_doc]
[2019-06-03T16:10:37,321][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluent-9bfb5660/RKXKGJdFQCi_s4C9P_NyXg] update_mapping [_doc]
[2019-06-03T16:10:37,384][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-aea358d7/51RJt_nZQWOwXxgEmuUxCg] update_mapping [_doc]
[2019-06-03T16:10:37,386][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-aea358d7/51RJt_nZQWOwXxgEmuUxCg] update_mapping [_doc]
[2019-06-03T16:10:37,525][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 218 finished with response BulkByScrollResponse[took=2.5s,timed_out=false,sliceId=null,updated=55,created=0,deleted=0,batches=1,versionConflicts=45,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:37,537][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 180 finished with response BulkByScrollResponse[took=2.5s,timed_out=false,sliceId=null,updated=29,created=0,deleted=0,batches=1,versionConflicts=71,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:37,557][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-6df0471d/4jaYS3JLR8qKHST24Clv6g] create_mapping [_doc]
[2019-06-03T16:10:37,570][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 165 finished with response BulkByScrollResponse[took=2.7s,timed_out=false,sliceId=null,updated=16,created=0,deleted=0,batches=1,versionConflicts=84,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:37,632][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-6df0471d/4jaYS3JLR8qKHST24Clv6g] update_mapping [_doc]
[2019-06-03T16:10:37,637][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-74a63f46/NeMGhZAvT5u9jl5jwMvtkQ] create_mapping [_doc]
[2019-06-03T16:10:37,642][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-74a63f46/NeMGhZAvT5u9jl5jwMvtkQ] update_mapping [_doc]
[2019-06-03T16:10:37,727][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-6df0471d/4jaYS3JLR8qKHST24Clv6g] update_mapping [_doc]
[2019-06-03T16:10:37,806][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-74a63f46/NeMGhZAvT5u9jl5jwMvtkQ] update_mapping [_doc]
[2019-06-03T16:10:37,808][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-74a63f46/NeMGhZAvT5u9jl5jwMvtkQ] update_mapping [_doc]
[2019-06-03T16:10:37,868][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-6df0471d/4jaYS3JLR8qKHST24Clv6g] update_mapping [_doc]
[2019-06-03T16:10:37,870][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-6df0471d/4jaYS3JLR8qKHST24Clv6g] update_mapping [_doc]
[2019-06-03T16:10:37,919][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-fluentasync-74a63f46/NeMGhZAvT5u9jl5jwMvtkQ] update_mapping [_doc]
[2019-06-03T16:10:38,062][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 187 finished with response BulkByScrollResponse[took=3.7s,timed_out=false,sliceId=null,updated=0,created=100,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:38,144][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 176 finished with response BulkByScrollResponse[took=4.2s,timed_out=false,sliceId=null,updated=0,created=100,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:38,889][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 212 finished with response BulkByScrollResponse[took=4.8s,timed_out=false,sliceId=null,updated=0,created=100,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:39,043][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 164 finished with response BulkByScrollResponse[took=5.2s,timed_out=false,sliceId=null,updated=0,created=100,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:39,062][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializer-58106723] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:39,161][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializer-9d733f44] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:39,523][INFO ][o.e.c.r.a.AllocationService] [reindex-node-9215609200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializer-9d733f44][0]] ...]).
[2019-06-03T16:10:39,582][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] create_mapping [_doc]
[2019-06-03T16:10:39,586][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] update_mapping [_doc]
[2019-06-03T16:10:39,642][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-9d733f44/Nk8I0aYlQ4G08CFbw_ihHg] create_mapping [_doc]
[2019-06-03T16:10:39,646][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-9d733f44/Nk8I0aYlQ4G08CFbw_ihHg] update_mapping [_doc]
[2019-06-03T16:10:39,741][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] update_mapping [_doc]
[2019-06-03T16:10:39,812][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] update_mapping [_doc]
[2019-06-03T16:10:39,820][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-9d733f44/Nk8I0aYlQ4G08CFbw_ihHg] update_mapping [_doc]
[2019-06-03T16:10:39,947][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] update_mapping [_doc]
[2019-06-03T16:10:39,995][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-58106723/5qjdp78aQIqfU95FYh58NA] update_mapping [_doc]
[2019-06-03T16:10:40,000][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-9d733f44/Nk8I0aYlQ4G08CFbw_ihHg] update_mapping [_doc]
[2019-06-03T16:10:40,002][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializer-9d733f44/Nk8I0aYlQ4G08CFbw_ihHg] update_mapping [_doc]
[2019-06-03T16:10:40,783][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializerasync-6d780dea] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:40,852][INFO ][o.e.c.m.MetaDataCreateIndexService] [reindex-node-9215609200] [nest-initializerasync-5727da4e] creating index, cause [auto(bulk api)], templates [nest_tests], shards [2]/[0], mappings []
[2019-06-03T16:10:41,073][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-6d780dea/zhLYZDxnRPaxgmDYedIJlw] create_mapping [_doc]
[2019-06-03T16:10:41,137][INFO ][o.e.c.r.a.AllocationService] [reindex-node-9215609200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[nest-initializerasync-5727da4e][0], [nest-initializerasync-5727da4e][1]] ...]).
[2019-06-03T16:10:41,176][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-6d780dea/zhLYZDxnRPaxgmDYedIJlw] update_mapping [_doc]
[2019-06-03T16:10:41,178][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-6d780dea/zhLYZDxnRPaxgmDYedIJlw] update_mapping [_doc]
[2019-06-03T16:10:41,183][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] create_mapping [_doc]
[2019-06-03T16:10:41,236][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] update_mapping [_doc]
[2019-06-03T16:10:41,275][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] update_mapping [_doc]
[2019-06-03T16:10:41,281][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-6d780dea/zhLYZDxnRPaxgmDYedIJlw] update_mapping [_doc]
[2019-06-03T16:10:41,283][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-6d780dea/zhLYZDxnRPaxgmDYedIJlw] update_mapping [_doc]
[2019-06-03T16:10:41,334][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] update_mapping [_doc]
[2019-06-03T16:10:41,434][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] update_mapping [_doc]
[2019-06-03T16:10:41,481][INFO ][o.e.c.m.MetaDataMappingService] [reindex-node-9215609200] [nest-initializerasync-5727da4e/3Fcu8BApSGuFroHrlQYNdA] update_mapping [_doc]
[2019-06-03T16:10:43,099][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 679 finished with response BulkByScrollResponse[took=753.2ms,timed_out=false,sliceId=null,updated=100,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:43,882][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 708 finished with response BulkByScrollResponse[took=1.1s,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:44,585][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 745 finished with response BulkByScrollResponse[took=1.1s,timed_out=false,sliceId=null,updated=100,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:46,083][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 817 finished with response BulkByScrollResponse[took=1.1s,timed_out=false,sliceId=null,updated=100,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:46,262][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 781 finished with response BulkByScrollResponse[took=2s,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:46,964][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 855 finished with response BulkByScrollResponse[took=899.8ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:47,266][INFO ][o.e.n.Node               ] [reindex-node-9215609200] stopping ...
[2019-06-03T16:10:47,292][INFO ][o.e.x.w.WatcherService   ] [reindex-node-9215609200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:10:47,530][INFO ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 892 finished with response BulkByScrollResponse[took=1s,timed_out=false,sliceId=null,updated=100,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2019-06-03T16:10:47,556][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [reindex-node-9215609200] [controller/3412] [Main.cc@148] Ml controller exiting
[2019-06-03T16:10:47,556][INFO ][o.e.x.m.p.NativeController] [reindex-node-9215609200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:10:47,553][WARN ][o.e.a.s.TransportClearScrollAction] [reindex-node-9215609200] Clear SC failed on node[{reindex-node-9215609200}{x3tES0GhQYG1Ue21QkTu8w}{R4os1NyET7Ghc8JHVGdNJw}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]
org.elasticsearch.transport.SendRequestTransportException: [reindex-node-9215609200][127.0.0.1:9300][indices:data/read/search[free_context/scroll]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.SearchTransportService.sendFreeContext(SearchTransportService.java:108) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$cleanScrollIds$4(ClearScrollController.java:114) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.SearchScrollAsyncAction.collectNodesAndRun(SearchScrollAsyncAction.java:129) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.cleanScrollIds(ClearScrollController.java:105) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$new$1(ClearScrollController.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.run(ClearScrollController.java:80) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.TransportClearScrollAction.doExecute(TransportClearScrollAction.java:46) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.TransportClearScrollAction.doExecute(TransportClearScrollAction.java:30) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.clearScroll(AbstractClient.java:616) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource.clearScroll(ClientScrollableHitSource.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ScrollableHitSource.close(ScrollableHitSource.java:88) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction.finishHim(AbstractAsyncBulkByScrollAction.java:483) ~[?:?]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction$3.onResponse(AbstractAsyncBulkByScrollAction.java:453) ~[?:?]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction$3.onResponse(AbstractAsyncBulkByScrollAction.java:450) ~[?:?]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:68) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction.finishAndNotifyListener(TransportBroadcastReplicationAction.java:167) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction.access$200(TransportBroadcastReplicationAction.java:53) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction$1.onFailure(TransportBroadcastReplicationAction.java:108) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:74) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishAsFailed(TransportReplicationAction.java:928) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleException(TransportReplicationAction.java:886) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:276) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 37 more
[2019-06-03T16:10:47,553][WARN ][o.e.a.s.TransportClearScrollAction] [reindex-node-9215609200] Clear SC failed on node[{reindex-node-9215609200}{x3tES0GhQYG1Ue21QkTu8w}{R4os1NyET7Ghc8JHVGdNJw}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]
org.elasticsearch.transport.SendRequestTransportException: [reindex-node-9215609200][127.0.0.1:9300][indices:data/read/search[free_context/scroll]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.SearchTransportService.sendFreeContext(SearchTransportService.java:108) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$cleanScrollIds$4(ClearScrollController.java:114) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.SearchScrollAsyncAction.collectNodesAndRun(SearchScrollAsyncAction.java:129) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.cleanScrollIds(ClearScrollController.java:105) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$new$1(ClearScrollController.java:71) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.run(ClearScrollController.java:80) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.TransportClearScrollAction.doExecute(TransportClearScrollAction.java:46) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.TransportClearScrollAction.doExecute(TransportClearScrollAction.java:30) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.clearScroll(AbstractClient.java:616) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource.clearScroll(ClientScrollableHitSource.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ScrollableHitSource.close(ScrollableHitSource.java:88) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction.finishHim(AbstractAsyncBulkByScrollAction.java:483) ~[?:?]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction$3.onResponse(AbstractAsyncBulkByScrollAction.java:453) ~[?:?]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction$3.onResponse(AbstractAsyncBulkByScrollAction.java:450) ~[?:?]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:68) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction.finishAndNotifyListener(TransportBroadcastReplicationAction.java:167) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction.access$200(TransportBroadcastReplicationAction.java:53) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportBroadcastReplicationAction$1.onFailure(TransportBroadcastReplicationAction.java:108) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:74) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishAsFailed(TransportReplicationAction.java:928) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleException(TransportReplicationAction.java:886) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:276) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 37 more
[2019-06-03T16:10:47,683][WARN ][o.e.t.TransportService   ] [reindex-node-9215609200] Transport response handler not found of id [448]
[2019-06-03T16:10:47,741][WARN ][o.e.t.TaskManager        ] [reindex-node-9215609200] couldn't store response BulkByScrollResponse[took=727ms,timed_out=false,sliceId=null,updated=0,created=0,deleted=100,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
org.elasticsearch.transport.SendRequestTransportException: [reindex-node-9215609200][127.0.0.1:9300][indices:data/write/bulk[s][p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:434) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:547) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:253) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:93) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:65) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.OriginSettingClient.doExecute(OriginSettingClient.java:51) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:70) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.doStoreResult(TaskResultsService.java:179) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.doStoreResult(TaskResultsService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.storeResult(TaskResultsService.java:150) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskManager.storeResult(TaskManager.java:237) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$TaskResultStoringActionListener.onResponse(TransportAction.java:174) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$TaskResultStoringActionListener.onResponse(TransportAction.java:160) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction.lambda$finishHim$4(AbstractAsyncBulkByScrollAction.java:488) ~[?:?]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource.cleanup(ClientScrollableHitSource.java:115) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ScrollableHitSource.lambda$close$2(ScrollableHitSource.java:88) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource$1.onResponse(ClientScrollableHitSource.java:102) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource$1.onResponse(ClientScrollableHitSource.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:68) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.onFailedFreedContext(ClearScrollController.java:142) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$cleanScrollIds$3(ClearScrollController.java:115) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:69) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$6.doRun(TransportService.java:660) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 54 more
[2019-06-03T16:10:47,821][WARN ][o.e.t.LoggingTaskListener] [reindex-node-9215609200] 921 failed with exception
org.elasticsearch.transport.SendRequestTransportException: [reindex-node-9215609200][127.0.0.1:9300][indices:data/write/bulk[s][p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:639) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:542) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:530) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:855) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:806) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:793) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:170) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:99) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:434) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:547) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:253) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:93) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:65) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.OriginSettingClient.doExecute(OriginSettingClient.java:51) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:70) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.doStoreResult(TaskResultsService.java:179) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.doStoreResult(TaskResultsService.java:175) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskResultsService.storeResult(TaskResultsService.java:150) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.tasks.TaskManager.storeResult(TaskManager.java:237) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$TaskResultStoringActionListener.onResponse(TransportAction.java:174) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$TaskResultStoringActionListener.onResponse(TransportAction.java:160) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.AbstractAsyncBulkByScrollAction.lambda$finishHim$4(AbstractAsyncBulkByScrollAction.java:488) ~[?:?]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource.cleanup(ClientScrollableHitSource.java:115) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ScrollableHitSource.lambda$close$2(ScrollableHitSource.java:88) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource$1.onResponse(ClientScrollableHitSource.java:102) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.index.reindex.ClientScrollableHitSource$1.onResponse(ClientScrollableHitSource.java:98) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:68) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.support.TransportAction$1.onResponse(TransportAction.java:64) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.onFailedFreedContext(ClearScrollController.java:142) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.search.ClearScrollController.lambda$cleanScrollIds$3(ClearScrollController.java:115) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:69) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportService$6.doRun(TransportService.java:660) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:621) ~[elasticsearch-7.0.0.jar:7.0.0]
	... 54 more
[2019-06-03T16:10:48,178][INFO ][o.e.n.Node               ] [reindex-node-9215609200] stopped
[2019-06-03T16:10:48,178][INFO ][o.e.n.Node               ] [reindex-node-9215609200] closing ...
[2019-06-03T16:10:48,189][INFO ][o.e.n.Node               ] [reindex-node-9215609200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:10:48,404][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\data}
[2019-06-03T06:10:48,506][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\config}
[2019-06-03T06:10:48,509][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\logs}
[2019-06-03T06:10:48,511][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6\repositories}
[2019-06-03T06:10:48,512][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-4556f6}
[2019-06-03T06:10:48,710][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [Security|XPack|SSL]
[2019-06-03T06:10:48,711][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:10:48,711][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-a5b078]
[2019-06-03T06:10:48,712][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [True]
[2019-06-03T06:10:48,712][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [True]
[2019-06-03T06:10:48,712][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:10:48,713][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [x-pack]
[2019-06-03T06:10:48,713][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [Trial]
[2019-06-03T06:10:48,713][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:10:48,714][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:10:48,714][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:10:48,715][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:10:48,715][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:10:48,715][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:10:48,716][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:10:48,716][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:10:48,717][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home]
[2019-06-03T06:10:50,691][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:10:50,692][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078}
[2019-06-03T06:10:50,692][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config}
[2019-06-03T06:10:50,693][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config]
[2019-06-03T06:10:50,699][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} attempting to add xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\elasticsearch.yml]
[2019-06-03T06:10:50,700][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} saved xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\elasticsearch.yml]
[2019-06-03T06:10:50,707][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} adding roles to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\roles.yml
[2019-06-03T06:10:50,708][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} saved roles to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\roles.yml]
[2019-06-03T06:10:50,709][INFO ][Managed Elasticsearch    ]  {EnsureSecurityUsersInDefaultRealmAreAdded} using cached users and users_roles files from {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\config}
[2019-06-03T06:10:50,710][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} creating config files
[2019-06-03T06:10:50,710][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\node-certificates.zip
[2019-06-03T06:10:50,711][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates
[2019-06-03T06:10:50,717][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\unused-node-certificates.zip
[2019-06-03T06:10:50,717][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\unused-node-certificates
[2019-06-03T06:10:50,724][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack]
[2019-06-03T06:10:50,725][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\analysis]
[2019-06-03T06:10:50,730][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationInElasticsearchYaml} saved watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\elasticsearch.yml]
[2019-06-03T06:10:50,730][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [creating elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home\bin\elasticsearch-keystore.bat} {create}
Created elasticsearch keystore in C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config
[2019-06-03T06:10:57,514][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [creating elasticsearch.keystore] {0}
[2019-06-03T06:10:57,514][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home\bin\elasticsearch-keystore.bat} {add xpack.notification.slack.account.monitoring.secure_url -xf}
[2019-06-03T06:10:59,235][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {0}
[2019-06-03T06:10:59,235][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home\bin\elasticsearch-keystore.bat} {add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key -xf}
[2019-06-03T06:11:01,273][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {0}
[2019-06-03T06:11:01,275][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationSecretsInKeystore} added watcher action secrets to elasticsearch.keystore
[2019-06-03T06:11:01,277][INFO ][Managed Elasticsearch    ]  {EnsureNativeSecurityRealmEnabledInElasticsearchYaml} native security realm [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\elasticsearch.yml]
[2019-06-03T06:11:01,279][INFO ][Managed Elasticsearch    ] [watcherstate-node-0ff09e9200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home\bin\elasticsearch.bat]
[2019-06-03T06:11:01,281][INFO ][Managed Elasticsearch    ] [watcherstate-node-0ff09e9200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-a5b078 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\logs -E xpack.security.enabled=true -E xpack.security.http.ssl.enabled=true -E xpack.security.transport.ssl.enabled=true -E xpack.security.authc.realms.pki.pki1.enabled=true -E xpack.security.authc.token.enabled=true -E xpack.security.transport.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\node01\node01.key -E xpack.security.transport.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\node01\node01.crt -E xpack.security.transport.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\ca\ca.crt -E xpack.security.http.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\node01\node01.key -E xpack.security.http.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\node01\node01.crt -E xpack.security.http.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\node-certificates\ca\ca.crt -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=watcherstate-node-0ff09e9200 -E http.port=9200 -E cluster.initial_master_nodes=watcherstate-node-0ff09e9200}
[2019-06-03T16:11:05,570][INFO ][o.e.e.NodeEnvironment    ] [watcherstate-node-0ff09e9200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:11:05,575][INFO ][o.e.e.NodeEnvironment    ] [watcherstate-node-0ff09e9200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:11:05,582][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] node name [watcherstate-node-0ff09e9200], node ID [HSeVxIgqR5admDEktkVlAA]
[2019-06-03T16:11:05,584][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] version[7.0.0], pid[5304], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:11:05,585][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:11:05,586][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:11:22,499][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [aggs-matrix-stats]
[2019-06-03T16:11:22,499][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [analysis-common]
[2019-06-03T16:11:22,499][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [ingest-common]
[2019-06-03T16:11:22,500][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [ingest-geoip]
[2019-06-03T16:11:22,500][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [ingest-user-agent]
[2019-06-03T16:11:22,500][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [lang-expression]
[2019-06-03T16:11:22,501][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [lang-mustache]
[2019-06-03T16:11:22,501][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [lang-painless]
[2019-06-03T16:11:22,501][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [mapper-extras]
[2019-06-03T16:11:22,502][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [parent-join]
[2019-06-03T16:11:22,502][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [percolator]
[2019-06-03T16:11:22,502][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [rank-eval]
[2019-06-03T16:11:22,502][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [reindex]
[2019-06-03T16:11:22,503][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [repository-url]
[2019-06-03T16:11:22,503][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [transport-netty4]
[2019-06-03T16:11:22,503][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-ccr]
[2019-06-03T16:11:22,504][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-core]
[2019-06-03T16:11:22,504][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-deprecation]
[2019-06-03T16:11:22,504][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-graph]
[2019-06-03T16:11:22,504][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-ilm]
[2019-06-03T16:11:22,504][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-logstash]
[2019-06-03T16:11:22,505][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-ml]
[2019-06-03T16:11:22,505][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-monitoring]
[2019-06-03T16:11:22,505][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-rollup]
[2019-06-03T16:11:22,506][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-security]
[2019-06-03T16:11:22,506][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-sql]
[2019-06-03T16:11:22,506][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] loaded module [x-pack-watcher]
[2019-06-03T16:11:22,507][INFO ][o.e.p.PluginsService     ] [watcherstate-node-0ff09e9200] no plugins loaded
[2019-06-03T16:11:27,913][INFO ][o.e.x.s.a.s.FileRolesStore] [watcherstate-node-0ff09e9200] parsed [3] roles from file [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config\roles.yml]
[2019-06-03T16:11:28,714][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [watcherstate-node-0ff09e9200] [controller/8216] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:11:29,173][DEBUG][o.e.a.ActionModule       ] [watcherstate-node-0ff09e9200] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2019-06-03T16:11:29,517][INFO ][o.e.d.DiscoveryModule    ] [watcherstate-node-0ff09e9200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:11:30,607][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] initialized
[2019-06-03T16:11:30,608][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] starting ...
[2019-06-03T16:11:31,408][INFO ][o.e.t.TransportService   ] [watcherstate-node-0ff09e9200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:11:31,419][WARN ][o.e.b.BootstrapChecks    ] [watcherstate-node-0ff09e9200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:11:31,432][INFO ][o.e.c.c.ClusterBootstrapService] [watcherstate-node-0ff09e9200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:11:34,434][INFO ][o.e.c.c.Coordinator      ] [watcherstate-node-0ff09e9200] setting initial configuration to VotingConfiguration{HSeVxIgqR5admDEktkVlAA}
[2019-06-03T16:11:34,576][INFO ][o.e.c.s.MasterService    ] [watcherstate-node-0ff09e9200] elected-as-master ([1] nodes joined)[{watcherstate-node-0ff09e9200}{HSeVxIgqR5admDEktkVlAA}{x9uIZUGqTkubEKch2V7LIQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{watcherstate-node-0ff09e9200}{HSeVxIgqR5admDEktkVlAA}{x9uIZUGqTkubEKch2V7LIQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:11:34,655][INFO ][o.e.c.s.ClusterApplierService] [watcherstate-node-0ff09e9200] master node changed {previous [], current [{watcherstate-node-0ff09e9200}{HSeVxIgqR5admDEktkVlAA}{x9uIZUGqTkubEKch2V7LIQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:11:34,848][INFO ][o.e.g.GatewayService     ] [watcherstate-node-0ff09e9200] recovered [0] indices into cluster_state
[2019-06-03T16:11:35,095][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:11:35,164][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:11:35,264][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:11:35,339][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:11:35,413][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:11:35,497][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:11:35,580][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:11:35,637][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:11:35,736][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [watcherstate-node-0ff09e9200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:11:35,805][INFO ][o.e.h.AbstractHttpServerTransport] [watcherstate-node-0ff09e9200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:11:35,806][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] started
[2019-06-03T06:11:35,811][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T16:11:36,054][INFO ][o.e.l.LicenseService     ] [watcherstate-node-0ff09e9200] license [7ff4682a-20be-4b60-8f12-34a52a54cad2] mode [basic] - valid
[2019-06-03T06:11:36,227][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:11:36,304][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} attempting to post license json
[2019-06-03T16:11:36,456][INFO ][o.e.l.LicenseService     ] [watcherstate-node-0ff09e9200] license [integ-test-license] mode [platinum] - valid
[2019-06-03T06:11:36,461][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:11:36,656][INFO ][Managed Elasticsearch    ]  All good! kicking off [WatcherStateCluster] tests now
[2019-06-03T16:11:36,742][DEBUG][o.e.a.a.i.t.d.TransportDeleteIndexTemplateAction] [watcherstate-node-0ff09e9200] failed to delete templates [nest_tests]
org.elasticsearch.indices.IndexTemplateMissingException: index_template [nest_tests] missing
	at org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService$1.execute(MetaDataIndexTemplateService.java:117) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252) [elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215) [elasticsearch-7.0.0.jar:7.0.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
[2019-06-03T16:11:36,836][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,843][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,844][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,876][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,881][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,883][INFO ][o.e.c.s.ClusterSettings  ] [watcherstate-node-0ff09e9200] updating [cluster.remote.remote-cluster.seeds] from [[]] to [["127.0.0.1:9300"]]
[2019-06-03T16:11:36,962][WARN ][o.e.t.OutboundHandler    ] [watcherstate-node-0ff09e9200] send message failed [channel: Netty4TcpChannel{localAddress=/127.0.0.1:52555, remoteAddress=/127.0.0.1:9300}]
javax.net.ssl.SSLException: SSLEngine closed already
	at io.netty.handler.ssl.SslHandler.wrap(...) (Unknown Source) ~[?:?]
[2019-06-03T16:11:36,966][WARN ][o.e.x.c.s.t.n.SecurityNetty4Transport] [watcherstate-node-0ff09e9200] client did not trust this server's certificate, closing connection Netty4TcpChannel{localAddress=0.0.0.0/0.0.0.0:9300, remoteAddress=/127.0.0.1:52555}
[2019-06-03T16:11:36,969][WARN ][o.e.t.TcpTransport       ] [watcherstate-node-0ff09e9200] exception caught on transport layer [Netty4TcpChannel{localAddress=/127.0.0.1:52555, remoteAddress=/127.0.0.1:9300}], closing connection
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Handshaker.checkThrown(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.checkTaskThrown(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.readNetRecord(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.unwrap(Unknown Source) ~[?:?]
	at javax.net.ssl.SSLEngine.unwrap(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:295) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1301) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Alerts.getSSLException(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.fatal(Unknown Source) ~[?:?]
	at sun.security.ssl.SSLEngineImpl.fatal(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.fatalSE(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.fatalSE(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.checkServerCerts(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.serverCertificate(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.processMessage(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.processLoop(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at sun.security.ssl.Handshaker$DelegatedTask.run(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1464) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1369) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
Caused by: java.security.cert.CertificateException: No subject alternative names present
	at sun.security.util.HostnameChecker.matchIP(Unknown Source) ~[?:?]
	at sun.security.util.HostnameChecker.match(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkIdentity(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkIdentity(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkTrusted(Unknown Source) ~[?:?]
	at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.checkServerCerts(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.serverCertificate(Unknown Source) ~[?:?]
	at sun.security.ssl.ClientHandshaker.processMessage(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker.processLoop(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at sun.security.ssl.Handshaker$1.run(Unknown Source) ~[?:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:?]
	at sun.security.ssl.Handshaker$DelegatedTask.run(Unknown Source) ~[?:?]
	at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1464) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1369) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1203) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[netty-handler-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.32.Final.jar:4.1.32.Final]
	... 15 more
[2019-06-03T16:11:36,975][WARN ][o.e.t.RemoteClusterConnection] [watcherstate-node-0ff09e9200] fetching nodes from external cluster [remote-cluster] failed
org.elasticsearch.transport.ConnectTransportException: [][127.0.0.1:9300] general node connection failure
	at org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener$1.onFailure(TcpTransport.java:1284) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker$HandshakeResponseHandler.handleLocalException(TransportHandshaker.java:155) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker.lambda$sendHandshake$0(TransportHandshaker.java:67) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$wrap$0(ActionListener.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:97) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:39) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(Unknown Source) ~[?:?]
	at org.elasticsearch.common.concurrent.CompletableContext.complete(CompletableContext.java:61) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.netty4.Netty4TcpChannel.lambda$new$0(Netty4TcpChannel.java:51) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103) ~[?:?]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[?:?]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1152) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:768) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:744) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:615) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.close(DefaultChannelPipeline.java:1376) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:624) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:608) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:465) ~[?:?]
	at io.netty.handler.ssl.SslUtils.handleHandshakeFailure(SslUtils.java:350) ~[?:?]
	at io.netty.handler.ssl.SslHandler.setHandshakeFailure(SslHandler.java:1581) ~[?:?]
	at io.netty.handler.ssl.SslHandler.handleUnwrapThrowable(SslHandler.java:1239) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1209) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[?:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) ~[?:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) ~[?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: handshake failed because connection reset
	... 47 more
[2019-06-03T16:11:37,045][INFO ][o.e.c.m.MetaDataIndexTemplateService] [watcherstate-node-0ff09e9200] adding template [nest_tests] for index patterns [*]
[2019-06-03T16:11:37,057][WARN ][o.e.t.RemoteClusterService] [watcherstate-node-0ff09e9200] failed to update seed list for cluster: remote-cluster
org.elasticsearch.transport.ConnectTransportException: [][127.0.0.1:9300] general node connection failure
	at org.elasticsearch.transport.TcpTransport$ChannelsConnectedListener$1.onFailure(TcpTransport.java:1284) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker$HandshakeResponseHandler.handleLocalException(TransportHandshaker.java:155) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.TransportHandshaker.lambda$sendHandshake$0(TransportHandshaker.java:67) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$wrap$0(ActionListener.java:83) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.action.ActionListener.lambda$toBiConsumer$2(ActionListener.java:97) ~[elasticsearch-7.0.0.jar:7.0.0]
	at org.elasticsearch.common.concurrent.CompletableContext.lambda$addListener$0(CompletableContext.java:39) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.postComplete(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.complete(Unknown Source) ~[?:?]
	at org.elasticsearch.common.concurrent.CompletableContext.complete(CompletableContext.java:61) ~[elasticsearch-core-7.0.0.jar:7.0.0]
	at org.elasticsearch.transport.netty4.Netty4TcpChannel.lambda$new$0(Netty4TcpChannel.java:51) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:511) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:504) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:483) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:424) ~[?:?]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:103) ~[?:?]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[?:?]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1152) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:768) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:744) ~[?:?]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:615) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.close(DefaultChannelPipeline.java:1376) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:624) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:608) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:465) ~[?:?]
	at io.netty.handler.ssl.SslUtils.handleHandshakeFailure(SslUtils.java:350) ~[?:?]
	at io.netty.handler.ssl.SslHandler.setHandshakeFailure(SslHandler.java:1581) ~[?:?]
	at io.netty.handler.ssl.SslHandler.handleUnwrapThrowable(SslHandler.java:1239) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1209) ~[?:?]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1247) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[?:?]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:278) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[?:?]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[?:?]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[?:?]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) ~[?:?]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) ~[?:?]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) ~[?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: org.elasticsearch.transport.TransportException: handshake failed because connection reset
	... 47 more
[2019-06-03T16:11:37,255][INFO ][o.e.c.m.MetaDataCreateIndexService] [watcherstate-node-0ff09e9200] [devs] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:11:37,458][INFO ][o.e.c.m.MetaDataCreateIndexService] [watcherstate-node-0ff09e9200] [project] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:11:37,638][INFO ][o.e.c.m.MetaDataCreateIndexService] [watcherstate-node-0ff09e9200] [queries] creating index, cause [api], templates [nest_tests], shards [2]/[0], mappings [_doc]
[2019-06-03T16:11:38,168][INFO ][o.e.c.r.a.AllocationService] [watcherstate-node-0ff09e9200] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[queries][1]] ...]).
[2019-06-03T16:11:38,404][INFO ][o.e.c.m.MetaDataMappingService] [watcherstate-node-0ff09e9200] [project/0cBzdoLxQBGnN7ckdX8n0Q] update_mapping [_doc]
[2019-06-03T16:11:39,509][INFO ][o.e.c.m.MetaDataMappingService] [watcherstate-node-0ff09e9200] [project/0cBzdoLxQBGnN7ckdX8n0Q] update_mapping [_doc]
[2019-06-03T16:11:41,443][INFO ][o.e.x.w.WatcherService   ] [watcherstate-node-0ff09e9200] stopping watch service, reason [watcher manually marked to shutdown by cluster state update]
[2019-06-03T16:11:41,538][INFO ][o.e.x.w.WatcherService   ] [watcherstate-node-0ff09e9200] stopping watch service, reason [watcher manually marked to shutdown by cluster state update]
[2019-06-03T16:11:41,634][INFO ][o.e.x.w.WatcherService   ] [watcherstate-node-0ff09e9200] stopping watch service, reason [watcher manually marked to shutdown by cluster state update]
[2019-06-03T16:11:41,741][INFO ][o.e.x.w.WatcherService   ] [watcherstate-node-0ff09e9200] stopping watch service, reason [watcher manually marked to shutdown by cluster state update]
[2019-06-03T16:11:41,855][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] stopping ...
[2019-06-03T16:11:41,862][INFO ][o.e.x.w.WatcherService   ] [watcherstate-node-0ff09e9200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:11:42,343][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [watcherstate-node-0ff09e9200] [controller/8216] [Main.cc@148] Ml controller exiting
[2019-06-03T16:11:42,344][INFO ][o.e.x.m.p.NativeController] [watcherstate-node-0ff09e9200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:11:42,474][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] stopped
[2019-06-03T16:11:42,475][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] closing ...
[2019-06-03T16:11:42,482][INFO ][o.e.n.Node               ] [watcherstate-node-0ff09e9200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:11:42,658][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\data}
[2019-06-03T06:11:42,682][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\config}
[2019-06-03T06:11:42,689][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\logs}
[2019-06-03T06:11:42,691][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078\repositories}
[2019-06-03T06:11:42,691][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-a5b078}
 -> Several tests skipped because they have no cluster associated
[2019-06-03T06:11:42,910][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [Security|XPack|SSL]
[2019-06-03T06:11:42,910][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:11:42,911][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-6f2320]
[2019-06-03T06:11:42,911][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [True]
[2019-06-03T06:11:42,911][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [True]
[2019-06-03T06:11:42,912][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:11:42,912][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [x-pack]
[2019-06-03T06:11:42,912][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [Trial]
[2019-06-03T06:11:42,913][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:11:42,913][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:11:42,913][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:11:42,914][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:11:42,914][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [True]
[2019-06-03T06:11:42,915][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:11:42,915][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:11:42,915][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:11:42,916][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home]
[2019-06-03T06:11:44,240][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:11:44,240][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320}
[2019-06-03T06:11:44,241][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config}
[2019-06-03T06:11:44,241][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config]
[2019-06-03T06:11:44,248][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} attempting to add xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\elasticsearch.yml]
[2019-06-03T06:11:44,249][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} saved xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\elasticsearch.yml]
[2019-06-03T06:11:44,250][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} adding roles to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\roles.yml
[2019-06-03T06:11:44,251][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} saved roles to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\roles.yml]
[2019-06-03T06:11:44,254][INFO ][Managed Elasticsearch    ]  {EnsureSecurityUsersInDefaultRealmAreAdded} using cached users and users_roles files from {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\config}
[2019-06-03T06:11:44,255][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} creating config files
[2019-06-03T06:11:44,255][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\node-certificates.zip
[2019-06-03T06:11:44,256][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates
[2019-06-03T06:11:44,262][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\unused-node-certificates.zip
[2019-06-03T06:11:44,262][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\unused-node-certificates
[2019-06-03T06:11:44,271][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack]
[2019-06-03T06:11:44,271][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\analysis]
[2019-06-03T06:11:44,276][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationInElasticsearchYaml} saved watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\elasticsearch.yml]
[2019-06-03T06:11:44,276][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [creating elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home\bin\elasticsearch-keystore.bat} {create}
Created elasticsearch keystore in C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config
[2019-06-03T06:11:51,127][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [creating elasticsearch.keystore] {0}
[2019-06-03T06:11:51,128][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home\bin\elasticsearch-keystore.bat} {add xpack.notification.slack.account.monitoring.secure_url -xf}
[2019-06-03T06:11:52,745][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {0}
[2019-06-03T06:11:52,746][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home\bin\elasticsearch-keystore.bat} {add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key -xf}
[2019-06-03T06:11:54,402][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {0}
[2019-06-03T06:11:54,403][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationSecretsInKeystore} added watcher action secrets to elasticsearch.keystore
[2019-06-03T06:11:54,405][INFO ][Managed Elasticsearch    ]  {EnsureNativeSecurityRealmEnabledInElasticsearchYaml} native security realm [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\elasticsearch.yml]
[2019-06-03T06:11:54,405][INFO ][Managed Elasticsearch    ] [denyallcertificates-node-1531489200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home\bin\elasticsearch.bat]
[2019-06-03T06:11:54,406][INFO ][Managed Elasticsearch    ] [denyallcertificates-node-1531489200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-6f2320 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\logs -E xpack.security.enabled=true -E xpack.security.http.ssl.enabled=true -E xpack.security.transport.ssl.enabled=true -E xpack.security.authc.realms.pki.pki1.enabled=true -E xpack.security.authc.token.enabled=true -E xpack.security.transport.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\node01\node01.key -E xpack.security.transport.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\node01\node01.crt -E xpack.security.transport.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\ca\ca.crt -E xpack.security.http.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\node01\node01.key -E xpack.security.http.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\node01\node01.crt -E xpack.security.http.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\node-certificates\ca\ca.crt -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=denyallcertificates-node-1531489200 -E http.port=9200 -E cluster.initial_master_nodes=denyallcertificates-node-1531489200}
[2019-06-03T16:11:58,032][INFO ][o.e.e.NodeEnvironment    ] [denyallcertificates-node-1531489200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:11:58,036][INFO ][o.e.e.NodeEnvironment    ] [denyallcertificates-node-1531489200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:11:58,042][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] node name [denyallcertificates-node-1531489200], node ID [zWOMoLoZQdKEoFlNgZcQNw]
[2019-06-03T16:11:58,043][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] version[7.0.0], pid[10796], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:11:58,044][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:11:58,044][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:12:13,573][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [aggs-matrix-stats]
[2019-06-03T16:12:13,574][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [analysis-common]
[2019-06-03T16:12:13,574][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [ingest-common]
[2019-06-03T16:12:13,575][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [ingest-geoip]
[2019-06-03T16:12:13,575][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [ingest-user-agent]
[2019-06-03T16:12:13,576][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [lang-expression]
[2019-06-03T16:12:13,576][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [lang-mustache]
[2019-06-03T16:12:13,576][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [lang-painless]
[2019-06-03T16:12:13,577][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [mapper-extras]
[2019-06-03T16:12:13,577][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [parent-join]
[2019-06-03T16:12:13,577][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [percolator]
[2019-06-03T16:12:13,577][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [rank-eval]
[2019-06-03T16:12:13,578][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [reindex]
[2019-06-03T16:12:13,578][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [repository-url]
[2019-06-03T16:12:13,578][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [transport-netty4]
[2019-06-03T16:12:13,578][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-ccr]
[2019-06-03T16:12:13,578][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-core]
[2019-06-03T16:12:13,579][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-deprecation]
[2019-06-03T16:12:13,579][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-graph]
[2019-06-03T16:12:13,579][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-ilm]
[2019-06-03T16:12:13,579][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-logstash]
[2019-06-03T16:12:13,579][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-ml]
[2019-06-03T16:12:13,580][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-monitoring]
[2019-06-03T16:12:13,580][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-rollup]
[2019-06-03T16:12:13,580][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-security]
[2019-06-03T16:12:13,580][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-sql]
[2019-06-03T16:12:13,581][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] loaded module [x-pack-watcher]
[2019-06-03T16:12:13,581][INFO ][o.e.p.PluginsService     ] [denyallcertificates-node-1531489200] no plugins loaded
[2019-06-03T16:12:17,873][INFO ][o.e.x.s.a.s.FileRolesStore] [denyallcertificates-node-1531489200] parsed [3] roles from file [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config\roles.yml]
[2019-06-03T16:12:18,458][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [denyallcertificates-node-1531489200] [controller/12376] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:12:18,932][DEBUG][o.e.a.ActionModule       ] [denyallcertificates-node-1531489200] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2019-06-03T16:12:19,332][INFO ][o.e.d.DiscoveryModule    ] [denyallcertificates-node-1531489200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:12:20,381][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] initialized
[2019-06-03T16:12:20,382][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] starting ...
[2019-06-03T16:12:21,195][INFO ][o.e.t.TransportService   ] [denyallcertificates-node-1531489200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:12:21,203][WARN ][o.e.b.BootstrapChecks    ] [denyallcertificates-node-1531489200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:12:21,218][INFO ][o.e.c.c.ClusterBootstrapService] [denyallcertificates-node-1531489200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:12:24,234][INFO ][o.e.c.c.Coordinator      ] [denyallcertificates-node-1531489200] setting initial configuration to VotingConfiguration{zWOMoLoZQdKEoFlNgZcQNw}
[2019-06-03T16:12:24,380][INFO ][o.e.c.s.MasterService    ] [denyallcertificates-node-1531489200] elected-as-master ([1] nodes joined)[{denyallcertificates-node-1531489200}{zWOMoLoZQdKEoFlNgZcQNw}{UTibbJV0ROGC1l1SivFOYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{denyallcertificates-node-1531489200}{zWOMoLoZQdKEoFlNgZcQNw}{UTibbJV0ROGC1l1SivFOYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:12:24,508][INFO ][o.e.c.s.ClusterApplierService] [denyallcertificates-node-1531489200] master node changed {previous [], current [{denyallcertificates-node-1531489200}{zWOMoLoZQdKEoFlNgZcQNw}{UTibbJV0ROGC1l1SivFOYA}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:12:24,727][INFO ][o.e.g.GatewayService     ] [denyallcertificates-node-1531489200] recovered [0] indices into cluster_state
[2019-06-03T16:12:24,938][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:12:25,053][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:12:25,297][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:12:25,526][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:12:25,670][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:12:25,742][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:12:25,817][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:12:25,866][INFO ][o.e.c.m.MetaDataIndexTemplateService] [denyallcertificates-node-1531489200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:12:25,935][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [denyallcertificates-node-1531489200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:12:26,087][INFO ][o.e.l.LicenseService     ] [denyallcertificates-node-1531489200] license [fff03d4c-e427-476d-a592-b32a2e7836f4] mode [basic] - valid
[2019-06-03T16:12:26,413][INFO ][o.e.h.AbstractHttpServerTransport] [denyallcertificates-node-1531489200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:12:26,414][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] started
[2019-06-03T16:12:26,577][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [denyallcertificates-node-1531489200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52605}
[2019-06-03T16:12:26,620][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [denyallcertificates-node-1531489200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52606}
[2019-06-03T16:12:26,659][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [denyallcertificates-node-1531489200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52607}
[2019-06-03T16:12:26,697][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [denyallcertificates-node-1531489200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52608}
[2019-06-03T16:12:26,882][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] stopping ...
[2019-06-03T16:12:26,897][INFO ][o.e.x.w.WatcherService   ] [denyallcertificates-node-1531489200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:12:27,355][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] stopped
[2019-06-03T16:12:27,355][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] closing ...
[2019-06-03T16:12:27,360][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [denyallcertificates-node-1531489200] [controller/12376] [Main.cc@148] Ml controller exiting
[2019-06-03T16:12:27,361][INFO ][o.e.x.m.p.NativeController] [denyallcertificates-node-1531489200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:12:27,365][INFO ][o.e.n.Node               ] [denyallcertificates-node-1531489200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:12:27,572][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\data}
[2019-06-03T06:12:27,575][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\config}
[2019-06-03T06:12:27,582][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\logs}
[2019-06-03T06:12:27,584][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320\repositories}
[2019-06-03T06:12:27,585][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-6f2320}
[2019-06-03T06:12:27,831][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [Security|XPack|SSL]
[2019-06-03T06:12:27,832][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:12:27,832][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-27060b]
[2019-06-03T06:12:27,833][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [True]
[2019-06-03T06:12:27,834][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [True]
[2019-06-03T06:12:27,834][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:12:27,835][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} [x-pack]
[2019-06-03T06:12:27,835][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [Trial]
[2019-06-03T06:12:27,836][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:12:27,837][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:12:27,837][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:12:27,838][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:12:27,839][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [True]
[2019-06-03T06:12:27,839][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:12:27,840][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:12:27,840][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:12:27,841][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home]
[2019-06-03T06:12:29,320][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:12:29,321][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b}
[2019-06-03T06:12:29,322][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config}
[2019-06-03T06:12:29,323][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config]
[2019-06-03T06:12:29,335][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} attempting to add xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\elasticsearch.yml]
[2019-06-03T06:12:29,336][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRealms} saved xpack realms to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\elasticsearch.yml]
[2019-06-03T06:12:29,336][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} adding roles to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\roles.yml
[2019-06-03T06:12:29,337][INFO ][Managed Elasticsearch    ]  {EnsureSecurityRolesFileExists} saved roles to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\roles.yml]
[2019-06-03T06:12:29,340][INFO ][Managed Elasticsearch    ]  {EnsureSecurityUsersInDefaultRealmAreAdded} using cached users and users_roles files from {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\config}
[2019-06-03T06:12:29,341][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} creating config files
[2019-06-03T06:12:29,341][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\node-certificates.zip
[2019-06-03T06:12:29,341][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates
[2019-06-03T06:12:29,351][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} using cached certificates from C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack\unused-node-certificates.zip
[2019-06-03T06:12:29,351][INFO ][Managed Elasticsearch    ]  {GenerateCertificatesTask} unzipping certificates to C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\unused-node-certificates
[2019-06-03T06:12:29,361][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-xsecssl-x-pack]
[2019-06-03T06:12:29,362][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\analysis]
[2019-06-03T06:12:29,368][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationInElasticsearchYaml} saved watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\elasticsearch.yml]
[2019-06-03T06:12:29,368][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [creating elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home\bin\elasticsearch-keystore.bat} {create}
Created elasticsearch keystore in C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config
[2019-06-03T06:12:37,750][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [creating elasticsearch.keystore] {0}
[2019-06-03T06:12:37,751][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home\bin\elasticsearch-keystore.bat} {add xpack.notification.slack.account.monitoring.secure_url -xf}
[2019-06-03T06:12:40,013][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.slack.account.monitoring.secure_url to elasticsearch.keystore] {0}
[2019-06-03T06:12:40,027][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} starting process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home\bin\elasticsearch-keystore.bat} {add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key -xf}
[2019-06-03T06:12:42,513][INFO ][Managed Elasticsearch    ]  {ExecuteBinary} finished process [add xpack.notification.pagerduty.account.my_pagerduty_account.secure_service_api_key to elasticsearch.keystore] {0}
[2019-06-03T06:12:42,513][INFO ][Managed Elasticsearch    ]  {EnsureWatcherActionConfigurationSecretsInKeystore} added watcher action secrets to elasticsearch.keystore
[2019-06-03T06:12:42,515][INFO ][Managed Elasticsearch    ]  {EnsureNativeSecurityRealmEnabledInElasticsearchYaml} native security realm [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\elasticsearch.yml]
[2019-06-03T06:12:42,515][INFO ][Managed Elasticsearch    ] [badcertgenca-node-2e7f679200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home\bin\elasticsearch.bat]
[2019-06-03T06:12:42,516][INFO ][Managed Elasticsearch    ] [badcertgenca-node-2e7f679200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-27060b -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\logs -E xpack.security.enabled=true -E xpack.security.http.ssl.enabled=true -E xpack.security.transport.ssl.enabled=true -E xpack.security.authc.realms.pki.pki1.enabled=true -E xpack.security.authc.token.enabled=true -E xpack.security.transport.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\node01\node01.key -E xpack.security.transport.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\node01\node01.crt -E xpack.security.transport.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\ca\ca.crt -E xpack.security.http.ssl.key=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\node01\node01.key -E xpack.security.http.ssl.certificate=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\node01\node01.crt -E xpack.security.http.ssl.certificate_authorities=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\node-certificates\ca\ca.crt -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=badcertgenca-node-2e7f679200 -E http.port=9200 -E cluster.initial_master_nodes=badcertgenca-node-2e7f679200}
[2019-06-03T16:12:47,386][INFO ][o.e.e.NodeEnvironment    ] [badcertgenca-node-2e7f679200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:12:47,390][INFO ][o.e.e.NodeEnvironment    ] [badcertgenca-node-2e7f679200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:12:47,396][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] node name [badcertgenca-node-2e7f679200], node ID [I0IOVftcS4uoDmu1tFrgpQ]
[2019-06-03T16:12:47,397][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] version[7.0.0], pid[18152], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:12:47,397][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:12:47,398][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:13:05,723][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [aggs-matrix-stats]
[2019-06-03T16:13:05,723][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [analysis-common]
[2019-06-03T16:13:05,724][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [ingest-common]
[2019-06-03T16:13:05,724][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [ingest-geoip]
[2019-06-03T16:13:05,724][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [ingest-user-agent]
[2019-06-03T16:13:05,725][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [lang-expression]
[2019-06-03T16:13:05,725][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [lang-mustache]
[2019-06-03T16:13:05,725][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [lang-painless]
[2019-06-03T16:13:05,726][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [mapper-extras]
[2019-06-03T16:13:05,726][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [parent-join]
[2019-06-03T16:13:05,726][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [percolator]
[2019-06-03T16:13:05,727][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [rank-eval]
[2019-06-03T16:13:05,727][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [reindex]
[2019-06-03T16:13:05,728][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [repository-url]
[2019-06-03T16:13:05,728][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [transport-netty4]
[2019-06-03T16:13:05,729][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-ccr]
[2019-06-03T16:13:05,729][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-core]
[2019-06-03T16:13:05,729][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-deprecation]
[2019-06-03T16:13:05,730][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-graph]
[2019-06-03T16:13:05,730][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-ilm]
[2019-06-03T16:13:05,730][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-logstash]
[2019-06-03T16:13:05,730][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-ml]
[2019-06-03T16:13:05,731][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-monitoring]
[2019-06-03T16:13:05,731][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-rollup]
[2019-06-03T16:13:05,731][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-security]
[2019-06-03T16:13:05,731][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-sql]
[2019-06-03T16:13:05,732][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] loaded module [x-pack-watcher]
[2019-06-03T16:13:05,733][INFO ][o.e.p.PluginsService     ] [badcertgenca-node-2e7f679200] no plugins loaded
[2019-06-03T16:13:12,596][INFO ][o.e.x.s.a.s.FileRolesStore] [badcertgenca-node-2e7f679200] parsed [3] roles from file [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config\roles.yml]
[2019-06-03T16:13:13,945][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [badcertgenca-node-2e7f679200] [controller/2724] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:13:14,404][DEBUG][o.e.a.ActionModule       ] [badcertgenca-node-2e7f679200] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2019-06-03T16:13:15,055][INFO ][o.e.d.DiscoveryModule    ] [badcertgenca-node-2e7f679200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:13:16,452][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] initialized
[2019-06-03T16:13:16,453][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] starting ...
[2019-06-03T16:13:17,370][INFO ][o.e.t.TransportService   ] [badcertgenca-node-2e7f679200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:13:17,381][WARN ][o.e.b.BootstrapChecks    ] [badcertgenca-node-2e7f679200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:13:17,397][INFO ][o.e.c.c.ClusterBootstrapService] [badcertgenca-node-2e7f679200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:13:20,409][INFO ][o.e.c.c.Coordinator      ] [badcertgenca-node-2e7f679200] setting initial configuration to VotingConfiguration{I0IOVftcS4uoDmu1tFrgpQ}
[2019-06-03T16:13:20,609][INFO ][o.e.c.s.MasterService    ] [badcertgenca-node-2e7f679200] elected-as-master ([1] nodes joined)[{badcertgenca-node-2e7f679200}{I0IOVftcS4uoDmu1tFrgpQ}{nSN6q2OQT1q4hccDaSoBlg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{badcertgenca-node-2e7f679200}{I0IOVftcS4uoDmu1tFrgpQ}{nSN6q2OQT1q4hccDaSoBlg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:13:20,674][INFO ][o.e.c.s.ClusterApplierService] [badcertgenca-node-2e7f679200] master node changed {previous [], current [{badcertgenca-node-2e7f679200}{I0IOVftcS4uoDmu1tFrgpQ}{nSN6q2OQT1q4hccDaSoBlg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:13:21,213][INFO ][o.e.g.GatewayService     ] [badcertgenca-node-2e7f679200] recovered [0] indices into cluster_state
[2019-06-03T16:13:21,486][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:13:21,607][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:13:21,778][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:13:21,920][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:13:22,005][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:13:22,102][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:13:22,177][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:13:22,268][INFO ][o.e.c.m.MetaDataIndexTemplateService] [badcertgenca-node-2e7f679200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:13:22,370][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [badcertgenca-node-2e7f679200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:13:22,373][INFO ][o.e.h.AbstractHttpServerTransport] [badcertgenca-node-2e7f679200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T16:13:22,375][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] started
[2019-06-03T16:13:22,658][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [badcertgenca-node-2e7f679200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52658}
[2019-06-03T16:13:22,725][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [badcertgenca-node-2e7f679200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52659}
[2019-06-03T16:13:22,775][INFO ][o.e.l.LicenseService     ] [badcertgenca-node-2e7f679200] license [6747078c-6626-4e0a-90cd-22b8f1e9cb84] mode [basic] - valid
[2019-06-03T16:13:22,796][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [badcertgenca-node-2e7f679200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52660}
[2019-06-03T16:13:22,845][WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [badcertgenca-node-2e7f679200] http client did not trust this server's certificate, closing connection Netty4HttpChannel{localAddress=0.0.0.0/0.0.0.0:9200, remoteAddress=/0:0:0:0:0:0:0:1:52661}
[2019-06-03T16:13:22,997][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] stopping ...
[2019-06-03T16:13:23,016][INFO ][o.e.x.w.WatcherService   ] [badcertgenca-node-2e7f679200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:13:23,359][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] stopped
[2019-06-03T16:13:23,360][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] closing ...
[2019-06-03T16:13:23,362][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [badcertgenca-node-2e7f679200] [controller/2724] [Main.cc@148] Ml controller exiting
[2019-06-03T16:13:23,363][INFO ][o.e.x.m.p.NativeController] [badcertgenca-node-2e7f679200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:13:23,375][INFO ][o.e.n.Node               ] [badcertgenca-node-2e7f679200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:13:23,597][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\data}
[2019-06-03T06:13:23,599][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\config}
[2019-06-03T06:13:23,606][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\logs}
[2019-06-03T06:13:23,609][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b\repositories}
[2019-06-03T06:13:23,610][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-27060b}
[2019-06-03T06:13:23,830][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T06:13:23,830][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:13:23,830][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-cff99c]
[2019-06-03T06:13:23,831][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T06:13:23,831][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T06:13:23,832][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:13:23,832][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} []
[2019-06-03T06:13:23,833][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T06:13:23,833][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:13:23,833][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:13:23,834][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:13:23,834][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:13:23,835][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:13:23,835][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:13:23,835][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:13:23,836][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:13:23,837][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\home]
[2019-06-03T06:13:25,533][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:13:25,536][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c}
[2019-06-03T06:13:25,537][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\config}
[2019-06-03T06:13:25,538][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\config]
[2019-06-03T06:13:25,550][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x]
[2019-06-03T06:13:25,552][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\config\analysis]
[2019-06-03T06:13:25,557][INFO ][Managed Elasticsearch    ] [triallicense-node-5f4de39200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\home\bin\elasticsearch.bat]
[2019-06-03T06:13:25,559][INFO ][Managed Elasticsearch    ] [triallicense-node-5f4de39200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-cff99c -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=triallicense-node-5f4de39200 -E http.port=9200 -E cluster.initial_master_nodes=triallicense-node-5f4de39200}
[2019-06-03T16:13:35,727][INFO ][o.e.e.NodeEnvironment    ] [triallicense-node-5f4de39200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:13:35,732][INFO ][o.e.e.NodeEnvironment    ] [triallicense-node-5f4de39200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:13:35,750][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] node name [triallicense-node-5f4de39200], node ID [sK32j3kTRJ21UfYGLvHyBQ]
[2019-06-03T16:13:35,752][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] version[7.0.0], pid[16628], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:13:35,755][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:13:35,756][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:13:57,255][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [aggs-matrix-stats]
[2019-06-03T16:13:57,255][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [analysis-common]
[2019-06-03T16:13:57,256][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [ingest-common]
[2019-06-03T16:13:57,256][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [ingest-geoip]
[2019-06-03T16:13:57,256][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [ingest-user-agent]
[2019-06-03T16:13:57,256][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [lang-expression]
[2019-06-03T16:13:57,257][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [lang-mustache]
[2019-06-03T16:13:57,257][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [lang-painless]
[2019-06-03T16:13:57,257][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [mapper-extras]
[2019-06-03T16:13:57,257][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [parent-join]
[2019-06-03T16:13:57,258][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [percolator]
[2019-06-03T16:13:57,258][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [rank-eval]
[2019-06-03T16:13:57,258][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [reindex]
[2019-06-03T16:13:57,258][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [repository-url]
[2019-06-03T16:13:57,259][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [transport-netty4]
[2019-06-03T16:13:57,259][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-ccr]
[2019-06-03T16:13:57,260][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-core]
[2019-06-03T16:13:57,260][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-deprecation]
[2019-06-03T16:13:57,260][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-graph]
[2019-06-03T16:13:57,261][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-ilm]
[2019-06-03T16:13:57,261][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-logstash]
[2019-06-03T16:13:57,261][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-ml]
[2019-06-03T16:13:57,262][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-monitoring]
[2019-06-03T16:13:57,262][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-rollup]
[2019-06-03T16:13:57,262][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-security]
[2019-06-03T16:13:57,262][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-sql]
[2019-06-03T16:13:57,263][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] loaded module [x-pack-watcher]
[2019-06-03T16:13:57,263][INFO ][o.e.p.PluginsService     ] [triallicense-node-5f4de39200] no plugins loaded
[2019-06-03T16:14:03,954][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [triallicense-node-5f4de39200] [controller/3428] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:14:05,424][INFO ][o.e.d.DiscoveryModule    ] [triallicense-node-5f4de39200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:14:06,931][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] initialized
[2019-06-03T16:14:06,932][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] starting ...
[2019-06-03T16:14:08,871][INFO ][o.e.t.TransportService   ] [triallicense-node-5f4de39200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:14:08,881][WARN ][o.e.b.BootstrapChecks    ] [triallicense-node-5f4de39200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:14:08,899][INFO ][o.e.c.c.ClusterBootstrapService] [triallicense-node-5f4de39200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:14:11,939][INFO ][o.e.c.c.Coordinator      ] [triallicense-node-5f4de39200] setting initial configuration to VotingConfiguration{sK32j3kTRJ21UfYGLvHyBQ}
[2019-06-03T16:14:12,436][INFO ][o.e.c.s.MasterService    ] [triallicense-node-5f4de39200] elected-as-master ([1] nodes joined)[{triallicense-node-5f4de39200}{sK32j3kTRJ21UfYGLvHyBQ}{JmUwkYxMRhSZ53_11xFwyQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{triallicense-node-5f4de39200}{sK32j3kTRJ21UfYGLvHyBQ}{JmUwkYxMRhSZ53_11xFwyQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:14:12,857][INFO ][o.e.c.s.ClusterApplierService] [triallicense-node-5f4de39200] master node changed {previous [], current [{triallicense-node-5f4de39200}{sK32j3kTRJ21UfYGLvHyBQ}{JmUwkYxMRhSZ53_11xFwyQ}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:14:13,578][INFO ][o.e.g.GatewayService     ] [triallicense-node-5f4de39200] recovered [0] indices into cluster_state
[2019-06-03T16:14:14,484][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:14:14,795][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:14:14,881][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:14:15,233][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:14:15,298][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:14:15,461][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:14:16,180][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:14:16,433][INFO ][o.e.c.m.MetaDataIndexTemplateService] [triallicense-node-5f4de39200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:14:16,866][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [triallicense-node-5f4de39200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T16:14:17,168][INFO ][o.e.l.LicenseService     ] [triallicense-node-5f4de39200] license [3b9e5342-ac26-462d-acfb-6bdf44d3d5cb] mode [basic] - valid
[2019-06-03T16:14:17,568][INFO ][o.e.h.AbstractHttpServerTransport] [triallicense-node-5f4de39200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T06:14:17,597][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T16:14:17,568][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] started
[2019-06-03T06:14:17,794][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:14:17,900][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T06:14:17,917][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T06:14:17,918][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:14:18,051][INFO ][Managed Elasticsearch    ]  All good! kicking off [TrialLicenseCluster] tests now
[2019-06-03T16:14:18,196][INFO ][o.e.l.LicenseService     ] [triallicense-node-5f4de39200] license [d397b3df-7ceb-4a0c-98e0-49629518dc52] mode [trial] - valid
[2019-06-03T16:14:18,324][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] stopping ...
[2019-06-03T16:14:18,333][INFO ][o.e.x.w.WatcherService   ] [triallicense-node-5f4de39200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:14:18,535][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [triallicense-node-5f4de39200] [controller/3428] [Main.cc@148] Ml controller exiting
[2019-06-03T16:14:18,536][INFO ][o.e.x.m.p.NativeController] [triallicense-node-5f4de39200] Native controller process has stopped - no new native processes can be started
[2019-06-03T16:14:18,545][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] stopped
[2019-06-03T16:14:18,546][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] closing ...
[2019-06-03T16:14:18,558][INFO ][o.e.n.Node               ] [triallicense-node-5f4de39200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:14:19,256][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\data}
[2019-06-03T06:14:19,264][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\config}
[2019-06-03T06:14:19,267][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\logs}
[2019-06-03T06:14:19,272][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c\repositories}
[2019-06-03T06:14:19,273][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-cff99c}
[2019-06-03T06:14:19,502][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T06:14:19,502][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:14:19,503][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-bfa472]
[2019-06-03T06:14:19,503][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T06:14:19,504][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T06:14:19,504][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:14:19,505][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} []
[2019-06-03T06:14:19,505][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T06:14:19,506][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:14:19,506][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:14:19,507][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:14:19,507][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:14:19,508][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:14:19,508][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:14:19,509][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:14:19,509][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:14:19,512][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\home]
[2019-06-03T06:14:22,234][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:14:22,237][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472}
[2019-06-03T06:14:22,237][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\config}
[2019-06-03T06:14:22,239][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\config]
[2019-06-03T06:14:22,250][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x]
[2019-06-03T06:14:22,251][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\config\analysis]
[2019-06-03T06:14:22,257][INFO ][Managed Elasticsearch    ] [sniffroledetection-node-89b3419200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\home\bin\elasticsearch.bat]
[2019-06-03T06:14:22,260][INFO ][Managed Elasticsearch    ] [sniffroledetection-node-89b3419200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-bfa472 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.data=false -E node.master=true -E node.attr.rack_id=rack_one -E node.name=sniffroledetection-node-89b3419200 -E http.port=9200 -E cluster.initial_master_nodes=sniffroledetection-node-89b3419200}
[2019-06-03T16:14:42,528][INFO ][o.e.e.NodeEnvironment    ] [sniffroledetection-node-89b3419200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:14:42,534][INFO ][o.e.e.NodeEnvironment    ] [sniffroledetection-node-89b3419200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:14:42,568][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] node name [sniffroledetection-node-89b3419200], node ID [Bc0DflHsRAmLP_kw69GnHA]
[2019-06-03T16:14:42,570][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] version[7.0.0], pid[5500], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:14:42,574][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:14:42,574][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
[2019-06-03T16:15:05,768][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [aggs-matrix-stats]
[2019-06-03T16:15:05,768][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [analysis-common]
[2019-06-03T16:15:05,769][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [ingest-common]
[2019-06-03T16:15:05,769][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [ingest-geoip]
[2019-06-03T16:15:05,769][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [ingest-user-agent]
[2019-06-03T16:15:05,770][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [lang-expression]
[2019-06-03T16:15:05,770][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [lang-mustache]
[2019-06-03T16:15:05,770][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [lang-painless]
[2019-06-03T16:15:05,770][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [mapper-extras]
[2019-06-03T16:15:05,771][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [parent-join]
[2019-06-03T16:15:05,771][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [percolator]
[2019-06-03T16:15:05,771][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [rank-eval]
[2019-06-03T16:15:05,772][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [reindex]
[2019-06-03T16:15:05,772][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [repository-url]
[2019-06-03T16:15:05,773][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [transport-netty4]
[2019-06-03T16:15:05,773][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-ccr]
[2019-06-03T16:15:05,773][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-core]
[2019-06-03T16:15:05,774][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-deprecation]
[2019-06-03T16:15:05,774][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-graph]
[2019-06-03T16:15:05,774][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-ilm]
[2019-06-03T16:15:05,775][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-logstash]
[2019-06-03T16:15:05,775][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-ml]
[2019-06-03T16:15:05,776][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-monitoring]
[2019-06-03T16:15:05,776][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-rollup]
[2019-06-03T16:15:05,776][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-security]
[2019-06-03T16:15:05,776][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-sql]
[2019-06-03T16:15:05,777][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] loaded module [x-pack-watcher]
[2019-06-03T16:15:05,777][INFO ][o.e.p.PluginsService     ] [sniffroledetection-node-89b3419200] no plugins loaded
[2019-06-03T16:15:12,600][INFO ][o.e.x.m.p.l.CppLogMessageHandler] [sniffroledetection-node-89b3419200] [controller/6644] [Main.cc@109] controller (64 bit): Version 7.0.0 (Build cdaa022645f38d) Copyright (c) 2019 Elasticsearch BV
[2019-06-03T16:15:13,889][INFO ][o.e.d.DiscoveryModule    ] [sniffroledetection-node-89b3419200] using discovery type [zen] and seed hosts providers [settings]
[2019-06-03T16:15:15,497][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] initialized
[2019-06-03T16:15:15,497][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] starting ...
[2019-06-03T16:15:16,973][INFO ][o.e.t.TransportService   ] [sniffroledetection-node-89b3419200] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2019-06-03T16:15:16,985][WARN ][o.e.b.BootstrapChecks    ] [sniffroledetection-node-89b3419200] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured
[2019-06-03T16:15:17,006][INFO ][o.e.c.c.ClusterBootstrapService] [sniffroledetection-node-89b3419200] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered
[2019-06-03T16:15:20,012][INFO ][o.e.c.c.Coordinator      ] [sniffroledetection-node-89b3419200] setting initial configuration to VotingConfiguration{Bc0DflHsRAmLP_kw69GnHA}
[2019-06-03T16:15:20,205][INFO ][o.e.c.s.MasterService    ] [sniffroledetection-node-89b3419200] elected-as-master ([1] nodes joined)[{sniffroledetection-node-89b3419200}{Bc0DflHsRAmLP_kw69GnHA}{f0fM2bHZRV2Zt2nzT3A_lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, rack_id=rack_one, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, reason: master node changed {previous [], current [{sniffroledetection-node-89b3419200}{Bc0DflHsRAmLP_kw69GnHA}{f0fM2bHZRV2Zt2nzT3A_lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, rack_id=rack_one, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}
[2019-06-03T16:15:20,315][INFO ][o.e.c.s.ClusterApplierService] [sniffroledetection-node-89b3419200] master node changed {previous [], current [{sniffroledetection-node-89b3419200}{Bc0DflHsRAmLP_kw69GnHA}{f0fM2bHZRV2Zt2nzT3A_lg}{127.0.0.1}{127.0.0.1:9300}{testingcluster=true, rack_id=rack_one, ml.machine_memory=17010651136, xpack.installed=true, ml.max_open_jobs=20, gateway=true}]}, term: 1, version: 1, reason: Publication{term=1, version=1}
[2019-06-03T16:15:20,697][INFO ][o.e.g.GatewayService     ] [sniffroledetection-node-89b3419200] recovered [0] indices into cluster_state
[2019-06-03T16:15:20,952][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.triggered_watches] for index patterns [.triggered_watches*]
[2019-06-03T16:15:21,130][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.watch-history-9] for index patterns [.watcher-history-9*]
[2019-06-03T16:15:21,268][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.watches] for index patterns [.watches*]
[2019-06-03T16:15:21,324][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.monitoring-logstash] for index patterns [.monitoring-logstash-7-*]
[2019-06-03T16:15:21,494][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.monitoring-es] for index patterns [.monitoring-es-7-*]
[2019-06-03T16:15:21,738][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.monitoring-beats] for index patterns [.monitoring-beats-7-*]
[2019-06-03T16:15:21,959][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.monitoring-alerts-7] for index patterns [.monitoring-alerts-7]
[2019-06-03T16:15:22,130][INFO ][o.e.c.m.MetaDataIndexTemplateService] [sniffroledetection-node-89b3419200] adding template [.monitoring-kibana] for index patterns [.monitoring-kibana-7-*]
[2019-06-03T16:15:22,452][INFO ][o.e.h.AbstractHttpServerTransport] [sniffroledetection-node-89b3419200] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2019-06-03T06:15:22,628][INFO ][Managed Elasticsearch    ]  {ValidateRunningVersion} validating the cluster is running the requested version: 7.0.0
[2019-06-03T16:15:22,453][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] started
[2019-06-03T16:15:22,502][INFO ][o.e.l.LicenseService     ] [sniffroledetection-node-89b3419200] license [6cbc1f81-1b1b-4212-8a68-8201d8084c56] mode [basic] - valid
[2019-06-03T16:15:22,555][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [sniffroledetection-node-89b3419200] adding index lifecycle policy [watch-history-ilm-policy]
[2019-06-03T06:15:22,817][INFO ][Managed Elasticsearch    ]  {ValidateClusterStateTask} waiting cluster to go into yellow health state
[2019-06-03T06:15:22,845][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} no license file available to post
[2019-06-03T06:15:22,851][INFO ][Managed Elasticsearch    ]  {PostLicenseTask} 7.0.0 < 6.3.0 or opting out of explicit basic/trial license
[2019-06-03T06:15:22,851][INFO ][Managed Elasticsearch    ]  {ValidateLicenseTask} validating the x-pack license is active
[2019-06-03T06:15:22,986][INFO ][Managed Elasticsearch    ]  All good! kicking off [SniffRoleDetectionCluster] tests now
[2019-06-03T16:15:23,198][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] stopping ...
[2019-06-03T16:15:23,205][INFO ][o.e.x.w.WatcherService   ] [sniffroledetection-node-89b3419200] stopping watch service, reason [shutdown initiated]
[2019-06-03T16:15:23,215][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] stopped
[2019-06-03T16:15:23,216][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] closing ...
[2019-06-03T16:15:23,229][INFO ][o.e.n.Node               ] [sniffroledetection-node-89b3419200] closed
Terminate batch job (Y/N)? 
Y
[2019-06-03T06:15:23,462][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster data]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\data}
[2019-06-03T06:15:23,465][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster config]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\config}
[2019-06-03T06:15:23,473][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster logs]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\logs}
[2019-06-03T06:15:23,477][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [repositories]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472\repositories}
[2019-06-03T06:15:23,479][INFO ][Managed Elasticsearch    ]  {CleanUpDirectoriesAfterNodeStopped} attempting to delete [cluster temp folder]: {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-bfa472}
[2019-06-03T06:15:23,709][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} starting {7.0.0} with features [None]
[2019-06-03T06:15:23,710][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NumberOfNodes} [1]
[2019-06-03T06:15:23,711][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ClusterName} [ephemeral-cluster-b3f403]
[2019-06-03T06:15:23,711][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSsl} [False]
[2019-06-03T06:15:23,712][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {EnableSecurity} [False]
[2019-06-03T06:15:23,713][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {XPackInstalled} [True]
[2019-06-03T06:15:23,713][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {Plugins} []
[2019-06-03T06:15:23,714][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {TrialMode} [None]
[2019-06-03T06:15:23,714][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {CacheEsHomeInstallation} [True]
[2019-06-03T06:15:23,715][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ShowElasticsearchOutputAfterStarted} [True]
[2019-06-03T06:15:23,716][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {ValidatePluginsToInstall} [True]
[2019-06-03T06:15:23,716][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {PrintYamlFilesInConfigFolder} [False]
[2019-06-03T06:15:23,717][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {SkipBuiltInAfterStartTasks} [False]
[2019-06-03T06:15:23,717][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {HttpFiddlerAware} [True]
[2019-06-03T06:15:23,718][INFO ][Managed Elasticsearch    ]  {PrintConfiguration} {NoCleanupAfterNodeStopped} [False]
[2019-06-03T06:15:23,719][INFO ][Managed Elasticsearch    ]  {CreateLocalApplicationDirectory} already exists: {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64}
[2019-06-03T06:15:23,719][INFO ][Managed Elasticsearch    ]  {CopyCachedEsInstallation} using cached ES_HOME {C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x} and copying it to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\home]
[2019-06-03T06:15:26,921][INFO ][Managed Elasticsearch    ]  {EnsureJavaHomeEnvironmentVariableIsSet} JAVA_HOME is set proceeding
[2019-06-03T06:15:26,926][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403}
[2019-06-03T06:15:26,927][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} creating config folder {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\config}
[2019-06-03T06:15:26,932][INFO ][Managed Elasticsearch    ]  {CreateEphemeralDirectory} copying cached {C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\home\config} as to [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\config]
[2019-06-03T06:15:26,950][INFO ][Managed Elasticsearch    ]  {CacheElasticsearchInstallation} cached home already exists [C:\Users\User\AppData\Local\ElasticManaged\7.0.0-windows-x86_64\10-x]
[2019-06-03T06:15:26,951][INFO ][Managed Elasticsearch    ]  {WriteAnalysisFiles} writing analysis files to watcher config [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\config\analysis]
[2019-06-03T06:15:26,956][INFO ][Managed Elasticsearch    ] [manualreindex-node-c9f8a89200] Elasticsearch location: [C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\home\bin\elasticsearch.bat]
[2019-06-03T06:15:26,957][INFO ][Managed Elasticsearch    ] [manualreindex-node-c9f8a89200] Settings: {-E node.max_local_storage_nodes=1 -E cluster.name=ephemeral-cluster-b3f403 -E path.repo=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\repositories -E path.data=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\data -E path.logs=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\logs -E xpack.security.enabled=false -E xpack.security.http.ssl.enabled=false -E xpack.security.transport.ssl.enabled=false -E node.attr.testingcluster=true -E node.attr.gateway=true -E search.remote.connect=true -E script.max_compilations_rate=10000/1m -E script.allowed_types=inline,stored -E node.name=manualreindex-node-c9f8a89200 -E http.port=9200 -E cluster.initial_master_nodes=manualreindex-node-c9f8a89200}
[2019-06-03T16:15:37,830][INFO ][o.e.e.NodeEnvironment    ] [manualreindex-node-c9f8a89200] using [1] data paths, mounts [[Windows (C:)]], net usable_space [168.6gb], net total_space [475.6gb], types [NTFS]
[2019-06-03T16:15:37,836][INFO ][o.e.e.NodeEnvironment    ] [manualreindex-node-c9f8a89200] heap size [990.7mb], compressed ordinary object pointers [true]
[2019-06-03T16:15:37,844][INFO ][o.e.n.Node               ] [manualreindex-node-c9f8a89200] node name [manualreindex-node-c9f8a89200], node ID [3ZRZUsONSmC8ckN5g_rBFA]
[2019-06-03T16:15:37,847][INFO ][o.e.n.Node               ] [manualreindex-node-c9f8a89200] version[7.0.0], pid[4332], build[default/zip/b7e28a7/2019-04-05T22:55:32.697037Z], OS[Windows 10/10.0/amd64], JVM["Oracle Corporation"/Java HotSpot(TM) 64-Bit Server VM/10.0.1/10.0.1+10]
[2019-06-03T16:15:37,848][INFO ][o.e.n.Node               ] [manualreindex-node-c9f8a89200] JVM home [C:\Program Files\Java\jre-10.0.1]
[2019-06-03T16:15:37,849][INFO ][o.e.n.Node               ] [manualreindex-node-c9f8a89200] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\Users\User\AppData\Local\Temp\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\home, -Des.path.conf=C:\Users\User\AppData\Local\Temp\ElasticManaged\elasticsearch-7.0.0\ephemeral-cluster-b3f403\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]
Attempting to cancel the build...
Attempting to cancel the build...
Attempting to cancel the build...
Attempting to cancel the build...
Terminate batch job (Y/N)? Terminate batch job (Y/N)? Terminate batch job (Y/N)? Terminate batch job (Y/N)? Terminate batch job (Y/N)? Terminate batch job (Y/N)? 